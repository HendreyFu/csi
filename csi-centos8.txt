
====CSI v1.4.0 06/25/2021 update
Supported Platforms and Support Kubernetes version!!!
https://dell.github.io/storage-plugin-docs/docs/dell-csi-driver/

Release Notes - CSI PowerStore v1.4.0 (06/18/2021)
New Features/Changes
-Added support for Kubernetes v1.21
-Added support for OpenShift 4.7 with RHEL and CoreOS worker nodes
-Added support for SLES 15.2 and RHEL 8.4 as a host operating system
-Added support for enabling root-squashing for NFS shares
-Added support for disabling snapshot feature during installation
-Added the ability to configure nasName per Storage Class
-Refactored configuration files to use more generic naming

Centos 8.4 or RHEL 8.4
Note:
Kubernetes cannot work with Podman (which is now the default container engine for both RHEL and CentOS).
youll need to install the docker engine. !!!

[root@master ~]# cat /etc/centos-release
CentOS Linux release 8.4.2105
[root@master ~]# uname -a
Linux master.local 4.18.0-305.3.1.el8.x86_64 #1 SMP Tue Jun 1 16:14:33 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
...
...
[root@master ~]# modprobe br_netfilter
[root@master ~]# lsmod |grep -i netfilter
br_netfilter           24576  0
bridge                192512  1 br_netfilter
[root@master ~]# cat > /etc/sysctl.d/k8s.conf <<EOF
> net.bridge.bridge-nf-call-ip6tables = 1
> net.bridge.bridge-nf-call-iptables = 1
> net.ipv4.ip_forward = 1
> EOF
[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1

[root@master ~]# cat /etc/hosts
192.168.1.20    master.local    master
192.168.1.21    node1.local     node1
192.168.1.22    node2.local     node2
192.168.1.23    node3.local     node3

[root@master ~]# cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 192.168.1.50

#install docker on master
   45  yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion git vim net-tools wget
   49  yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
   50  ls /etc/yum.repos.d/
   52  yum makecache
   53  yum list docker-ce | sort -r
   54  yum -y install docker-ce
   55  systemctl enable --now docker
   57  systemctl status docker
   58  docker --version
   Docker version 20.10.7, build f0df350
   59  docker info

#clone master to node1--3

ssh-keygen -t rsa
for i in {master,node1,node2,node3}; do ssh-copy-id $i ; done
cat ~/.ssh/authorized_keys
cat ~/.ssh/id_rsa.pub
for i in {master,node1,node2,node3}; do ssh $i sed -i.bak '/swap/s/^/#/' /etc/fstab ; ssh $i swapoff -a; ssh $i free; done
for i in {master,node1,node2,node3}; do ssh $i setenforce 0 ; ssh $i sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config ; ssh $i getenforce ; done
for i in {node1,node2,node3}; do scp /etc/resolv.conf  $i:/etc/resolv.conf; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i cat /sys/class/dmi/id/product_uuid; done
[root@master ~]# for i in {node1,node2,node3}; do ssh $i modprobe br_netfilter ; scp /etc/sysctl.d/k8s.conf $i:/etc/sysctl.d/k8s.conf; ssh $i sysctl -p /etc/sysctl.d/k8s.conf ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i systemctl disable firewalld ;  ssh $i systemctl stop firewalld ; done

vi /etc/yum.repos.d/kubernetes.repo
[root@master ~]# cat /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl

[root@master ~]# for i in {node1,node2,node3}; do scp /etc/yum.repos.d/kubernetes.repo $i:/etc/yum.repos.d/kubernetes.repo ; ssh $i yum repolist ; done
[root@master ~]# yum list --showduplicates kubeadm --disableexcludes=kubernetes | sort -r
#csi v1.4.0 support kubernetes 1.21
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes ; done
#csi v1.3.0 use kubectl 1.20
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet-1.20.8-0 kubeadm-1.20.8-0 kubectl-1.20.8-0 --disableexcludes=kubernetes ; done

#rhel8 can't use podman for kubernetes!!!
{
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum module install -y container-tools:2.0  ; done
[root@master ~]# grep -v "^#\|^$" /etc/containers/registries.conf
[registries.search]
registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io']
[registries.insecure]
registries = []
[registries.block]
registries = []
[root@master ~]# podman -v
podman version 1.6.4
[root@master ~]# podman info
host:
  BuildahVersion: 1.12.0-dev
  CgroupVersion: v1
  Conmon:
    package: conmon-2.0.15-1.module_el8.3.0+479+69e2ae26.x86_64
    path: /usr/bin/conmon
    version: 'conmon version 2.0.15, commit: 0198f57f29209da30f765318dda9328bac6a5e07'
  Distribution:
    distribution: '"centos"'
    version: "8"
  MemFree: 6980251648
  MemTotal: 8144797696
  OCIRuntime:
    name: runc
    package: runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64
    path: /usr/bin/runc
    version: 'runc version spec: 1.0.1-dev'
  SwapFree: 0
  SwapTotal: 0
  arch: amd64
  cpus: 2
  eventlogger: journald
  hostname: master
  kernel: 4.18.0-240.el8.x86_64
  os: linux
  rootless: false
  uptime: 2h 13m 16.45s (Approximately 0.08 days)
registries:
  blocked: null
  insecure: null
  search:
  - registry.access.redhat.com
  - registry.redhat.io
  - docker.io
store:
  ConfigFile: /etc/containers/storage.conf
  ContainerStore:
    number: 0
  GraphDriverName: overlay
  GraphOptions: {}
  GraphRoot: /var/lib/containers/storage
  GraphStatus:
    Backing Filesystem: xfs
    Native Overlay Diff: "true"
    Supports d_type: "true"
    Using metacopy: "false"
  ImageStore:
    number: 0
  RunRoot: /var/run/containers/storage
  VolumePath: /var/lib/containers/storage/volumes

[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i podman pull dellemc/csi-powerstore && podman images ; done
[root@master ~]# podman inspect docker.io/dellemc/csi-powerstore:latest | grep -i "version\|release"
                "release": "291",
                "version": "1.3.0"
        "Version": "",
            "release": "291",
            "version": "1.3.0"


  128  for i in {master,node1,node2,node3}; do ssh $i podman rmi dellemc/csi-powerstore && podman images ; done
  129  for i in {master,node1,node2,node3}; do ssh $i yum module remove -y container-tools:2.0  ; done

[root@master ~]# cat /tmp/config.sh
#/bin/bash
for i in {node1,node2,node3}; do scp /etc/yum.repos.d/kubernetes.repo $i:/etc/yum.repos.d/kubernetes.repo ; ssh $i yum repolist ; done
for i in {master,node1,node2,node3}; do ssh $i setenforce 0 ; ssh $i sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config ; ssh $i getenforce ; done
for i in {master,node1,node2,node3}; do ssh $i systemctl disable firewalld.service; ssh $i systemctl stop firewalld.service ; done
for i in {master,node1,node2,node3}; do ssh $i yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion git vim net-tools ; done
for i in {master,node1,node2,node3}; do ssh $i yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo ; done
for i in {master,node1,node2,node3}; do ssh $i yum -y install docker-ce ; done
for i in {master,node1,node2,node3}; do ssh $i systemctl enable docker ; ssh $i systemctl start docker ; ssh $i systemctl status docker ; ssh $i docker version; done
for i in {master,node1,node2,node3}; do ssh $i docker --version ; done
for i in {master,node1,node2,node3}; do ssh $i docker pull dellemc/csi-powerstore:v1.3.0 ; ssh $i docker images ; done
for i in {master,node1,node2,node3}; do ssh $i docker images ; done
for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes ; done
[root@master ~]# chmod +x /tmp/config.sh
[root@master ~]# /tmp/config.sh
}

#Note:
Don't change docker.service to "MountFlags=shared" in /etc/systemd/system/multi-user.target.wants/docker.service, it will cause Centos 8 docker failed to start!!!

[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i kubeadm config images pull ; done
[root@master csi-powerstore]# docker images | grep k8s
k8s.gcr.io/kube-apiserver            v1.21.2    106ff58d4308   9 days ago      126MB
k8s.gcr.io/kube-proxy                v1.21.2    a6ebd1c1ad98   9 days ago      131MB
k8s.gcr.io/kube-scheduler            v1.21.2    f917b8c8f55b   9 days ago      50.6MB
k8s.gcr.io/kube-controller-manager   v1.21.2    ae24db9aa2cc   9 days ago      120MB
k8s.gcr.io/pause                     3.4.1      0f8457a4c2ec   5 months ago    683kB
k8s.gcr.io/coredns/coredns           v1.8.0     296a6d5035e2   8 months ago    42.5MB
k8s.gcr.io/etcd                      3.4.13-0   0369cf4303ff   10 months ago   253MB
[root@master ~]#

#add iscsi nic in VC and config each ip
nmcli conn show
nmcli connection modify "Wired connection 1" con-name ens224 ifname ens224
nmcli conn mod ens224 ipv4.address 192.168.2.220/24 ipv4.method static connection.autoconnect yes && nmcli con up ens224 && nmcli con show

  138  kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.1.20
  139  for i in {node1,node2,node3}; do ssh $i kubeadm join 192.168.1.20:6443 --token tkmf3y.x3rzt3m6rtxhwc02 --discovery-token-ca-cert-hash sha256:9823a831616f82a964ae1116b6c6dfeac5c83e865a7205230adc8a0828e18fb8 ; done
  140  systemctl status kubelet
       for i in {master,node1,node2,node3}; do ssh $i systemctl enable kubelet ; done 
  141  netstat -ntpl
  142  kubectl get nodes
  144  echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile
  145  echo "source <(kubectl completion bash)" >> ~/.bash_profile
  146  source ~/.bash_profile
  147  kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
  148  kubectl get cs
  149  vi ~/.vimrc
  150  vim /etc/kubernetes/manifests/kube-controller-manager.yaml     //delete --port=0 line!!
  151  vim /etc/kubernetes/manifests/kube-scheduler.yaml
  152  kubectl get cs
  153  kubectl cluster-info
  154  kubectl get nodes
[root@master ~]# kubectl get nodes
NAME           STATUS   ROLES                  AGE     VERSION
master.local   Ready    control-plane,master   12m   v1.21.2
node1.local    Ready    <none>                 10m   v1.21.2
node2.local    Ready    <none>                 10m   v1.21.2
node3.local    Ready    <none>                 10m   v1.21.2
[root@master ~]# kubectl get pods -A
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-hj952          1/1     Running   1          26m
kube-system   coredns-74ff55c5b-qfg5p          1/1     Running   1          26m
kube-system   etcd-master                      1/1     Running   1          26m
kube-system   kube-apiserver-master            1/1     Running   1          26m
kube-system   kube-controller-manager-master   1/1     Running   1          17m
kube-system   kube-flannel-ds-amd64-5lgwk      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-fvtgw      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-hcgth      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-rgmkv      1/1     Running   1          21m
kube-system   kube-proxy-kc7dp                 1/1     Running   1          24m
kube-system   kube-proxy-nwm98                 1/1     Running   1          24m
kube-system   kube-proxy-vl27z                 1/1     Running   1          24m
kube-system   kube-proxy-xmlqj                 1/1     Running   1          26m
kube-system   kube-scheduler-master            1/1     Running   1          17m

#install helm
[root@master ~]# curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
[root@master ~]# helm version
version.BuildInfo{Version:"v3.6.1", GitCommit:"61d8e8c4a6f95540c15c6a65f36a6dd0a45e7a2f", GitTreeState:"clean", GoVersion:"go1.16.5"}

#install iscsi
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum -y install iscsi-initiator-utils device-mapper-multipath lsscsi ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i cat /etc/iscsi/initiatorname.iscsi ; done
InitiatorName=iqn.1994-05.com.redhat:master
InitiatorName=iqn.1994-05.com.redhat:node1
InitiatorName=iqn.1994-05.com.redhat:node2
InitiatorName=iqn.1994-05.com.redhat:node3
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i iscsiadm -m discovery -t st -p 192.168.2.40:3260 ; ssh $i iscsiadm -m node -L all ; ssh $i hostname ; ssh $i iscsiadm -m session ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i mpathconf --enable --user_friendly_names y --with_module y --with_multipathd y --find_multipaths y ; ssh $i systemctl is-enabled multipathd.service ; ssh $i systemctl start multipathd.service ; ssh $i hostname; ssh $i systemctl status multipathd.service ; done


#install powerstore csi v1.4.0 gitclone
Procedure
Run git clone https://github.com/dell/csi-powerstore.git to clone the git repository
...
...
[root@master ~]# cd csi-powerstore/
[root@master csi-powerstore]# ls
cmd  core  dell-csi-helm-installer  docker-files  docker.mk  env.sh  go.mod  go.sum  helm  LICENSE  licenses  Makefile  mocks  pkg  README.md  tests
[root@master csi-powerstore]# ls helm/
config.yaml  csi-powerstore  README.md  samples  secret.yaml

[root@master csi-powerstore]# cat helm/csi-powerstore/driver-image.yaml | grep driver
  # "images.driver" defines the container images used for the driver container.
  driver: dellemc/csi-powerstore:v1.4.0
[root@master csi-powerstore]# for i in {master,node1,node2,node3}; do ssh $i docker pull dellemc/csi-powerstore:v1.4.0 ; ssh $i docker images ; done

#snapshot install
[root@master csi-powerstore]# cd ~
[root@master ~]# git clone https://github.com/kubernetes-csi/external-snapshotter/
Cloning into 'external-snapshotter'...
remote: Enumerating objects: 44797, done.
remote: Counting objects: 100% (1802/1802), done.
remote: Compressing objects: 100% (744/744), done.
remote: Total 44797 (delta 1022), reused 1779 (delta 1013), pack-reused 42995
Receiving objects: 100% (44797/44797), 60.93 MiB | 2.62 MiB/s, done.
Resolving deltas: 100% (21787/21787), done.
[root@master ~]# cd external-snapshotter/
[root@master external-snapshotter]# ls
CHANGELOG  cloudbuild.yaml  code-of-conduct.md  deploy    go.mod  LICENSE   OWNERS          pkg        release-tools      vendor
client     cmd              CONTRIBUTING.md     examples  go.sum  Makefile  OWNERS_ALIASES  README.md  SECURITY_CONTACTS

[root@master external-snapshotter]# git checkout release-4.0
Branch 'release-4.0' set up to track remote branch 'release-4.0' from 'origin'.
Switched to a new branch 'release-4.0'

[root@master external-snapshotter]# kubectl create -f client/config/crd/
customresourcedefinition.apiextensions.k8s.io/volumesnapshotclasses.snapshot.storage.k8s.io created
customresourcedefinition.apiextensions.k8s.io/volumesnapshotcontents.snapshot.storage.k8s.io created
customresourcedefinition.apiextensions.k8s.io/volumesnapshots.snapshot.storage.k8s.io created
[root@master external-snapshotter]# kubectl create -f deploy/kubernetes/snapshot-controller/
serviceaccount/snapshot-controller created
clusterrole.rbac.authorization.k8s.io/snapshot-controller-runner created
clusterrolebinding.rbac.authorization.k8s.io/snapshot-controller-role created
role.rbac.authorization.k8s.io/snapshot-controller-leaderelection created
rolebinding.rbac.authorization.k8s.io/snapshot-controller-leaderelection created
statefulset.apps/snapshot-controller created

[root@master tmp]# cd ~/csi-powerstore/dell-csi-helm-installer/
[root@master dell-csi-helm-installer]# kubectl get all --all-namespaces
NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE
default       pod/snapshot-controller-0            1/1     Running   0          52s
kube-system   pod/coredns-74ff55c5b-8hbq8          0/1     Running   0          99m
kube-system   pod/coredns-74ff55c5b-msrrz          0/1     Running   0          99m
kube-system   pod/etcd-master                      1/1     Running   0          99m
kube-system   pod/kube-apiserver-master            1/1     Running   0          99m
kube-system   pod/kube-controller-manager-master   1/1     Running   0          90m
kube-system   pod/kube-flannel-ds-amd64-b6vd7      1/1     Running   0          94m
kube-system   pod/kube-flannel-ds-amd64-dws65      1/1     Running   0          94m
kube-system   pod/kube-flannel-ds-amd64-tqqnj      1/1     Running   0          94m
kube-system   pod/kube-flannel-ds-amd64-xtcjv      1/1     Running   0          94m
kube-system   pod/kube-proxy-5lbwp                 1/1     Running   0          98m
kube-system   pod/kube-proxy-b5n8s                 1/1     Running   0          97m
kube-system   pod/kube-proxy-c6jzr                 1/1     Running   0          98m
kube-system   pod/kube-proxy-r7kxj                 1/1     Running   0          99m
kube-system   pod/kube-scheduler-master            1/1     Running   0          90m

NAMESPACE     NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
default       service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP                  99m
kube-system   service/kube-dns     ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   99m

NAMESPACE     NAME                                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-system   daemonset.apps/kube-flannel-ds-amd64     4         4         4       4            4           <none>                   94m
kube-system   daemonset.apps/kube-flannel-ds-arm       0         0         0       0            0           <none>                   94m
kube-system   daemonset.apps/kube-flannel-ds-arm64     0         0         0       0            0           <none>                   94m
kube-system   daemonset.apps/kube-flannel-ds-ppc64le   0         0         0       0            0           <none>                   94m
kube-system   daemonset.apps/kube-flannel-ds-s390x     0         0         0       0            0           <none>                   94m
kube-system   daemonset.apps/kube-proxy                4         4         4       4            4           kubernetes.io/os=linux   99m

NAMESPACE     NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
kube-system   deployment.apps/coredns   0/2     2            0           99m

NAMESPACE     NAME                                DESIRED   CURRENT   READY   AGE
kube-system   replicaset.apps/coredns-74ff55c5b   2         2         0       99m

NAMESPACE   NAME                                   READY   AGE
default     statefulset.apps/snapshot-controller   1/1     52s
[root@master csi-powerstore]# kubectl logs snapshot-controller-0 -n default
[root@master tmp]# kubectl logs snapshot-controller-0 -n default
I0625 12:59:36.440439       1 main.go:71] Version: v4.0.0
I0625 12:59:36.446428       1 main.go:120] Start NewCSISnapshotController with kubeconfig [] resyncPeriod [15m0s]
I0625 12:59:36.447786       1 reflector.go:219] Starting reflector *v1.VolumeSnapshotClass (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.447805       1 reflector.go:255] Listing and watching *v1.VolumeSnapshotClass from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.447969       1 reflector.go:219] Starting reflector *v1.VolumeSnapshot (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.447981       1 reflector.go:255] Listing and watching *v1.VolumeSnapshot from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.448956       1 reflector.go:219] Starting reflector *v1.VolumeSnapshotContent (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.448968       1 reflector.go:255] Listing and watching *v1.VolumeSnapshotContent from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0625 12:59:36.449260       1 reflector.go:219] Starting reflector *v1.PersistentVolumeClaim (15m0s) from k8s.io/client-go/informers/factory.go:134
I0625 12:59:36.449274       1 reflector.go:255] Listing and watching *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:134
I0625 12:59:36.450125       1 snapshot_controller_base.go:133] Starting snapshot controller
I0625 12:59:36.550432       1 shared_informer.go:270] caches populated
I0625 12:59:36.550458       1 snapshot_controller_base.go:485] controller initialized

[root@master csi-powerstore]#

[root@master csi-powerstore]# kubectl create namespace csi-powerstore

[root@master csi-powerstore]# cat helm/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: powerstore-config
  # Set driver namespace
  namespace: csi-powerstore
type: Opaque
data:
  config: CONFIG_YAML
 
[root@linux17 ~]# curl -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=* | json_reformat
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   310    0   310    0     0   1920      0 --:--:-- --:--:-- --:--:--  1913
[
    {
        "id": "0",
        "global_id": "PSec370360bc60",
        "name": "POD3-Cluster2",
        "physical_mtu": 1500,
        "master_appliance_id": "A1",
        "state": "Configured",
        "appliance_count": 1,
        "management_address": "192.168.1.40",
        "is_encryption_enabled": true,
        "storage_discovery_address": "192.168.2.40",
        "compatibility_level": 1,
        "state_l10n": "Configured"
    }
]
 
[root@master csi-powerstore]# cat helm/config.yaml
# You can apply current config to Kubernetes cluster by running following command:
#
# sed "s/CONFIG_YAML/`cat config.yaml | base64 -w0`/g" secret.yaml | kubectl apply -f -
#
arrays:
  - endpoint: "https://192.168.1.40/api/rest"     # full URL path to the PowerStore API
    globalID: "PSec370360bc60"                    # unique id of the PowerStore array
    username: "admin"                          # username for connecting to API
    password: "P@ssw0rd!"                      # password for connecting to API
    skipCertificateValidation: true           # indicates if client side validation of (management)server's certificate can be skipped
    isDefault: true                           # treat current array as a default (would be used by storage classes without arrayID parameter)
    blockProtocol: "auto"                     # what SCSI transport protocol use on node side (FC, ISCSI, None, or auto)
    #nasName: "nas-server"                     # what NAS should be used for NFS volumes

#  - endpoint: "https://11.0.0.1/api/rest"
#    globalID: "unique"
#    username: "user"
#    password: "password"
#    skipCertificateValidation: true
#    blockProtocol: "FC"
[root@master csi-powerstore]#

#csi v1.4.0 storageclass use arrayID!!
[root@master csi-powerstore]# cat helm/samples/storageclass/powerstore-xfs.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-xfs
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate
parameters:
  arrayID: "PS04e694d0c442"
  FsType: xfs

#csi v1.3.0 storageclass use arrayIP!!
[root@master csi-powerstore]# cat helm/samples/storageclass/powerstore-xfs.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-xfs
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate
parameters:
  arrayIP: "192.168.1.30"
  FsType: xfs
  
[root@master csi-powerstore]# kubectl get sc
No resources found
[root@master csi-powerstore]# kubectl apply -f helm/samples/storageclass/powerstore-xfs.yaml
storageclass.storage.k8s.io/powerstore-xfs created
[root@master csi-powerstore]# kubectl get sc
NAME             PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
powerstore-xfs   csi-powerstore.dellemc.com   Delete          Immediate           true                   18s

[root@master csi-powerstore]# sed "s/CONFIG_YAML/`cat helm/config.yaml | base64 -w0`/g" helm/secret.yaml | kubectl apply -f -
[root@master csi-powerstore]# kubectl get secrets -n csi-powerstore
NAME                  TYPE                                  DATA   AGE
default-token-9zbgd   kubernetes.io/service-account-token   3      81m
powerstore-config     Opaque                                1      12s

[root@master csi-powerstore]# cd dell-csi-helm-installer && cp ../helm/csi-powerstore/values.yaml ./my-powerstore-settings.yaml
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# vim my-powerstore-settings.yaml
[root@master dell-csi-helm-installer]# grep -v "^#\|^$\|^  #" my-powerstore-settings.yaml
driverName: "csi-powerstore.dellemc.com"
volumeNamePrefix: csi
nodeNamePrefix: csi-node
nodeIDPath: /etc/hostname
controller:
  nodeSelector:
  tolerations:
  replicas: 3
node:
  nodeSelector:
  tolerations:
connection:
  enableCHAP: false
nodeFCPortsFilterFile: /etc/fc-ports-filter
snapshot:
  enabled: false
replication:
  enabled: false
externalAccess:

[root@master dell-csi-helm-installer]# ./csi-install.sh --namespace csi-powerstore --values ./my-powerstore-settings.yaml
------------------------------------------------------
> Installing CSI Driver: csi-powerstore on 1.20
------------------------------------------------------
------------------------------------------------------
> Checking to see if CSI Driver is already installed
------------------------------------------------------
------------------------------------------------------
> Verifying Kubernetes and driver configuration
------------------------------------------------------
|- Kubernetes Version: 1.20
|
|- Driver: csi-powerstore
|
|- Verifying Kubernetes versions
  |
  |--> Verifying minimum Kubernetes version                         Success
  |
  |--> Verifying maximum Kubernetes version                         Success
|
|- Verifying that required namespaces have been created             Success
|
|- Verifying that required secrets have been created                Success
|
|- Verifying alpha snapshot resources
  |
  |--> Verifying that alpha snapshot CRDs are not installed         Success
|
|- Verifying iSCSI installation                                     Success
|
|- Verifying helm version                                           Success

------------------------------------------------------
> Verification Complete - Success
------------------------------------------------------
|
|- Installing Driver                                                Success
  |
  |--> Waiting for Deployment powerstore-controller to be ready     Success
  |
  |--> Waiting for DaemonSet powerstore-node to be ready            Success
------------------------------------------------------
> Operation complete
------------------------------------------------------
[root@master dell-csi-helm-installer]#

[root@master dell-csi-helm-installer]# kubectl get pods -n csi-powerstore
NAME                                    READY   STATUS    RESTARTS   AGE
powerstore-controller-74c75cb64-pnjgm   4/4     Running   0          55m
powerstore-controller-74c75cb64-rv79g   4/4     Running   0          55m
powerstore-controller-74c75cb64-zjqnp   4/4     Running   0          55m
powerstore-node-794fz                   2/2     Running   0          55m
powerstore-node-bzrxg                   2/2     Running   0          55m
powerstore-node-frl67                   2/2     Running   0          55m
[root@master dell-csi-helm-installer]#

[root@master tmp]# kubectl describe pods powerstore-controller-74c75cb64-pnjgm
Name:         powerstore-controller-74c75cb64-pnjgm
Namespace:    csi-powerstore
Priority:     0
Node:         node3.local/192.168.1.23
Start Time:   Fri, 25 Jun 2021 07:55:28 -0400
Labels:       name=powerstore-controller
              pod-template-hash=74c75cb64
Annotations:  <none>
Status:       Running
IP:           10.244.3.6
IPs:
  IP:           10.244.3.6
Controlled By:  ReplicaSet/powerstore-controller-74c75cb64
Containers:
  attacher:
    Container ID:  docker://1783082fd2490d49bd3a74f9328cc72c465a5d7b3b2fd9c01afb013fcd987902
    Image:         k8s.gcr.io/sig-storage/csi-attacher:v3.2.1
    Image ID:      docker-pullable://k8s.gcr.io/sig-storage/csi-attacher@sha256:60ab9b3e6a030d3038c87c0d6bca2930f58d1d72823e6a4af09767dc83b696a2
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --v=5
      --leader-election
      --worker-threads=130
      --resync=10s
      --timeout=130s
    State:          Running
      Started:      Fri, 25 Jun 2021 08:58:58 -0400
    Last State:     Terminated
      Reason:       Error
      Exit Code:    2
      Started:      Fri, 25 Jun 2021 07:56:06 -0400
      Finished:     Fri, 25 Jun 2021 08:55:08 -0400
    Ready:          True
    Restart Count:  1
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gqzpg (ro)
  resizer:
    Container ID:  docker://39158b9763df05f2ad48ec17550c3c376518df7a6e2f1237b39b6c8ca984c5a7
    Image:         k8s.gcr.io/sig-storage/csi-resizer:v1.2.0
    Image ID:      docker-pullable://k8s.gcr.io/sig-storage/csi-resizer@sha256:36c31f7e1f433c9634d24f876353e8646246d81a03c4e351202c2644daff1620
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --v=5
      --leader-election
    State:          Running
      Started:      Fri, 25 Jun 2021 08:58:59 -0400
    Last State:     Terminated
      Reason:       Error
      Exit Code:    2
      Started:      Fri, 25 Jun 2021 07:57:00 -0400
      Finished:     Fri, 25 Jun 2021 08:55:09 -0400
    Ready:          True
    Restart Count:  1
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gqzpg (ro)
  provisioner:
    Container ID:  docker://0f70cc86c4f3d3870ef3e9ac02c6664ae24b6c4a27651267cedf9f8cdcd4cafd
    Image:         k8s.gcr.io/sig-storage/csi-provisioner:v2.2.1
    Image ID:      docker-pullable://k8s.gcr.io/sig-storage/csi-provisioner@sha256:4e74c0492bceddc598de1c90cc5bc14dcda94cb49fa9c5bad9d117c4834b5e08
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --volume-name-prefix=csi
      --volume-name-uuid-length=10
      --v=5
      --leader-election
      --default-fstype=ext4
      --extra-create-metadata
      --feature-gates=Topology=true
    State:          Running
      Started:      Fri, 25 Jun 2021 08:59:00 -0400
    Last State:     Terminated
      Reason:       Error
      Message:      Lost connection to CSI driver, exiting
      Exit Code:    255
      Started:      Fri, 25 Jun 2021 07:57:37 -0400
      Finished:     Fri, 25 Jun 2021 08:55:09 -0400
    Ready:          True
    Restart Count:  1
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gqzpg (ro)
  driver:
    Container ID:  docker://f439f466d4c7486d91013c27afdbade9a808843a090dca01e884dd1a8641a263
    Image:         dellemc/csi-powerstore:v1.4.0
    Image ID:      docker-pullable://dellemc/csi-powerstore@sha256:d98c918ac4c40839b67e379fb0711c55bf4ca1c4c7355b323723a29ad8a9bce4
    Port:          <none>
    Host Port:     <none>
    Command:
      /csi-powerstore
    State:          Running
      Started:      Fri, 25 Jun 2021 08:59:01 -0400
    Last State:     Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Fri, 25 Jun 2021 07:57:38 -0400
      Finished:     Fri, 25 Jun 2021 08:55:09 -0400
    Ready:          True
    Restart Count:  1
    Environment:
      CSI_ENDPOINT:                      /var/run/csi/csi.sock
      X_CSI_MODE:                        controller
      X_CSI_DEBUG:                       true
      X_CSI_DRIVER_NAME:                 csi-powerstore.dellemc.com
      X_CSI_POWERSTORE_EXTERNAL_ACCESS:
      X_CSI_POWERSTORE_CONFIG_PATH:      /powerstore-config/config
      GOPOWERSTORE_DEBUG:                true
    Mounts:
      /powerstore-config from powerstore-config (rw)
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gqzpg (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  socket-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  powerstore-config:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  powerstore-config
    Optional:    false
  kube-api-access-gqzpg:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>
[root@master dell-csi-helm-installer]#

[root@master tmp]# kubectl get sc
NAME             PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
powerstore-xfs   csi-powerstore.dellemc.com   Delete          Immediate           true                   146m
[root@master tmp]# kubectl describe sc powerstore-xfs
Name:                  powerstore-xfs
IsDefaultClass:        No
Annotations:           <none>
Provisioner:           csi-powerstore.dellemc.com
Parameters:            FsType=xfs,arrayID=PSec370360bc60
AllowVolumeExpansion:  True
MountOptions:          <none>
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                <none>


[root@master tmp]# yum localinstall pstcli-1.0.0.227.x86_64.release_5H1P8.rpm
[root@master tmp]# pstcli -d 192.168.1.40 -u admin -p P@ssw0rd! -session
cli> host show -sort name+ -limit 3
 #  |                  id                  |            name             |   description   | os_type | host_group.name
----+--------------------------------------+-----------------------------+-----------------+---------+-----------------
  1 | 37e0b151-e866-4b69-854c-0682324bdce7 | csi-node-node1-192.168.1.21 | k8s node: node1 | Linux   |
  2 | cddbf404-e7de-41b5-8252-c5bfaebe9373 | csi-node-node2-192.168.1.22 | k8s node: node2 | Linux   |
  3 | e1431128-bc5b-4f9e-bf15-014fef2d84d7 | csi-node-node3-192.168.1.23 | k8s node: node3 | Linux   |


##SQL test
for i in {node1,node2,node3}; do ssh $i docker pull mcr.microsoft.com/mssql/rhel/server:2019-latest ; ssh $i docker images ; done
REPOSITORY                                         TAG           IMAGE ID       CREATED         SIZE
dellemc/csi-powerstore                             v1.4.0        8bddb808e6ec   7 days ago      253MB
k8s.gcr.io/kube-apiserver                          v1.21.2       106ff58d4308   9 days ago      126MB
k8s.gcr.io/kube-controller-manager                 v1.21.2       ae24db9aa2cc   9 days ago      120MB
k8s.gcr.io/kube-scheduler                          v1.21.2       f917b8c8f55b   9 days ago      50.6MB
k8s.gcr.io/kube-proxy                              v1.21.2       a6ebd1c1ad98   9 days ago      131MB
mcr.microsoft.com/mssql/rhel/server                2019-latest   31312494c1b6   3 weeks ago     1.54GB
quay.io/coreos/flannel                             v0.14.0       8522d622299c   5 weeks ago     67.9MB
k8s.gcr.io/sig-storage/csi-provisioner             v2.2.1        b93fb1bfc551   6 weeks ago     56.4MB
k8s.gcr.io/sig-storage/csi-attacher                v3.2.1        6de272f18137   6 weeks ago     53.5MB
k8s.gcr.io/sig-storage/csi-resizer                 v1.2.0        0aa9629e1508   7 weeks ago     54MB
k8s.gcr.io/sig-storage/csi-node-driver-registrar   v2.2.0        8e5a15e16dca   8 weeks ago     18.7MB
k8s.gcr.io/pause                                   3.4.1         0f8457a4c2ec   5 months ago    683kB
k8s.gcr.io/coredns/coredns                         v1.8.0        296a6d5035e2   8 months ago    42.5MB
k8s.gcr.io/etcd                                    3.4.13-0      0369cf4303ff   10 months ago   253MB


[root@master tmp]# kubectl create secret generic mssql --from-literal=SA_PASSWORD="P@ssw0rd!"
secret/mssql created
[root@master tmp]# kubectl get secrets | grep -i mssql
mssql                               Opaque                                1      26s

[root@master tmp]# mkdir sql
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/pvc.yaml -O /tmp/sql/pvc.yaml
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/sql.yaml -O /tmp/sql/sql.yaml
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/CSNoIndex.sql -O sql/CSNoIndex.sql
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/CSIndex.sql -O sql/CSIndex.sql
[root@master tmp]# vim sql/pvc.yaml
[root@master tmp]# kubectl create -f sql/pvc.yaml
persistentvolumeclaim/mssql-data created
persistentvolumeclaim/mssql-data2 created
persistentvolumeclaim/mssql-log2 created
[root@master tmp]# kubectl get pvc
NAME          STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Bound    csi-115a96149c   10Gi       RWO            powerstore-xfs   5s
mssql-data2   Bound    csi-3962f2348e   5Gi        RWO            powerstore-xfs   5s
mssql-log2    Bound    csi-1b60e606af   2Gi        RWO            powerstore-xfs   5s
[root@master tmp]# kubectl get pv
NAME             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                        STORAGECLASS     REASON   AGE
csi-115a96149c   10Gi       RWO            Delete           Bound    csi-powerstore/mssql-data    powerstore-xfs            7s
csi-1b60e606af   2Gi        RWO            Delete           Bound    csi-powerstore/mssql-log2    powerstore-xfs            7s
csi-3962f2348e   5Gi        RWO            Delete           Bound    csi-powerstore/mssql-data2   powerstore-xfs            7s
[root@master tmp]# kubectl describe pvc mssql-data
Name:          mssql-data
Namespace:     csi-powerstore
StorageClass:  powerstore-xfs
Status:        Bound
Volume:        csi-115a96149c
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-class: powerstore-xfs
               volume.beta.kubernetes.io/storage-provisioner: csi-powerstore.dellemc.com
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      10Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       <none>
Events:
  Type    Reason                 Age                From                                                                                                   Message
  ----    ------                 ----               ----                                                                                                   -------
  Normal  ExternalProvisioning   23s (x2 over 23s)  persistentvolume-controller                                                                            waiting for a volume to be created, either by external provisioner "csi-powerstore.dellemc.com" or manually created by system administrator
  Normal  Provisioning           22s (x2 over 23s)  csi-powerstore.dellemc.com_powerstore-controller-74c75cb64-rv79g_90c3bcdf-4b8f-407a-9f51-32dd58799852  External provisioner is provisioning volume for claim "csi-powerstore/mssql-data"
  Normal  ProvisioningSucceeded  22s (x2 over 22s)  csi-powerstore.dellemc.com_powerstore-controller-74c75cb64-rv79g_90c3bcdf-4b8f-407a-9f51-32dd58799852  Successfully provisioned volume csi-115a96149c

[root@master tmp]# pstcli -u admin -p P@ssw0rd! -d 192.168.1.40 -session
cli> volume show -sort name+ -limit 3
 #  |                  id                  |      name      |  type   |                 wwn                 |         size         | protection_policy.na~
----+--------------------------------------+----------------+---------+-------------------------------------+----------------------+-----------------------
  1 | 4bdb1237-6502-470c-9671-b84495a02426 | csi-115a96149c | Primary | naa.68ccf0980008ba33c40ecd501d0108~ | 10737418240 (10.00G) |
  2 | 053058e6-b839-4542-87b4-b7fd4240a0cc | csi-1b60e606af | Primary | naa.68ccf09800523f509ddeca42e919df~ | 2147483648 (2.00G)   |
  3 | 37676fa0-f7dd-4d2a-835b-ad935baa798d | csi-3962f2348e | Primary | naa.68ccf09800fa3ff3516f641b726594~ | 5368709120 (5.00G)   |
cli> job show -sort resource_name+ -limit 10
 #  |                  id                  | resourc~ |    resource_name     | description_l~ |   state   |   start_time   |    end_time    | progress_pe~
----+--------------------------------------+----------+----------------------+----------------+-----------+----------------+----------------+--------------
  1 | 38aab931-340a-4c0f-b5c5-f1d132c72f2e | volume   | csi-115a96149c       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  2 | 73af6083-92d1-450d-98a8-d9f3e6569a27 | volume   | csi-115a96149c       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  3 | 404d9bfe-4ecc-4f8b-824f-9ca629123ebd | volume   | csi-1b60e606af       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  4 | 4df24f6a-1246-4db8-81e4-df160b437747 | volume   | csi-1b60e606af       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  5 | a0f3e08e-d157-442d-a72f-9f02ea571fe6 | volume   | csi-3962f2348e       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  6 | df706671-dd43-4162-8e96-1c835b9914be | volume   | csi-3962f2348e       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  7 | f43d9ebc-624b-4302-b945-d95324f2dd13 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  8 | 72341901-c28d-497b-8140-8db83f42a05a | host     | csi-node-node1.loca~ | Create host.   | COMPLETED | 06/25/2021 07~ | 06/25/2021 07~ |          100
  9 | 017510df-c156-4310-a3e4-c8aadd4abf97 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
 10 | 9da311b1-fab8-4523-9869-35dfba779b23 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
cli>

cli> exit

[root@master tmp]# kubectl describe pv csi-115a96149c
Name:              csi-115a96149c
Labels:            <none>
Annotations:       pv.kubernetes.io/provisioned-by: csi-powerstore.dellemc.com
Finalizers:        [kubernetes.io/pv-protection]
StorageClass:      powerstore-xfs
Status:            Bound
Claim:             csi-powerstore/mssql-data
Reclaim Policy:    Delete
Access Modes:      RWO
VolumeMode:        Filesystem
Capacity:          10Gi
Node Affinity:
  Required Terms:
    Term 0:        csi-powerstore.dellemc.com/192.168.1.40-iscsi in [true]
                   csi-powerstore.dellemc.com/192.168.1.40-nfs in [true]
Message:
Source:
    Type:              CSI (a Container Storage Interface (CSI) volume source)
    Driver:            csi-powerstore.dellemc.com
    FSType:            xfs
    VolumeHandle:      4bdb1237-6502-470c-9671-b84495a02426/PSec370360bc60/scsi
    ReadOnly:          false
    VolumeAttributes:      FsType=xfs
                           Name=csi-115a96149c
                           Protocol=scsi
                           arrayID=PSec370360bc60
                           csi.storage.k8s.io/pv/name=csi-115a96149c
                           csi.storage.k8s.io/pvc/name=mssql-data
                           csi.storage.k8s.io/pvc/namespace=csi-powerstore
                           storage.kubernetes.io/csiProvisionerIdentity=1624625930028-8081-csi-powerstore.dellemc.com
Events:                <none>
[root@master tmp]#

[root@master tmp]# vim sql/sql.yaml
[root@master tmp]# kubectl create -f sql/sql.yaml
deployment.apps/mssql-deployment created
service/mssql-deployment created

[root@master tmp]# kubectl get pods
NAME                                    READY   STATUS    RESTARTS   AGE
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          33s
powerstore-controller-74c75cb64-pnjgm   4/4     Running   4          91m
powerstore-controller-74c75cb64-rv79g   4/4     Running   5          91m
powerstore-controller-74c75cb64-zjqnp   4/4     Running   4          91m
powerstore-node-794fz                   2/2     Running   2          91m
powerstore-node-bzrxg                   2/2     Running   2          91m
powerstore-node-frl67                   2/2     Running   2          91m
[root@master tmp]# kubectl get services
NAME               TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
mssql-deployment   NodePort   10.108.193.217   <none>        1433:31690/TCP   41s


[root@master tmp]# kubectl logs -f mssql-deployment-5f4cd94964-hs774
...
2021-06-25 13:27:06.66 spid11s     Clearing tempdb database.
2021-06-25 13:27:07.32 spid11s     [2]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1.
2021-06-25 13:27:07.32 spid11s     Starting up database 'tempdb'.
2021-06-25 13:27:07.60 spid11s     The tempdb database has 1 data file(s).
2021-06-25 13:27:07.61 spid36s     The Service Broker endpoint is in disabled or stopped state.
2021-06-25 13:27:07.62 spid36s     The Database Mirroring endpoint is in disabled or stopped state.
2021-06-25 13:27:07.66 spid36s     Service Broker manager has started.
2021-06-25 13:27:07.69 spid9s      Database 'msdb' running the upgrade step from version 902 to version 903.
2021-06-25 13:27:07.73 spid9s      Database 'msdb' running the upgrade step from version 903 to version 904.
2021-06-25 13:27:07.91 spid9s      Recovery is complete. This is an informational message only. No user action is required.
2021-06-25 13:27:07.94 spid39s     The default language (LCID 0) has been set for engine and full-text services.
2021-06-25 13:27:08.11 spid39s     The tempdb database has 2 data file(s).
2021-06-25 13:33:50.07 spid57      Attempting to load library 'xplog70.dll' into memory. This is an informational message only. No user action is required.
2021-06-25 13:33:50.13 spid57      Using 'xplog70.dll' version '2019.150.4138' to execute extended stored procedure 'xp_msver'. This is an informational message only; no user action is required.

[root@master tmp]# kubectl get pods -o wide | grep mssql -B2
NAME                                    READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          10m    10.244.1.6     node1.local   <none>           <none>

[root@master sql]# kubectl cp /tmp/sql/ mssql-deployment-5f4cd94964-hs774:/tmp/

[root@master tmp]# kubectl exec -it mssql-deployment-5f4cd94964-hs774 bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -Q "select @@version"
                                                                                                                                                             
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Microsoft SQL Server 2019 (RTM-CU11) (KB5003249) - 15.0.4138.2 (X64)
        May 27 2021 17:34:14
        Copyright (C) 2019 Microsoft Corporation
        Developer Edition (64-bit) on Linux (Red Hat Enterprise Linux 8.3 (Ootpa)) <X64>                                                                     

(1 rows affected)

bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd!
1> select @@VERSION as Version, SERVERPROPERTY('ServerName') as 'Container ID', SERVERPROPERTY('Edition') as Edition;
2> go
1> create database [TestDB] CONTAINMENT = NONE on primary ( NAME = N'TestDB', FILENAME = N'/var/opt/mssql/data2/TestDB.mdf', SIZE = 4GB, FILEGROWTH = 1024KB ) LOG ON ( NAME = N'TestDB_log', FILENAME = N'/var/opt/mssql/log2/TestDB_log.ldf', SIZE = 1GB, FILEGROWTH = 10% )
2> go
1> use TestDB
2> CREATE TABLE Inventory (id INT, name NVARCHAR(50), quantity INT)
3> INSERT INTO Inventory VALUES (1, 'banana', 150); INSERT INTO Inventory VALUES (2, 'orange', 154);
4> go
Changed database context to 'TestDB'.

(1 rows affected)

(1 rows affected)
1> SELECT * FROM Inventory WHERE quantity > 152;
2> go
id          name                                               quantity
----------- -------------------------------------------------- -----------
          2 orange                                                     154

(1 rows affected)
1>exit

//The aggregation query over 5 million rows with SQL optimizer option to ignore columnstore index
SELECT SUM(Price), AVG(Price) FROM Orders;
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -i /tmp/sql/CSNoIndex.sql
Changed database context to 'SampleDB'.
DBCC execution completed. If DBCC printed error messages, contact your system administrator.

----------- -----------
   50000000          10
Not using columnstore index: 960 ms

----------- -----------
   50000000          10
Not using columnstore index: 826 ms

----------- -----------
   50000000          10
Not using columnstore index: 822 ms

----------- -----------
   50000000          10
Not using columnstore index: 701 ms

----------- -----------
   50000000          10
Not using columnstore index: 716 ms

----------- -----------
   50000000          10
Not using columnstore index: 713 ms

----------- -----------
   50000000          10
Not using columnstore index: 885 ms

----------- -----------
   50000000          10
Not using columnstore index: 766 ms

----------- -----------
   50000000          10
Not using columnstore index: 789 ms

----------- -----------
   50000000          10
Not using columnstore index: 830 ms

//The aggregation query over 5 million rows
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -i /tmp/sql/CSIndex.sql
Changed database context to 'SampleDB'.
DBCC execution completed. If DBCC printed error messages, contact your system administrator.

----------- -----------
   50000000          10
Using nonclustered columnstore index: 121 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 9 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 5 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 8 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 7 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 8 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms
bash-4.4$


bash-4.4$ cd /var/opt/mssql/
bash-4.4$ ls -l
total 8
drwxr-sr-x. 2 mssql 10001 4096 Jun 25 13:27 data
drwxrwsr-x. 2 root  10001   24 Jun 25 13:40 data2
drwxr-sr-x. 2 mssql 10001 4096 Jun 25 13:40 log
drwxrwsr-x. 2 root  10001   28 Jun 25 13:40 log2
drwxr-sr-x. 2 mssql 10001   25 Jun 25 13:27 secrets
bash-4.4$ ls -hl data2/
total 4.1G
-rw-r-----. 1 mssql 10001 4.0G Jun 25 13:40 TestDB.mdf
bash-4.4$ ls -hl log2/
total 1.0G
-rw-r-----. 1 mssql 10001 1.0G Jun 25 13:42 TestDB_log.ldf
bash-4.4$ ls -hl data
total 735M
-rw-r-----. 1 mssql 10001  256 Jun 25 13:27 Entropy.bin
-rw-r-----. 1 mssql 10001 328M Jun 25 16:19 SampleDB.mdf
-rw-r-----. 1 mssql 10001 328M Jun 25 16:38 SampleDB_log.ldf
bash-4.4$ df -H
Filesystem                                                                                                     Size  Used Avail Use% Mounted on
overlay                                                                                                         67G  5.9G   61G   9% /
tmpfs                                                                                                           68M     0   68M   0% /dev
tmpfs                                                                                                          3.1G     0  3.1G   0% /sys/fs/cgroup
/dev/mapper/cl-root                                                                                             67G  5.9G   61G   9% /etc/hosts
shm                                                                                                             68M     0   68M   0% /dev/shm
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-115a96149c/globalmount/4bdb1237-6502-470c-9671-b84495a02426   11G  119M   11G   2% /var/opt/mssql
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-1b60e606af/globalmount/053058e6-b839-4542-87b4-b7fd4240a0cc  2.2G  1.2G  1.1G  52% /var/opt/mssql/log2
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-3962f2348e/globalmount/37676fa0-f7dd-4d2a-835b-ad935baa798d  5.4G  4.4G  1.1G  81% /var/opt/mssql/data2
tmpfs                                                                                                          3.1G   13k  3.1G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                                                                                                          3.1G     0  3.1G   0% /proc/acpi
tmpfs                                                                                                          3.1G     0  3.1G   0% /proc/scsi
tmpfs                                                                                                          3.1G     0  3.1G   0% /sys/firmware
bash-4.4$
bash-4.4$ exit
exit
[root@master tmp]#

#install Azure Data Studio
1)https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15
2)check witch node and ports run sql server
[root@master tmp]# kubectl get services -o wide
NAME               TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE   SELECTOR
mssql-deployment   NodePort   10.108.193.217   <none>        1433:31690/TCP   22m   app=mssql

[root@master tmp]# kubectl get pods -o wide | grep mssql -B2
NAME                                    READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          28m    10.244.1.6     node1.local   <none>           <none>

3)check sql listen port
[root@master tmp]# ssh node1
Last login: Fri Jun 25 07:18:58 2021 from 192.168.1.20
[root@node1 ~]# netstat -ntpl | grep 31690
tcp        0      0 0.0.0.0:31690           0.0.0.0:*               LISTEN      2740/kube-proxy

4)install GUI Azure Data Studio on client,
Server:    192.168.1.21,31690
User Name: sa
Password:  P@ssw0rd!
5)test db scripts...

#use root config sql container
1)
[root@node1 ~]# docker ps -l
CONTAINER ID   IMAGE          COMMAND                  CREATED       STATUS       PORTS     NAMES
efcf6d8e2a05   31312494c1b6   "/opt/mssql/bin/perm…"   7 hours ago   Up 7 hours             k8s_mssql_mssql-deployment-5f4cd94964-hdbrd_csi-powerstore_526d50ff-b729-49d4-ae20-d1caa22ae68c_0
[root@node1 ~]# docker exec -u 0 -it efcf6d8e2a05 bash
[root@mssqlinst /]# id
uid=0(root) gid=0(root) groups=0(root),10001
[root@mssqlinst /]# /opt/mssql/bin/
checkinstallextensibility.sh  generate-sql-dump.sh          mssql-conf                    setnetbr
compress-dump.sh              handle-crash.sh               paldumper                     sqlservr
crash-support-functions.sh    launchpadd                    permissions_check.sh
[root@mssqlinst /]# /opt/mssql/bin/mssql-conf list
control.alternatewritethrough                           Enable optimized write through flush for O_DSYNC requests
control.hestacksize                                     Host extension stack size in KB
control.stoponguestprocessfault                         Stops the process if any guest process reports unhandled exception
control.writethrough                                    Use O_DSYNC for file flag write through requests
[root@mssqlinst /]# /opt/mssql/bin/mssql-conf setup
The license terms for this product can be found in
/usr/share/doc/mssql-server or downloaded from:
https://go.microsoft.com/fwlink/?LinkId=2104294&clcid=0x409

The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010&clcid=0x409

Configuring SQL Server...

Initial setup of Microsoft SQL Server failed. Please consult the ERRORLOG
in /var/opt/mssql/log for more information.

2)
recommand use Environment variables:
https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-configure-environment-variables?view=sql-server-ver15
https://www.sqlshack.com/configure-sql-server-2017-linux-mssql-conf-available-tools/

#delete sql pods and pvc
[root@master tmp]# kubectl delete -f sql/sql.yaml
deployment.apps "mssql-deployment" deleted
service "mssql-deployment" deleted
[root@master tmp]# kubectl delete -f sql/pvc.yaml
persistentvolumeclaim "mssql-data" deleted
persistentvolumeclaim "mssql-data2" deleted
persistentvolumeclaim "mssql-log2" deleted
[root@master tmp]# kubectl get pvc
No resources found in csi-powerstore namespace.
[root@master tmp]# kubectl get pv
No resources found

cli> job show -sort start_time- -limit 30
 #  |                  id                  | reso~ | resource_n~ |         description_l10n         | state  | start_t~ | end_time | progre~
----+--------------------------------------+-------+-------------+----------------------------------+--------+----------+----------+---------
  1 | 99b33d26-44e2-449b-924e-e351d7624ac7 |       |             | Detaching                        | PENDI~ |          |          |       0
  2 | 9e9eda82-78b4-4252-8458-15741c97aa14 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  3 | 2515482d-a5f4-4fd4-9f4f-d00d73c91be1 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  4 | dc81be97-656d-4991-bfeb-6484bc71d465 |       |             | Detaching                        | PENDI~ |          |          |       0
  5 | d3d3a464-34c0-4b56-b353-0ce16d28049d |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  6 | c92cf2bc-5648-41bf-b36d-1c8457854873 |       |             | Detaching                        | PENDI~ |          |          |       0
  7 | 2c028595-ff4a-4492-9ef1-67a8ae89aea0 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  8 | e46143cc-c234-4f53-8ed8-ec2c2a052aff |       |             | Detaching                        | PENDI~ |          |          |       0
  9 | 108027e2-2e28-4358-b2ea-bf9597e6da15 | volu~ | csi-115a96~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 10 | 84ee562d-f11a-4166-9733-506d352a84bd | volu~ | csi-1b60e6~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 11 | 5c92827c-4466-4849-9b75-a12f344e5b4b | volu~ | csi-3962f2~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 12 | 62f2d0ac-b74b-45c5-9567-0a05d903f97a |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 13 | 8995c7c0-0629-4e6c-9c50-8bc928037cfa |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 14 | 015bd3a6-13e9-427c-8834-4b6a5ad9ffff |       |             | Detaching Host 17aa8ad2-2da1-40~ | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 15 | 3811a07b-471b-4d2a-aa44-5b9f0f9acb34 | host  | csi-node-n~ | Detach volume from host.         | FAILED | 06/26/2~ | 06/26/2~ |     100
 16 | cb5b2d32-3047-459d-bacd-2ff69001c17a |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 17 | 92b07e18-a608-44c9-ab0c-30f939d7b74e |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 18 | db29653b-d98c-4de9-9a63-8176fe4d3c93 |       |             | Detaching Host 17aa8ad2-2da1-40~ | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 19 | 7a522a09-d2a3-4de6-aa16-94cbb26acf0d | host  | csi-node-n~ | Detach volume from host.         | FAILED | 06/26/2~ | 06/26/2~ |     100
 20 | c9d4c164-cacd-4e6b-ae23-a8dc425608e1 |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 21 | a4457590-faea-4c78-b29c-f0e6e2e74aa1 |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 22 | d0579ddd-9689-4aae-a430-6eacfa0d920c |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 23 | b607c34a-97d6-483c-ac1d-085ccfea700e |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 24 | 1492b383-fd10-44da-afa9-ff7c75dc9e0e |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 25 | 309abad2-31dd-4309-90a7-fa6bc807f4c7 |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 26 | 95b7915f-458d-483c-b39a-65a978227b18 |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 27 | 60e51fc7-df8e-4b3e-a3bd-1487747824ae |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 28 | 66b845a4-1a68-450c-8f6a-dc7474ca251c |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 29 | fdd2293a-8c50-461a-8a17-c2ec88599c84 |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 30 | 9cf226be-dc97-42f7-ac51-60c913b7dc9b |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
cli>



##SQL BDC Cluster Deployment
SQL Server 2019 Big Data Clusters
https://www.youtube.com/watch?v=syFE77B6d14

[root@master sql]# cat /etc/yum.conf
[main]
gpgcheck=1
installonly_limit=3
clean_requirements_on_remove=True
best=True
skip_if_unavailable=False
sslverify=false
[root@master sql]# yum module install -y python36

[root@master tmp]# useradd stack
[root@master tmp]# echo redhat | passwd stack --stdin
Changing password for user stack.
passwd: all authentication tokens updated successfully.
[root@master tmp]# echo "stack ALL=(root) NOPASSWD:ALL" | tee -a /etc/sudoers.d/stack
stack ALL=(root) NOPASSWD:ALL
[root@master tmp]# chmod 0440 /etc/sudoers.d/stack
[root@master tmp]# su - stack
[stack@master ~]$ sudo ls
[stack@master ~]$ yum install wget
[stack@master ~]$ wget --no-check-certificate https://packages.microsoft.com/keys/microsoft.asc
[stack@master ~]$ sudo rpm --import microsoft.asc
[stack@master ~]$ sudo curl -k -o /etc/yum.repos.d/mssql-server.repo https://packages.microsoft.com/config/rhel/8/prod.repo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   192  100   192    0     0    240      0 --:--:-- --:--:-- --:--:--   240
[stack@master ~]$ sudo cat /etc/yum.repos.d/mssql-server.repo
[packages-microsoft-com-prod]
name=packages-microsoft-com-prod
baseurl=https://packages.microsoft.com/rhel/8/prod/
enabled=1
gpgcheck=1
gpgkey=https://packages.microsoft.com/keys/microsoft.asc
[stack@master ~]$
[stack@master ~]$ sudo yum -y install azdata-cli
[stack@master ~]$ azdata --version
20.3.5

Build (20210609.2)

SQL Server 2019 (15.0.4138)

Legal docs and information: https://aka.ms/eula-azdata-en

Python (Linux) 3.6.8 (default, Mar 19 2021, 05:13:41)
[GCC 8.4.1 20200928 (Red Hat 8.4.1-1)]

Python location '/usr/bin/python3'


[stack@master ~]$ azdata bdc config list
The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010

The license terms for azdata can be viewed at:
https://aka.ms/eula-azdata-en

Do you accept the license terms? (y/n): y
[
  "aks-dev-test",
  "aks-dev-test-ha",
  "aro-dev-test",
  "aro-dev-test-ha",
  "kubeadm-dev-test",
  "kubeadm-prod",
  "openshift-dev-test",
  "openshift-prod"
]
[stack@master ~]$ azdata bdc config init --source kubeadm-dev-test --path custom
"Created configuration profile in custom"
[stack@master ~]$ vi custom/control.json
[stack@master ~]$ cat custom/control.json
{
    "apiVersion": "v1",
    "metadata": {
        "kind": "Cluster",
        "name": "mssql-cluster"
    },
    "spec": {
        "docker": {
            "registry": "mcr.microsoft.com",
            "repository": "mssql/bdc",
            "imageTag": "2019-CU9-ubuntu-16.04",
            "imagePullPolicy": "IfNotPresent"
        },
        "storage": {
            "data": {
                "className": "powerstore-xfs",
                "accessMode": "ReadWriteOnce",
                "size": "15Gi"
            },
            "logs": {
                "className": "powerstore-xfs",
                "accessMode": "ReadWriteOnce",
                "size": "10Gi"
            }
        },
        "endpoints": [
            {
                "name": "Controller",
                "serviceType": "NodePort",
                "port": 30080
            },
            {
                "name": "ServiceProxy",
                "serviceType": "NodePort",
                "port": 30777
            }
        ],
        "settings": {
            "controller": {
                "logs.rotation.size": "5000",
                "logs.rotation.days": "7"
            }
        }
    },
    "security": {}
}
[stack@master ~]$ grep -i memory custom/bdc.json
                    "spark-defaults-conf.spark.driver.memory": "1664m",
                    "spark-defaults-conf.spark.driver.memoryOverhead": "384",
                    "spark-defaults-conf.spark.executor.memory": "3712m",
                    "spark-defaults-conf.spark.executor.memoryOverhead": "384",
                    "yarn-site.yarn.nodemanager.resource.memory-mb": "6044",

[stack@master ~]$exit

[root@master tmp]# cp -a /home/stack/custom/ ./
[root@master tmp]# ls custom/
bdc.json  control.json
[root@master tmp]# vi custom/control.json
[root@master tmp]# azdata bdc create --config-profile custom --accept-eula yes
The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010

The license terms for SQL Server Big Data Cluster can be viewed at:
Enterprise: https://go.microsoft.com/fwlink/?linkid=2104292
Standard: https://go.microsoft.com/fwlink/?linkid=2104294
Developer: https://go.microsoft.com/fwlink/?linkid=2104079


Cluster deployment documentation can be viewed at:
https://aka.ms/bdc-deploy

Azdata username:admin
Azdata password:
Confirm Azdata password:

NOTE: Cluster creation can take a significant amount of time depending on
configuration, network speed, and the number of nodes in the cluster.

Starting cluster deployment.
Waiting for cluster controller to start.
...

[root@master tmp]# kubectl get pods -n mssql-cluster
[root@master tmp]# kubectl get pvc -n mssql-cluster -L app,plane,role,type

#check BDC status
azdata login -n mssql-cluster
azdata bdc endpoint list -o table
azdata bdc status show
azdata bdc control status show
azdata bdc sql status show

azdata bdc endpoint list -e sql-server-master
Azure Data Studio (launch GUI console, connect to bdc "xxxip,31433)
https://docs.microsoft.com/en-us/sql/big-data-cluster/connect-to-big-data-cluster?view=sql-server-ver15

#delete BDC
[root@master ~]# azdata bdc delete --name mssql-cluster --force

This operation will delete everything inside of cluster "mssql-cluster"
which includes the SQL Server containers, Kubernetes secrets and services,
and HDFS containers. Data stored on persistent volumes will get deleted if
the storage class reclaim policy is set to delete/recycle.
Namespace "mssql-cluster" and other objects created outside of Big Data Cluster
will not be dropped.

Deleting cluster 'mssql-cluster'.
Cluster 'mssql-cluster' deleted successfully.

#BDC Architecture
https://www.youtube.com/watch?v=GvOo-VV7-p4
Control Plane
  -Controller(SQL Server Master,Knox Gateway,Livy,HIVE,SQL Cluster Administration Portal,Grafana Dashboard,Kibana Dashboard)
Compute Plane
  -Compute Pool(SQL Server,SQL Server...)
Data Plane
  -Data Pool(SQL Server)
  -Storage Pool(SQL Server,Spark,HDFS)
App Pool
  -App Pool(ML Server,Job(SSIS(SQL Server Integration Services)),Web Apps)
HDFS (Hadoop Distributed File System)

#Load sample data
https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster
curl -o bootstrap-sample-db.sh "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/bootstrap-sample-db.sh"
chmod +x bootstrap-sample-db.sh
curl -o bootstrap-sample-db.sql "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/bootstrap-sample-db.sql"
./bootstrap-sample-db.sh <CLUSTER_NAMESPACE> <SQL_MASTER_ENDPOINT> <KNOX_ENDPOINT>

#BDC workshop lab
https://microsoft.github.io/sqlworkshops/
https://github.com/microsoft/sqlworkshops-bdc
https://aka.ms/bdc-samples

#BDC offline deployments

#BDC upgrade
azdata bdc upgrade -n mssql-cluster -t 2019-CU5-ubuntu-16.04 -r mcr.microsoft.com/mssql/bdc


issue:
1)
[root@master ~]# kubectl get pods -w -n csi-powerstore
NAME                                     READY   STATUS             RESTARTS   AGE
powerstore-controller-7bc455d5c7-bn2q9   5/5     Running            184        16h
powerstore-controller-7bc455d5c7-d4fjd   4/5     CrashLoopBackOff   184        16h
powerstore-controller-7bc455d5c7-vfvgt   4/5     CrashLoopBackOff   184        16h
powerstore-node-6hljh                    2/2     Running            0          16h
powerstore-node-jbbds                    2/2     Running            0          16h
powerstore-node-xg7wp                    2/2     Running            0          16h
powerstore-controller-7bc455d5c7-bn2q9   4/5     Error              184        16h
powerstore-controller-7bc455d5c7-bn2q9   4/5     CrashLoopBackOff   184        16h


[root@master dell-csi-helm-installer]# kubectl logs -f powerstore-controller-7bc455d5c7-bn2q9 -c snapshotter

I0322 10:11:27.729241       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
E0322 10:12:06.262052       1 leaderelection.go:325] error retrieving resource lock csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/csi-powerstore/leases/external-snapshotter-leader-csi-powerstore-dellemc-com": dial tcp 10.96.0.1:443: i/o timeout
I0322 10:12:06.262096       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
E0322 10:12:45.820648       1 leaderelection.go:325] error retrieving resource lock csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/csi-powerstore/leases/external-snapshotter-leader-csi-powerstore-dellemc-com": dial tcp 10.96.0.1:443: i/o timeout
I0322 10:12:45.820688       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
^C
-->fix
#only use 2 node test, master and node1!!!
check /etc/hosts right lines!!!
192.168.1.20 master master
192.168.1.21 node1  node1
[root@master ~]# kubectl get pods
NAME                                     READY   STATUS    RESTARTS   AGE
powerstore-controller-7bc455d5c7-5zm85   5/5     Running   112        9h
powerstore-controller-7bc455d5c7-kqlrv   5/5     Running   10         9h
powerstore-node-rskw4                    2/2     Running   4          9h
powerstore-node-z7l8b                    2/2     Running   4          9h

[root@master ~]# kubectl logs powerstore-controller-7bc455d5c7-kqlrv snapshotter
I0613 02:56:56.060628       1 leaderelection.go:273] successfully renewed lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
I0613 02:57:01.070784       1 leaderelection.go:273] successfully renewed lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com

[root@master ~]# kubectl logs powerstore-controller-7bc455d5c7-5zm85 snapshotter -f
I0613 02:58:49.876381       1 leaderelection.go:346] lock is held by powerstore-controller-7bc455d5c7-kqlrv and has not yet expired
I0613 02:58:49.876398       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com

2)csi 1.4.0 driver install issue
[root@master dell-csi-helm-installer]# ./csi-install.sh --namespace csi-powerstore --values ./my-powerstore-settings.yaml
...
...
|- Verifying helm version                                           Success

------------------------------------------------------
> Verification Complete - Success
------------------------------------------------------
|
|- Installing Driver                                                Error: template: csi-powerstore/templates/controller.yaml:67:19: executing "csi-powerstore/templates/controller.yaml" at <.Values.replication.enabled>: nil pointer evaluating interface {}.enabled

------------------------------------------------------
Error: Helm operation failed, output can be found in /tmp/csi-install.127624.out. The failure should be examined, before proceeding. Additionally, running csi-uninstall.sh may be needed to clean up partial deployments.
Installation cannot continue
-->fix
#add "replication" to false!!!
[root@master dell-csi-helm-installer]# vim my-powerstore-settings.yaml
...
replication:
  enabled: false

3)
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-8xhgz driver | grep -i "error\|failed"
{"level":"error","msg":"iscsi initiators found on node","time":"2021-06-22T16:28:08.568003871Z"}
{"level":"error","msg":"failed to read initiator ports names: FC is not supported for this host","time":"2021-06-22T16:28:08.568096312Z"}
{"level":"error","msg":"FC was not found or filtered with FCPortsFilterFile","time":"2021-06-22T16:28:08.568120251Z"}
{"level":"error","msg":"Get \"https://192.168.1.30/api/rest/host?limit=1000\u0026offset=0\u0026order=name\u0026select=id%2Cname%2Cdescription%2Chost_group_id%2Cimport_host_system_id%2Cos_type%2Ctype%2Chost_initiators\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:08.619686872Z"}
{"level":"error","msg":"can't setup host on https://192.168.1.30/api/rest: Get \"https://192.168.1.30/api/rest/host?limit=1000\u0026offset=0\u0026order=name\u0026select=id%2Cname%2Cdescription%2Chost_group_id%2Cimport_host_system_id%2Cos_type%2Ctype%2Chost_initiators\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:08.619779977Z"}
{"level":"error","msg":"Get \"https://192.168.1.30/api/rest/ip_pool_address?order=id\u0026purposes=cs.%7BStorage_Iscsi_Target%7D\u0026select=address%2Cappliance_id%2Cid%2Cip_port_id%2Cip_port%28target_iqn%2C+id%29%2Cnetwork_id%2Cnode_id%2Cpurposes\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:09.493292411Z"}
{"level":"error","msg":"couldn't get targets from array: Get \"https://192.168.1.30/api/rest/ip_pool_address?order=id\u0026purposes=cs.%7BStorage_Iscsi_Target%7D\u0026select=address%2Cappliance_id%2Cid%2Cip_port_id%2Cip_port%28target_iqn%2C+id%29%2Cnetwork_id%2Cnode_id%2Cpurposes\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:09.493310476Z"}
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-685ff6cb4b-g95w6 attacher | grep -i "error\|failed"
I0622 16:28:08.972809       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.973742       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.975031       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.977185       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.978389       1 connection.go:186] GRPC error: <nil>
I0622 16:28:09.014772       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0622 16:28:17.654198       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-685ff6cb4b-g95w6 provisioner | grep -i "error\|failed"
I0622 16:28:08.348313       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.349898       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.351509       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.352395       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.369140       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
I0622 16:28:19.020188       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com

[root@master tmp]# kubectl get pvc
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Pending                                      powerstore-xfs   9s
mssql-data2   Pending                                      powerstore-xfs   9s
mssql-log2    Pending                                      powerstore-xfs   9s
[root@master tmp]# kubectl describe pvc mssql-data
...
Events:
  Type     Reason                Age                From                                                                                                    Message
  ----     ------                ----               ----                                                                                                    -------
  Normal   Provisioning          14s (x5 over 27s)  csi-powerstore.dellemc.com_powerstore-controller-685ff6cb4b-rkk2q_72dc4dfb-a968-444c-9a81-de775162c97a  External provisioner is provisioning volume for claim "default/mssql-data"
  Warning  ProvisioningFailed    14s (x5 over 27s)  csi-powerstore.dellemc.com_powerstore-controller-685ff6cb4b-rkk2q_72dc4dfb-a968-444c-9a81-de775162c97a  failed to provision volume with StorageClass "powerstore-xfs": rpc error: code = Internal desc = Array IP's been provided, however it is not supported in current version. Configure you storage classes according to the documentation
  Normal   ExternalProvisioning  13s (x4 over 29s)  persistentvolume-controller                                                                             waiting for a volume to be created, either by external provisioner "csi-powerstore.dellemc.com" or manually created by system administrator

-->fix
use 192.168.1.40 firmware with sp4 normal!!!

[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 
driver     registrar
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 driver | grep -i "error\|failed"
{"level":"error","msg":"iscsi initiators found on node","time":"2021-06-25T11:55:29.025240969Z"}
{"level":"error","msg":"failed to read initiator ports names: FC is not supported for this host","time":"2021-06-25T11:55:29.025326146Z"}
{"level":"error","msg":"FC was not found or filtered with FCPortsFilterFile","time":"2021-06-25T11:55:29.02536739Z"}
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 registrar | grep -i "error\|failed"
I0625 11:56:23.245146       1 connection.go:186] GRPC error: <nil>
I0625 11:56:23.720754       1 main.go:90] Received NotifyRegistrationStatus call: &RegistrationStatus{PluginRegistered:true,Error:,}
[root@master dell-csi-helm-installer]#

[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm
attacher     driver       provisioner  resizer
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm attacher | grep -i "error\|failed"
I0625 11:57:38.984501       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.985615       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.987002       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.988187       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.989306       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.033355       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0625 11:57:47.666299       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0625 11:57:58.319250       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm driver | grep -i "error\|failed"
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm provisioner |grep -i "error\|failed"
I0625 11:57:38.903729       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.905305       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.906920       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.908222       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.945069       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
I0625 11:57:49.593829       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm resizer |grep -i "error\|failed"
I0625 11:57:39.393998       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.395062       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.396430       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.398074       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.417296       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-resizer-csi-powerstore-dellemc-com
I0625 11:57:48.054355       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-resizer-csi-powerstore-dellemc-com

[root@master ~]# kubectl get pvc
NAME          STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Bound    csi-115a96149c   10Gi       RWO            powerstore-xfs   100m
mssql-data2   Bound    csi-3962f2348e   5Gi        RWO            powerstore-xfs   100m
mssql-log2    Bound    csi-1b60e606af   2Gi        RWO            powerstore-xfs   100m
[root@master ~]# kubectl describe pvc mssql-data
Name:          mssql-data
Namespace:     csi-powerstore
StorageClass:  powerstore-xfs
Status:        Bound
Volume:        csi-115a96149c
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-class: powerstore-xfs
               volume.beta.kubernetes.io/storage-provisioner: csi-powerstore.dellemc.com
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      10Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       mssql-deployment-5f4cd94964-hs774
Events:        <none>

4)curl issue
cluster1 with firmware 1.0.0.0.4.038 have issue.
cluster2 with firmware 1.0.4.0.5.003 normal !!!
rhel8.2 and centos 8.4 same issue, will rhel7 curl is normal !!!

[root@master ~]#  curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.30/api/rest/cluster?select=*
*   Trying 192.168.1.30...
* TCP_NODELAY set
* Connected to 192.168.1.30 (192.168.1.30) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS alert, bad certificate (554):
* error:0D0E20DD:asn1 encoding routines:c2i_ibuf:illegal padding
* Closing connection 0
curl: (35) error:0D0E20DD:asn1 encoding routines:c2i_ibuf:illegal padding
[root@master ~]#

[root@master ~]#  curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=*
*   Trying 192.168.1.40...
* TCP_NODELAY set
* Connected to 192.168.1.40 (192.168.1.40) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server did not agree to a protocol
* Server certificate:
*  subject: C=US + O=Dell + L=Hopkinton + OU=PowerStore + ST=Massachusetts + CN=ManagementHTTP.PSec370360bc60
*  start date: Jun 21 03:11:23 2021 GMT
*  expire date: Jun 20 03:11:23 2026 GMT
*  issuer: C=US; ST=MA; O=Dell EMC; CN=Dell EMC PowerStore CA YZ4USM9E
*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Host: 192.168.1.40
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.61.1
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: IhJC/04NmCqSmLQxvgyVSsnebB8A/0qHDa+K3LkhXJY=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=dae0401ca49609c01f6102c5f9fa5191; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.40 left intact
[{"id":"0","global_id":"PSec370360bc60","name":"POD3-Cluster2","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.40","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.40","compatibility_level":1,"state_l10n":"Configured"}]
[root@master ~]#


[root@linux17 ~]# curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.30/api/rest/cluster?select=*
* About to connect() to 192.168.1.30 port 443 (#0)
*   Trying 192.168.1.30...
* Connected to 192.168.1.30 (192.168.1.30) port 443 (#0)
* Initializing NSS with certpath: sql:/etc/pki/nssdb
* skipping SSL peer certificate verification
* NSS: client certificate not found (nickname not specified)
* SSL connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
* Server certificate:
*       subject: C=US+O=Dell+L=Hopkinton+OU=PowerStore+ST=Massachusetts+CN=ManagementHTTP.PS04e694d0c442
*       start date: Jun 21 03:09:45 2021 GMT
*       expire date: Jun 20 03:09:45 2026 GMT
*       common name: ManagementHTTP.PS04e694d0c442
*       issuer: CN=Dell EMC PowerStore CA ZTUGYPNK,O=Dell EMC,ST=MA,C=US
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.29.0
> Host: 192.168.1.30
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: IrfmhMXOORUkBZ0RGzAPV1AK+O07s5uRbULnslrRr8s=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=b5557d07ba1347883106689382b97a74; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.30 left intact
[{"id":"0","global_id":"PS04e694d0c442","name":"POD3-Cluster1","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.30","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.30","compatibility_level":1,"state_l10n":"Configured"}]
[root@linux17 ~]#

-->fix
192.168.1.30 powerstore firmware 1.0.0.0.4.038 have reset api issue!!! (rhel7 use curl check normal, but centos 8.4 or rhel 8.2 have this issue!)
192.168.1.40 powerstore firmware sp4 1.0.4.0.5.003 can use normal!!!

[root@master ~]# curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=*
*   Trying 192.168.1.40...
* TCP_NODELAY set
* Connected to 192.168.1.40 (192.168.1.40) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server did not agree to a protocol
* Server certificate:
*  subject: C=US + O=Dell + L=Hopkinton + OU=PowerStore + ST=Massachusetts + CN=ManagementHTTP.PSec370360bc60
*  start date: Jun 21 03:11:23 2021 GMT
*  expire date: Jun 20 03:11:23 2026 GMT
*  issuer: C=US; ST=MA; O=Dell EMC; CN=Dell EMC PowerStore CA YZ4USM9E
*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Host: 192.168.1.40
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.61.1
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: cLdyIkHyN9a/gVqfpZPeHzNLTcuEMj1C55WLJqAEy9Q=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=9ccf86b61424b93b3f57e891f6a3a95d; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.40 left intact
[{"id":"0","global_id":"PSec370360bc60","name":"POD3-Cluster2","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.40","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.40","compatibility_level":1,"state_l10n":"Configured"}]

5)azdata install issue
[root@master sql]# yum list azdata-cli
packages-microsoft-com-prod                                                                                                  0.0  B/s |   0  B     00:00
Errors during downloading metadata for repository 'packages-microsoft-com-prod':
  - Curl error (60): Peer certificate cannot be authenticated with given CA certificates for https://packages.microsoft.com/rhel/8/prod/repodata/repomd.xml [SSL certificate problem: self signed certificate in certificate chain]
Error: Failed to download metadata for repo 'packages-microsoft-com-prod': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried

-->fix
add "sslverify=false" to /etc/yum.conf
[root@master sql]# cat /etc/yum.conf
[main]
gpgcheck=1
installonly_limit=3
clean_requirements_on_remove=True
best=True
skip_if_unavailable=False
sslverify=false

[root@master sql]# yum list azdata-cli
packages-microsoft-com-prod                                                                                                  6.2 MB/s | 7.5 MB     00:01
Last metadata expiration check: 0:00:19 ago on Fri 25 Jun 2021 11:52:48 PM EDT.
Available Packages
azdata-cli.x86_64                                                  20.3.5-1.el7                                                   packages-microsoft-com-prod
