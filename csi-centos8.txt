====CSI v2.3.0  06/22/2022 update
https://dell.github.io/csm-docs/docs/csidriver/release/powerstore/
-Support Volume Group Snapshots.
-Removed beta volumesnapshotclass sample files.
-Support Configurable Volume Attributes.
-Added support for Kubernetes 1.24.
-Added support for OpenShift 4.10.
-Added support for NVMe/FC protocol.

====CSI v2.0.0 10/01/2021 update
Release Notes - CSI PowerStore v2.0.0
New Features/Changes
-Added support for Kubernetes v1.22.
-Added support for OpenShift 4.8.
-Added the ability to change log level and log format of CSI driver and change them dynamically.
-Added the ability to configure kubelet directory path.
-Added the ability to enable/disable installation of resizer sidecar with driver installation.
-Added the ability to enable/disable installation of snapshotter sidecar with driver installation.
-Added support for consistent config parameters across CSI drivers.

====CSI v1.4.0 06/25/2021 update
Supported Platforms and Support Kubernetes version!!!
https://dell.github.io/storage-plugin-docs/docs/dell-csi-driver/

Release Notes - CSI PowerStore v1.4.0 (06/18/2021)
New Features/Changes
-Added support for Kubernetes v1.21
-Added support for OpenShift 4.7 with RHEL and CoreOS worker nodes
-Added support for SLES 15.2 and RHEL 8.4 as a host operating system
-Added support for enabling root-squashing for NFS shares
-Added support for disabling snapshot feature during installation
-Added the ability to configure nasName per Storage Class
-Refactored configuration files to use more generic naming


Centos 8.4 or RHEL 8.4
Note:
Kubernetes cannot work with Podman (which is now the default container engine for both RHEL and CentOS).
youll need to install the docker engine. !!!

https://learn-k8s-from-scratch.readthedocs.io/en/latest/k8s-install/kubeadm.html

[root@master ~]# cat /etc/centos-release
CentOS Linux release 8.4.2105
[root@master ~]# uname -a
Linux master.local 4.18.0-305.3.1.el8.x86_64 #1 SMP Tue Jun 1 16:14:33 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
...
...
[root@master ~]# modprobe br_netfilter
[root@master ~]# lsmod |grep -i netfilter
br_netfilter           24576  0
bridge                192512  1 br_netfilter
[root@master ~]# cat > /etc/sysctl.d/k8s.conf <<EOF
> net.bridge.bridge-nf-call-ip6tables = 1
> net.bridge.bridge-nf-call-iptables = 1
> net.ipv4.ip_forward = 1
> EOF
[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1

[root@master ~]# cat /etc/hosts
192.168.1.20    master.local    master
192.168.1.21    node1.local     node1
192.168.1.22    node2.local     node2
192.168.1.23    node3.local     node3

[root@master ~]# cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 192.168.1.50

#install docker on master
   45  yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion git vim net-tools wget iproute-tc jq
   49  yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
   50  ls /etc/yum.repos.d/
   52  yum makecache
   53  yum list docker-ce | sort -r
   54  yum -y install docker-ce
   
   #https://upcloud.com/resources/tutorials/install-kubernetes-cluster-centos-8
   echo '{
     "exec-opts": ["native.cgroupdriver=systemd"]
   }' > /etc/docker/daemon.json
   cat /etc/docker/daemon.json
   {
     "exec-opts": ["native.cgroupdriver=systemd"]
   }
   systemctl restart docker
   
   55  systemctl enable --now docker
   57  systemctl status docker
   58  docker --version
   Docker version 20.10.7, build f0df350
   59  docker info

#clone master to node1--3

ssh-keygen -t rsa
for i in {master,node1,node2,node3}; do ssh-copy-id $i ; done
cat ~/.ssh/authorized_keys
cat ~/.ssh/id_rsa.pub
for i in {master,node1,node2,node3}; do ssh $i sed -i.bak '/swap/s/^/#/' /etc/fstab ; ssh $i swapoff -a; ssh $i free; done
for i in {master,node1,node2,node3}; do ssh $i setenforce 0 ; ssh $i sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config ; ssh $i getenforce ; done
for i in {node1,node2,node3}; do scp /etc/resolv.conf  $i:/etc/resolv.conf; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i cat /sys/class/dmi/id/product_uuid; done

#if node missing /etc/machine-id       //machine-id need use for kubelet service!!!
systemd-machine-id-setup

[root@master ~]# for i in {node1,node2,node3}; do ssh $i modprobe br_netfilter ; scp /etc/sysctl.d/k8s.conf $i:/etc/sysctl.d/k8s.conf; ssh $i sysctl -p /etc/sysctl.d/k8s.conf ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i systemctl disable firewalld ;  ssh $i systemctl stop firewalld ; done

vi /etc/yum.repos.d/kubernetes.repo
[root@master ~]# cat /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl

[root@master ~]# for i in {node1,node2,node3}; do scp /etc/yum.repos.d/kubernetes.repo $i:/etc/yum.repos.d/kubernetes.repo ; ssh $i yum repolist ; done
[root@master ~]# yum list --showduplicates kubeadm --disableexcludes=kubernetes | sort -r
#csi v1.4.0 support kubernetes 1.21
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes ; done
#csi v1.3.0 use kubectl 1.20
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet-1.20.8-0 kubeadm-1.20.8-0 kubectl-1.20.8-0 --disableexcludes=kubernetes ; done

#rhel8 can't use podman for kubernetes!!!
{
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum module install -y container-tools:2.0  ; done
[root@master ~]# grep -v "^#\|^$" /etc/containers/registries.conf
[registries.search]
registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io']
[registries.insecure]
registries = []
[registries.block]
registries = []
[root@master ~]# podman -v
podman version 1.6.4
[root@master ~]# podman info
host:
  BuildahVersion: 1.12.0-dev
  CgroupVersion: v1
  Conmon:
    package: conmon-2.0.15-1.module_el8.3.0+479+69e2ae26.x86_64
    path: /usr/bin/conmon
    version: 'conmon version 2.0.15, commit: 0198f57f29209da30f765318dda9328bac6a5e07'
  Distribution:
    distribution: '"centos"'
    version: "8"
  MemFree: 6980251648
  MemTotal: 8144797696
  OCIRuntime:
    name: runc
    package: runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64
    path: /usr/bin/runc
    version: 'runc version spec: 1.0.1-dev'
  SwapFree: 0
  SwapTotal: 0
  arch: amd64
  cpus: 2
  eventlogger: journald
  hostname: master
  kernel: 4.18.0-240.el8.x86_64
  os: linux
  rootless: false
  uptime: 2h 13m 16.45s (Approximately 0.08 days)
registries:
  blocked: null
  insecure: null
  search:
  - registry.access.redhat.com
  - registry.redhat.io
  - docker.io
store:
  ConfigFile: /etc/containers/storage.conf
  ContainerStore:
    number: 0
  GraphDriverName: overlay
  GraphOptions: {}
  GraphRoot: /var/lib/containers/storage
  GraphStatus:
    Backing Filesystem: xfs
    Native Overlay Diff: "true"
    Supports d_type: "true"
    Using metacopy: "false"
  ImageStore:
    number: 0
  RunRoot: /var/run/containers/storage
  VolumePath: /var/lib/containers/storage/volumes

[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i podman pull dellemc/csi-powerstore && podman images ; done
[root@master ~]# podman inspect docker.io/dellemc/csi-powerstore:latest | grep -i "version\|release"
                "release": "291",
                "version": "1.3.0"
        "Version": "",
            "release": "291",
            "version": "1.3.0"


  128  for i in {master,node1,node2,node3}; do ssh $i podman rmi dellemc/csi-powerstore && podman images ; done
  129  for i in {master,node1,node2,node3}; do ssh $i yum module remove -y container-tools:2.0  ; done

[root@master ~]# cat /tmp/config.sh
#/bin/bash
for i in {node1,node2,node3}; do scp /etc/yum.repos.d/kubernetes.repo $i:/etc/yum.repos.d/kubernetes.repo ; ssh $i yum repolist ; done
for i in {master,node1,node2,node3}; do ssh $i setenforce 0 ; ssh $i sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config ; ssh $i getenforce ; done
for i in {master,node1,node2,node3}; do ssh $i systemctl disable firewalld.service; ssh $i systemctl stop firewalld.service ; done
for i in {master,node1,node2,node3}; do ssh $i yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion git vim net-tools ; done
for i in {master,node1,node2,node3}; do ssh $i yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo ; done
for i in {master,node1,node2,node3}; do ssh $i yum -y install docker-ce ; done
for i in {master,node1,node2,node3}; do ssh $i systemctl enable docker ; ssh $i systemctl start docker ; ssh $i systemctl status docker ; ssh $i docker version; done
for i in {master,node1,node2,node3}; do ssh $i docker --version ; done
for i in {master,node1,node2,node3}; do ssh $i docker pull dellemc/csi-powerstore:v1.3.0 ; ssh $i docker images ; done
for i in {master,node1,node2,node3}; do ssh $i docker images ; done
for i in {master,node1,node2,node3}; do ssh $i yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes ; done
[root@master ~]# chmod +x /tmp/config.sh
[root@master ~]# /tmp/config.sh
}

#Note:
Don't change docker.service to "MountFlags=shared" in /etc/systemd/system/multi-user.target.wants/docker.service, it will cause Centos 8 docker failed to start!!!

[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i kubeadm config images pull ; done
[root@master ~]# docker images | grep k8s
k8s.gcr.io/kube-apiserver            v1.21.2    106ff58d4308   9 days ago      126MB
k8s.gcr.io/kube-proxy                v1.21.2    a6ebd1c1ad98   9 days ago      131MB
k8s.gcr.io/kube-scheduler            v1.21.2    f917b8c8f55b   9 days ago      50.6MB
k8s.gcr.io/kube-controller-manager   v1.21.2    ae24db9aa2cc   9 days ago      120MB
k8s.gcr.io/pause                     3.4.1      0f8457a4c2ec   5 months ago    683kB
k8s.gcr.io/coredns/coredns           v1.8.0     296a6d5035e2   8 months ago    42.5MB
k8s.gcr.io/etcd                      3.4.13-0   0369cf4303ff   10 months ago   253MB
[root@master ~]#

#add iscsi nic in VC and config each ip
nmcli conn show
nmcli connection modify "Wired connection 1" con-name ens224 ifname ens224
nmcli conn mod ens224 ipv4.address 192.168.2.220/24 ipv4.method static connection.autoconnect yes && nmcli con up ens224 && nmcli con show

[
#change all node cgroup-driver=cgroupfs for kubernetes 1.21 version!!
vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
Environment="KUBELET_KUBECONFIG_ARGS=...  --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=cgroupfs"
]

  137  kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.1.20
  138  kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml   //after apply CNI plugin, worker will run coredns & flannel pods, then nodes will change to ready status!!
  139  for i in {node1,node2,node3}; do ssh $i kubeadm join 192.168.1.20:6443 --token tkmf3y.x3rzt3m6rtxhwc02 --discovery-token-ca-cert-hash sha256:9823a831616f82a964ae1116b6c6dfeac5c83e865a7205230adc8a0828e18fb8 ; done
  140  systemctl status kubelet           //no need start service before run "kubeadm init"!!!
       for i in {master,node1,node2,node3}; do ssh $i systemctl enable kubelet ; done 
  141  netstat -ntpl
  142  kubectl get nodes
  144  echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile
  145  echo "source <(kubectl completion bash)" >> ~/.bash_profile
  146  source ~/.bash_profile
  148  kubectl get cs
  149  vi ~/.vimrc
  syntax on
  autocmd FileType yaml setlocal ai ts=2 sw=2 et nu cuc cul
  autocmd FileType yaml colo desert
  150  vim /etc/kubernetes/manifests/kube-controller-manager.yaml     //kubernetes 1.21 version delete --port=0 line!!
  151  vim /etc/kubernetes/manifests/kube-scheduler.yaml
  152  systemctl restart kubelet
  153  kubectl get cs
  154  kubectl cluster-info
  155  kubectl get nodes
  
  #kubeadm reset
  master: kubeadm reset
          rm -rf $HOME/.kube/config
  worker: system stop kubelet
          rm -rf /etc/kubernetes
  for i in {node1,node2,node3}; do ssh $i systemctl stop kubelet; ssh $i rm -rf /etc/kubernetes/; ssh $i rm -rf /var/lib/kubelet/ ; done
  kubeadm reset
  rm -rf $HOME/.kube/config
  
[root@master ~]# kubectl get nodes
NAME           STATUS   ROLES                  AGE     VERSION
master.local   Ready    control-plane,master   12m   v1.21.2
node1.local    Ready    <none>                 10m   v1.21.2
node2.local    Ready    <none>                 10m   v1.21.2
node3.local    Ready    <none>                 10m   v1.21.2
[root@master ~]# kubectl get pods -A
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-hj952          1/1     Running   1          26m
kube-system   coredns-74ff55c5b-qfg5p          1/1     Running   1          26m
kube-system   etcd-master                      1/1     Running   1          26m
kube-system   kube-apiserver-master            1/1     Running   1          26m
kube-system   kube-controller-manager-master   1/1     Running   1          17m
kube-system   kube-flannel-ds-amd64-5lgwk      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-fvtgw      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-hcgth      1/1     Running   1          21m
kube-system   kube-flannel-ds-amd64-rgmkv      1/1     Running   1          21m
kube-system   kube-proxy-kc7dp                 1/1     Running   1          24m
kube-system   kube-proxy-nwm98                 1/1     Running   1          24m
kube-system   kube-proxy-vl27z                 1/1     Running   1          24m
kube-system   kube-proxy-xmlqj                 1/1     Running   1          26m
kube-system   kube-scheduler-master            1/1     Running   1          17m

#install helm
[root@master ~]# curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
[root@master ~]# helm version
version.BuildInfo{Version:"v3.6.1", GitCommit:"61d8e8c4a6f95540c15c6a65f36a6dd0a45e7a2f", GitTreeState:"clean", GoVersion:"go1.16.5"}

#install iscsi
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i yum -y install iscsi-initiator-utils device-mapper-multipath lsscsi ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i cat /etc/iscsi/initiatorname.iscsi ; done
InitiatorName=iqn.1994-05.com.redhat:master
InitiatorName=iqn.1994-05.com.redhat:node1
InitiatorName=iqn.1994-05.com.redhat:node2
InitiatorName=iqn.1994-05.com.redhat:node3
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i iscsiadm -m discovery -t st -p 192.168.2.40:3260 ; ssh $i iscsiadm -m node -L all ; ssh $i hostname ; ssh $i iscsiadm -m session ; done
[root@master ~]# for i in {master,node1,node2,node3}; do ssh $i mpathconf --enable --user_friendly_names y --with_module y --with_multipathd y --find_multipaths y ; ssh $i systemctl is-enabled multipathd.service ; ssh $i systemctl start multipathd.service ; ssh $i hostname; ssh $i systemctl status multipathd.service ; done


#install powerstore csi v2.3.0 gitclone
use Helm install Powerstore CSI driver
https://dell.github.io/csm-docs/docs/csidriver/installation/helm/powerstore/

[root@master ~]# git clone -b v2.3.0 https://github.com/dell/csi-powerstore.git
Cloning into 'csi-powerstore'...
...
...
[root@master ~]# cd csi-powerstore/
[root@master csi-powerstore]# ls
cmd  core  dell-csi-helm-installer  docker-files  docker.mk  env.sh  go.mod  go.sum  helm  LICENSE  licenses  Makefile  mocks  pkg  README.md  tests
[root@master csi-powerstore]# ls helm/
config.yaml  csi-powerstore  README.md  samples  secret.yaml

[root@master csi-powerstore]# cat helm/csi-powerstore/driver-image.yaml | grep driver
  # "images.driver" defines the container images used for the driver container.
  driver: dellemc/csi-powerstore:v2.3.0
[root@master csi-powerstore]# for i in {master,node1,node2,node3}; do ssh $i docker pull dellemc/csi-powerstore:v2.3.0 ; ssh $i docker images ; done

#snapshot install
[root@master csi-powerstore]# cd ~
[root@master ~]# git clone https://github.com/kubernetes-csi/external-snapshotter/
Cloning into 'external-snapshotter'...
remote: Enumerating objects: 44797, done.
remote: Counting objects: 100% (1802/1802), done.
remote: Compressing objects: 100% (744/744), done.
remote: Total 44797 (delta 1022), reused 1779 (delta 1013), pack-reused 42995
Receiving objects: 100% (44797/44797), 60.93 MiB | 2.62 MiB/s, done.
Resolving deltas: 100% (21787/21787), done.
[root@master ~]# cd external-snapshotter/
[root@master external-snapshotter]# ls
CHANGELOG  cloudbuild.yaml  code-of-conduct.md  deploy    go.mod  LICENSE   OWNERS          pkg        release-tools      vendor
client     cmd              CONTRIBUTING.md     examples  go.sum  Makefile  OWNERS_ALIASES  README.md  SECURITY_CONTACTS

[root@master external-snapshotter]# git checkout release-6.0                        //use Tab key to auto fill release-[Tab]!!
Switched to branch 'release-6.0'
Your branch is up to date with 'origin/release-6.0'.

[root@master crd]# kubectl config set-context --current --namespace kube-system     // > 5.0 snapshot release need use kube-system namespace!!
Context "kubernetes-admin@kubernetes" modified.
[root@master crd]# kubectl config get-contexts
CURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE
*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin   kube-system

[root@master external-snapshotter]# kubectl kustomize client/config/crd | kubectl create -f -
customresourcedefinition.apiextensions.k8s.io/volumesnapshotclasses.snapshot.storage.k8s.io created
customresourcedefinition.apiextensions.k8s.io/volumesnapshotcontents.snapshot.storage.k8s.io created
customresourcedefinition.apiextensions.k8s.io/volumesnapshots.snapshot.storage.k8s.io created
[root@master external-snapshotter]# kubectl kustomize deploy/kubernetes/snapshot-controller | kubectl create -f -
serviceaccount/snapshot-controller created
role.rbac.authorization.k8s.io/snapshot-controller-leaderelection created
clusterrole.rbac.authorization.k8s.io/snapshot-controller-runner created
rolebinding.rbac.authorization.k8s.io/snapshot-controller-leaderelection created
clusterrolebinding.rbac.authorization.k8s.io/snapshot-controller-role created
deployment.apps/snapshot-controller created
[root@master external-snapshotter]# kubectl get pods
NAME                                   READY   STATUS    RESTARTS     AGE
coredns-6d4b75cb6d-7m5zp               1/1     Running   2 (6d ago)   6d
coredns-6d4b75cb6d-n4tc2               1/1     Running   2 (6d ago)   6d
etcd-master.local                      1/1     Running   2 (6d ago)   6d
kube-apiserver-master.local            1/1     Running   2 (6d ago)   6d
kube-controller-manager-master.local   1/1     Running   2 (6d ago)   6d
kube-proxy-4928z                       1/1     Running   2 (6d ago)   6d
kube-proxy-c67jg                       1/1     Running   2 (6d ago)   6d
kube-proxy-kn84w                       1/1     Running   2 (6d ago)   6d
kube-proxy-rq6bz                       1/1     Running   2 (6d ago)   6d
kube-scheduler-master.local            1/1     Running   2 (6d ago)   6d
snapshot-controller-cdc49b95d-8dkj9    1/1     Running   0            19s
snapshot-controller-cdc49b95d-pt6gr    1/1     Running   0            19s
[root@master external-snapshotter]#
[root@master external-snapshotter]# kubectl logs pods/snapshot-controller-cdc49b95d-8dkj9
I0827 13:14:28.054885       1 main.go:126] Version: v5.0.0-rc3-webhook
I0827 13:14:28.056737       1 main.go:175] Start NewCSISnapshotController with kubeconfig [] resyncPeriod [15m0s]
I0827 13:14:28.080154       1 leaderelection.go:248] attempting to acquire leader lease kube-system/snapshot-controller-leader...
I0827 13:14:28.090438       1 leaderelection.go:258] successfully acquired lease kube-system/snapshot-controller-leader
I0827 13:14:28.090535       1 leader_election.go:205] became leader, starting
I0827 13:14:28.090732       1 leader_election.go:212] new leader detected, current leader: snapshot-controller-cdc49b95d-8dkj9
I0827 13:14:28.090866       1 snapshot_controller_base.go:148] Starting snapshot controller
I0827 13:14:28.090991       1 reflector.go:219] Starting reflector *v1.VolumeSnapshotClass (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.091014       1 reflector.go:255] Listing and watching *v1.VolumeSnapshotClass from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.091114       1 reflector.go:219] Starting reflector *v1.PersistentVolumeClaim (15m0s) from k8s.io/client-go/informers/factory.go:134
I0827 13:14:28.091130       1 reflector.go:255] Listing and watching *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:134
I0827 13:14:28.091633       1 reflector.go:219] Starting reflector *v1.VolumeSnapshot (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.091650       1 reflector.go:255] Listing and watching *v1.VolumeSnapshot from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.091821       1 reflector.go:219] Starting reflector *v1.VolumeSnapshotContent (15m0s) from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.091840       1 reflector.go:255] Listing and watching *v1.VolumeSnapshotContent from github.com/kubernetes-csi/external-snapshotter/client/v4/informers/externalversions/factory.go:117
I0827 13:14:28.101241       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:28.191738       1 shared_informer.go:270] caches populated
I0827 13:14:28.191773       1 snapshot_controller_base.go:505] controller initialized
I0827 13:14:33.118553       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:38.135601       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:43.149501       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:48.165639       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:53.177183       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:14:58.190787       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:03.201652       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:08.225599       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:13.240462       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:18.262782       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:23.272420       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:28.294611       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:33.307568       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:38.323194       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:43.337687       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:48.352643       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:53.362570       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:15:58.378431       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
I0827 13:16:03.390545       1 leaderelection.go:278] successfully renewed lease kube-system/snapshot-controller-leader
[root@master external-snapshotter]#

[root@master csi-powerstore]#

[root@master csi-powerstore]# kubectl create namespace csi-powerstore

[root@master csi-powerstore]# cat helm/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: powerstore-config
  # Set driver namespace
  namespace: csi-powerstore
type: Opaque
data:
  config: CONFIG_YAML
 
[root@master csi-powerstore]# curl -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=* | jq .
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   380    0   380    0     0   4691      0 --:--:-- --:--:-- --:--:--  4750
[
  {
    "id": "0",
    "global_id": "PS7d3c8339f256",
    "name": "Pod2-Cluster2",
    "physical_mtu": 1500,
    "master_appliance_id": "A1",
    "primary_appliance_id": "A1",
    "state": "Configured",
    "appliance_count": 1,
    "management_address": "192.168.1.40",
    "is_encryption_enabled": true,
    "storage_discovery_address": "192.168.2.40",
    "compatibility_level": 10,
    "system_time": "2022-08-27T14:22:19.397Z",
    "state_l10n": "Configured"
  }
]

[root@master csi-powerstore]# vim helm/config.yaml             //create config.yaml and secret.yaml in helm directory! or can copy samples/secret/secret.yaml to helm directory!
[root@master csi-powerstore]# cat helm/config.yaml
arrays:
  - endpoint: "https://192.168.1.40/api/rest"     # full URL path to the PowerStore API
    globalID: "PS7d3c8339f256"                    # unique id of the PowerStore array
    username: "admin"                          # username for connecting to API
    password: "P@ssw0rd!"                      # password for connecting to API
    skipCertificateValidation: true           # indicates if client side validation of (management)server's certificate can be skipped
    isDefault: true                           # treat current array as a default (would be used by storage classes without arrayID parameter)
    blockProtocol: "auto"                     # what SCSI transport protocol use on node side (FC, ISCSI, None, or auto)
    #nasName: "nas-server"                     # what NAS should be used for NFS volumes
    #nfsAcls: "0777"                          # defines NFSv4 ACLs
[root@master csi-powerstore]# cat helm/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: powerstore-config
  namespace: csi-powerstore
type: Opaque
data:
  config: CONFIG_YAML

#csi > v1.4.0 storageclass use arrayID!!
[root@master csi-powerstore]# cat samples/storageclass/powerstore-xfs.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-xfs
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate
parameters:
  arrayID: "PS7d3c8339f256"
  FsType: xfs

#csi v1.3.0 storageclass use arrayIP!!
[root@master csi-powerstore]# cat helm/samples/storageclass/powerstore-xfs.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-xfs
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate
parameters:
  arrayIP: "192.168.1.30"
  FsType: xfs
  
[root@master csi-powerstore]# sed "s/CONFIG_YAML/`cat helm/config.yaml | base64 -w0`/g" helm/secret.yaml | kubectl apply -f -
secret/powerstore-config created
[root@master csi-powerstore]# kubectl get secrets -n csi-powerstore
NAME                TYPE     DATA   AGE
powerstore-config   Opaque   1      64s

[root@master csi-powerstore]# kubectl get sc
No resources found
[root@master csi-powerstore]# kubectl apply -f samples/storageclass/powerstore-xfs.yaml
storageclass.storage.k8s.io/powerstore-xfs created
[root@master csi-powerstore]# kubectl get sc
NAME             PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
powerstore-xfs   csi-powerstore.dellemc.com   Delete          Immediate           true                   18s

[root@master csi-powerstore]# cd dell-csi-helm-installer && cp ../helm/csi-powerstore/values.yaml ./my-powerstore-settings.yaml
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# vim my-powerstore-settings.yaml
[root@master dell-csi-helm-installer]# grep -v "^#\|^$\|^  #" my-powerstore-settings.yaml
driverName: "csi-powerstore.dellemc.com"
volumeNamePrefix: csi
nodeNamePrefix: csi-node
nodeIDPath: /etc/hostname
controller:
  nodeSelector:
  tolerations:
  replicas: 3
node:
  nodeSelector:
  tolerations:
connection:
  enableCHAP: false
nodeFCPortsFilterFile: /etc/fc-ports-filter
snapshot:
  enabled: false
replication:
  enabled: false
externalAccess:

[root@master dell-csi-helm-installer]# ./csi-install.sh --namespace csi-powerstore --values ./my-powerstore-settings.yaml
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
------------------------------------------------------
> Installing CSI Driver: csi-powerstore on 1.24
------------------------------------------------------
------------------------------------------------------
> Checking to see if CSI Driver is already installed
------------------------------------------------------
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
------------------------------------------------------
> Verifying Kubernetes and driver configuration
------------------------------------------------------
|- Kubernetes Version: 1.24
|
|- Driver: csi-powerstore
|
|- Verifying Kubernetes version
  |
  |--> Verifying minimum Kubernetes version                         Success
  |
  |--> Verifying maximum Kubernetes version                         Success
|
|- Verifying that required namespaces have been created             Success
|
|- Verifying that required secrets have been created                Success
|
|- Verifying alpha snapshot resources
  |
  |--> Verifying that alpha snapshot CRDs are not installed         Success
|
|- Verifying Replication requirements
  |
  |--> Verifying that Dell CSI Replication CRDs are available       Failed
|
|- Verifying iSCSI installation                                     Success
|
|- Verifying NVMe installation                                      Failed
|
|- Verifying helm version                                           Success

------------------------------------------------------
> Verification Complete - With Warnings
------------------------------------------------------
Warnings:
- The CRD for DellCSIReplicationGroups is not installed. This needs to be installed if you are going to enable replication support
- Either NVMe client was not found on node: 192.168.1.21 or not able to verify
- Either NVMe module is not loaded on node: 192.168.1.21 or not able to verify
- Either NVMe client was not found on node: 192.168.1.22 or not able to verify
- Either NVMe module is not loaded on node: 192.168.1.22 or not able to verify
- Either NVMe client was not found on node: 192.168.1.23 or not able to verify
- Either NVMe module is not loaded on node: 192.168.1.23 or not able to verify
------------------------------------------------------
WARNING:
Kubernetes validation failed but installation can continue.
This may affect driver installation.

Press 'y' to continue or any other key to exit: y
|
|- Installing Driver                                                Success
  |
  |--> Waiting for Deployment powerstore-controller to be ready     Success
  |
  |--> Waiting for DaemonSet powerstore-node to be ready            Success
------------------------------------------------------
> Operation complete
------------------------------------------------------
[root@master dell-csi-helm-installer]# kubectl get pods
NAME                                   READY   STATUS    RESTARTS        AGE
coredns-6d4b75cb6d-7m5zp               1/1     Running   2 (6d18h ago)   6d19h
coredns-6d4b75cb6d-n4tc2               1/1     Running   2 (6d18h ago)   6d19h
etcd-master.local                      1/1     Running   2 (6d18h ago)   6d19h
kube-apiserver-master.local            1/1     Running   2 (6d18h ago)   6d19h
kube-controller-manager-master.local   1/1     Running   2 (6d18h ago)   6d19h
kube-proxy-4928z                       1/1     Running   2 (6d18h ago)   6d19h
kube-proxy-c67jg                       1/1     Running   2 (6d18h ago)   6d19h
kube-proxy-kn84w                       1/1     Running   2 (6d18h ago)   6d19h
kube-proxy-rq6bz                       1/1     Running   2 (6d18h ago)   6d19h
kube-scheduler-master.local            1/1     Running   2 (6d18h ago)   6d19h
snapshot-controller-cdc49b95d-8dkj9    1/1     Running   0               18h
snapshot-controller-cdc49b95d-pt6gr    1/1     Running   0               18h
[root@master dell-csi-helm-installer]# kubectl get pods -n csi-powerstore
NAME                                     READY   STATUS    RESTARTS   AGE
powerstore-controller-6cf885bff5-56947   6/6     Running   0          25s
powerstore-controller-6cf885bff5-m9cbd   6/6     Running   0          25s
powerstore-node-f48ns                    2/2     Running   0          25s
powerstore-node-hghl6                    2/2     Running   0          25s
powerstore-node-nfk4c                    2/2     Running   0          25s
[root@master dell-csi-helm-installer]# kubectl describe pods/powerstore-controller-6cf885bff5-56947 -n csi-powerstore
Name:         powerstore-controller-6cf885bff5-56947
Namespace:    csi-powerstore
Priority:     0
Node:         node3.local/192.168.1.23
Start Time:   Sun, 28 Aug 2022 03:39:02 -0400
Labels:       name=powerstore-controller
              pod-template-hash=6cf885bff5
Annotations:  <none>
Status:       Running
IP:           10.244.3.4
IPs:
  IP:           10.244.3.4
Controlled By:  ReplicaSet/powerstore-controller-6cf885bff5
Containers:
  attacher:
    Container ID:  containerd://927ae8ea77470381c829622fdc05443bdf295d4eafd05d9a297a5cedf8f14cef
    Image:         k8s.gcr.io/sig-storage/csi-attacher:v3.4.0
    Image ID:      k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --v=5
      --leader-election
      --worker-threads=130
      --resync=10s
      --timeout=130s
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:03 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
  resizer:
    Container ID:  containerd://4db3f7f75b81f6d6d119ac1813a1537980f61409f9ff5011797d14b0264e9c05
    Image:         k8s.gcr.io/sig-storage/csi-resizer:v1.4.0
    Image ID:      k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --v=5
      --leader-election
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:03 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
  provisioner:
    Container ID:  containerd://2676ec24fa4cd16af8ebc92db5da1ea9a6f5918f2482aa2a6283d6c297179856
    Image:         k8s.gcr.io/sig-storage/csi-provisioner:v3.1.0
    Image ID:      k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --volume-name-prefix=csivol
      --volume-name-uuid-length=10
      --v=5
      --leader-election
      --default-fstype=ext4
      --extra-create-metadata
      --feature-gates=Topology=true
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:03 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
  snapshotter:
    Container ID:  containerd://b7dd4d47c3e3d48fdd97e8135f8d4f869e3cd2241025aaa4e9b49734f177a4de
    Image:         k8s.gcr.io/sig-storage/csi-snapshotter:v5.0.1
    Image ID:      k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709
    Port:          <none>
    Host Port:     <none>
    Args:
      --csi-address=$(ADDRESS)
      --v=5
      --leader-election
      --snapshot-name-prefix=csisnap
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:03 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      ADDRESS:  /var/run/csi/csi.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
  csi-metadata-retriever:
    Container ID:  containerd://9aa01beba000ae33afedf106b14e82c4728a4fcd9d4d82395d2bfd0a49793068
    Image:         dellemc/csi-metadata-retriever:v1.0.0
    Image ID:      docker.io/dellemc/csi-metadata-retriever@sha256:d83121ce20d0e1d30626eaa8bc17c16fa862551ed1cd254281534b81db7724f9
    Port:          <none>
    Host Port:     <none>
    Command:
      /csi-metadata-retriever
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:03 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      CSI_RETRIEVER_ENDPOINT:  /var/run/csi/csi_retriever.sock
    Mounts:
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
  driver:
    Container ID:  containerd://a5606d60668a838b81129f13a60ecff4aab0d46be982710024535a5792da1e28
    Image:         dellemc/csi-powerstore:v2.3.0
    Image ID:      docker.io/dellemc/csi-powerstore@sha256:d11726080832b58a55cd2cc96ed3810db4034bd0cee3d5df88f2b32bfc52e6cd
    Port:          <none>
    Host Port:     <none>
    Command:
      /csi-powerstore
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:12 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      CSI_ENDPOINT:                         /var/run/csi/csi.sock
      CSI_RETRIEVER_ENDPOINT:               /var/run/csi/csi_retriever.sock
      X_CSI_MODE:                           controller
      X_CSI_DRIVER_NAME:                    csi-powerstore.dellemc.com
      X_CSI_POWERSTORE_EXTERNAL_ACCESS:
      X_CSI_NFS_ACLS:                       0777
      X_CSI_POWERSTORE_CONFIG_PATH:         /powerstore-config/config
      X_CSI_POWERSTORE_CONFIG_PARAMS_PATH:  /powerstore-config-params/driver-config-params.yaml
      GOPOWERSTORE_DEBUG:                   true
    Mounts:
      /powerstore-config from powerstore-config (rw)
      /powerstore-config-params from powerstore-config-params (rw)
      /var/run/csi from socket-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jt7zv (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  socket-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  powerstore-config-params:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      powerstore-config-params
    Optional:  false
  powerstore-config:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  powerstore-config
    Optional:    false
  kube-api-access-jt7zv:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  8m12s  default-scheduler  Successfully assigned csi-powerstore/powerstore-controller-6cf885bff5-56947 to node3.local
  Normal  Pulled     8m12s  kubelet            Container image "k8s.gcr.io/sig-storage/csi-snapshotter:v5.0.1" already present on machine
  Normal  Created    8m12s  kubelet            Created container attacher
  Normal  Started    8m12s  kubelet            Started container attacher
  Normal  Pulled     8m12s  kubelet            Container image "k8s.gcr.io/sig-storage/csi-resizer:v1.4.0" already present on machine
  Normal  Created    8m12s  kubelet            Created container resizer
  Normal  Started    8m12s  kubelet            Started container resizer
  Normal  Pulled     8m12s  kubelet            Container image "k8s.gcr.io/sig-storage/csi-provisioner:v3.1.0" already present on machine
  Normal  Created    8m12s  kubelet            Created container provisioner
  Normal  Started    8m12s  kubelet            Started container provisioner
  Normal  Pulled     8m12s  kubelet            Container image "k8s.gcr.io/sig-storage/csi-attacher:v3.4.0" already present on machine
  Normal  Created    8m12s  kubelet            Created container snapshotter
  Normal  Started    8m12s  kubelet            Started container snapshotter
  Normal  Pulled     8m12s  kubelet            Container image "dellemc/csi-metadata-retriever:v1.0.0" already present on machine
  Normal  Created    8m12s  kubelet            Created container csi-metadata-retriever
  Normal  Started    8m12s  kubelet            Started container csi-metadata-retriever
  Normal  Pulling    8m12s  kubelet            Pulling image "dellemc/csi-powerstore:v2.3.0"
  Normal  Pulled     8m3s   kubelet            Successfully pulled image "dellemc/csi-powerstore:v2.3.0" in 8.647268104s
  Normal  Created    8m3s   kubelet            Created container driver
  Normal  Started    8m3s   kubelet            Started container driver
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# kubectl describe pods/powerstore-node-f48ns -n csi-powerstore
Name:         powerstore-node-f48ns
Namespace:    csi-powerstore
Priority:     0
Node:         node1.local/192.168.1.21
Start Time:   Sun, 28 Aug 2022 03:39:03 -0400
Labels:       app=powerstore-node
              controller-revision-hash=864df4c549
              pod-template-generation=1
Annotations:  <none>
Status:       Running
IP:           192.168.1.21
IPs:
  IP:           192.168.1.21
Controlled By:  DaemonSet/powerstore-node
Containers:
  driver:
    Container ID:  containerd://5fb561051940073d6244ca527c49ba2c5ae55c90a7253eb3329c0d532a5f5aa0
    Image:         dellemc/csi-powerstore:v2.3.0
    Image ID:      docker.io/dellemc/csi-powerstore@sha256:d11726080832b58a55cd2cc96ed3810db4034bd0cee3d5df88f2b32bfc52e6cd
    Port:          <none>
    Host Port:     <none>
    Command:
      /csi-powerstore
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:13 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      CSI_ENDPOINT:                         unix:///var/lib/kubelet/plugins/csi-powerstore.dellemc.com/csi_sock
      X_CSI_MODE:                           node
      X_CSI_POWERSTORE_KUBE_NODE_NAME:       (v1:spec.nodeName)
      X_CSI_POWERSTORE_NODE_NAME_PREFIX:    csi-node
      X_CSI_POWERSTORE_NODE_ID_PATH:        /node-id
      X_CSI_POWERSTORE_NODE_CHROOT_PATH:    /noderoot
      X_CSI_POWERSTORE_TMP_DIR:             /var/lib/kubelet/plugins/csi-powerstore.dellemc.com/tmp
      X_CSI_DRIVER_NAME:                    csi-powerstore.dellemc.com
      X_CSI_FC_PORTS_FILTER_FILE_PATH:      /etc/fc-ports-filter
      X_CSI_DRIVER_NAME:                    csi-powerstore.dellemc.com
      X_CSI_POWERSTORE_ENABLE_CHAP:         false
      X_CSI_POWERSTORE_CONFIG_PATH:         /powerstore-config/config
      X_CSI_POWERSTORE_CONFIG_PARAMS_PATH:  /powerstore-config-params/driver-config-params.yaml
      GOPOWERSTORE_DEBUG:                   true
    Mounts:
      /dev from dev (rw)
      /etc/iscsi from etciscsi (rw)
      /etc/multipath.conf from mpath (rw)
      /node-id from node-id (rw)
      /noderoot from noderoot (rw)
      /powerstore-config from powerstore-config (rw)
      /powerstore-config-params from powerstore-config-params (rw)
      /run from run (rw)
      /sys from sys (rw)
      /var/lib/kubelet/plugins/csi-powerstore.dellemc.com from driver-path (rw)
      /var/lib/kubelet/plugins/kubernetes.io/csi from csi-path (rw)
      /var/lib/kubelet/pods from pods-path (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-8fms5 (ro)
  registrar:
    Container ID:  containerd://eb1c170c57796d7efa3b82432b89f13f7fb6d31f26a51b52081744c2d54a79b6
    Image:         k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.5.1
    Image ID:      k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:0103eee7c35e3e0b5cd8cdca9850dc71c793cdeb6669d8be7a89440da2d06ae4
    Port:          <none>
    Host Port:     <none>
    Args:
      --v=5
      --csi-address=$(ADDRESS)
      --kubelet-registration-path=/var/lib/kubelet/plugins/csi-powerstore.dellemc.com/csi_sock
    State:          Running
      Started:      Sun, 28 Aug 2022 03:39:13 -0400
    Ready:          True
    Restart Count:  0
    Environment:
      ADDRESS:         /csi/csi_sock
      KUBE_NODE_NAME:   (v1:spec.nodeName)
    Mounts:
      /csi from driver-path (rw)
      /registration from registration-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-8fms5 (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  registration-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/kubelet/plugins_registry/
    HostPathType:  DirectoryOrCreate
  driver-path:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/kubelet/plugins/csi-powerstore.dellemc.com
    HostPathType:  DirectoryOrCreate
  csi-path:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/kubelet/plugins/kubernetes.io/csi
    HostPathType:
  pods-path:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/kubelet/pods
    HostPathType:  Directory
  dev:
    Type:          HostPath (bare host directory volume)
    Path:          /dev
    HostPathType:  Directory
  node-id:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/machine-id
    HostPathType:  File
  etciscsi:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/iscsi
    HostPathType:  DirectoryOrCreate
  mpath:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/multipath.conf
    HostPathType:  FileOrCreate
  noderoot:
    Type:          HostPath (bare host directory volume)
    Path:          /
    HostPathType:  Directory
  sys:
    Type:          HostPath (bare host directory volume)
    Path:          /sys
    HostPathType:  Directory
  run:
    Type:          HostPath (bare host directory volume)
    Path:          /run
    HostPathType:  Directory
  powerstore-config-params:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      powerstore-config-params
    Optional:  false
  powerstore-config:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  powerstore-config
    Optional:    false
  kube-api-access-8fms5:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/disk-pressure:NoSchedule op=Exists
                             node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                             node.kubernetes.io/network-unavailable:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists
                             node.kubernetes.io/pid-pressure:NoSchedule op=Exists
                             node.kubernetes.io/unreachable:NoExecute op=Exists
                             node.kubernetes.io/unschedulable:NoSchedule op=Exists
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  15m   default-scheduler  Successfully assigned csi-powerstore/powerstore-node-f48ns to node1.local
  Normal  Pulling    15m   kubelet            Pulling image "dellemc/csi-powerstore:v2.3.0"
  Normal  Pulled     14m   kubelet            Successfully pulled image "dellemc/csi-powerstore:v2.3.0" in 9.745384644s
  Normal  Created    14m   kubelet            Created container driver
  Normal  Started    14m   kubelet            Started container driver
  Normal  Pulled     14m   kubelet            Container image "k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.5.1" already present on machine
  Normal  Created    14m   kubelet            Created container registrar
  Normal  Started    14m   kubelet            Started container registrar
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# kubectl get sc
NAME             PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
powerstore-xfs   csi-powerstore.dellemc.com   Delete          Immediate           true                   20h
[root@master dell-csi-helm-installer]# kubectl describe sc powerstore-xfs
Name:            powerstore-xfs
IsDefaultClass:  No
Annotations:     kubectl.kubernetes.io/last-applied-configuration={"allowVolumeExpansion":true,"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":{"annotations":{},"name":"powerstore-xfs"},"parameters":{"arrayID":"PS7d3c8339f256","csi.storage.k8s.io/fstype":"xfs"},"provisioner":"csi-powerstore.dellemc.com","reclaimPolicy":"Delete","volumeBindingMode":"Immediate"}

Provisioner:           csi-powerstore.dellemc.com
Parameters:            arrayID=PS7d3c8339f256,csi.storage.k8s.io/fstype=xfs
AllowVolumeExpansion:  True
MountOptions:          <none>
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                <none>
[root@master dell-csi-helm-installer]#


[root@master tmp]# yum localinstall pstcli-1.0.0.227.x86_64.release_5H1P8.rpm
[root@master tmp]# pstcli -d 192.168.1.40 -u admin -p P@ssw0rd! -session
cli> host show -sort name+ -limit 3
 #  |                  id                  |            name             |   description   | os_type | host_group.name
----+--------------------------------------+-----------------------------+-----------------+---------+-----------------
  1 | 37e0b151-e866-4b69-854c-0682324bdce7 | csi-node-node1-192.168.1.21 | k8s node: node1 | Linux   |
  2 | cddbf404-e7de-41b5-8252-c5bfaebe9373 | csi-node-node2-192.168.1.22 | k8s node: node2 | Linux   |
  3 | e1431128-bc5b-4f9e-bf15-014fef2d84d7 | csi-node-node3-192.168.1.23 | k8s node: node3 | Linux   |


##SQL test
for i in {node1,node2,node3}; do ssh $i docker pull mcr.microsoft.com/mssql/rhel/server:2019-latest ; ssh $i docker images ; done
REPOSITORY                                         TAG           IMAGE ID       CREATED         SIZE
dellemc/csi-powerstore                             v1.4.0        8bddb808e6ec   7 days ago      253MB
k8s.gcr.io/kube-apiserver                          v1.21.2       106ff58d4308   9 days ago      126MB
k8s.gcr.io/kube-controller-manager                 v1.21.2       ae24db9aa2cc   9 days ago      120MB
k8s.gcr.io/kube-scheduler                          v1.21.2       f917b8c8f55b   9 days ago      50.6MB
k8s.gcr.io/kube-proxy                              v1.21.2       a6ebd1c1ad98   9 days ago      131MB
mcr.microsoft.com/mssql/rhel/server                2019-latest   31312494c1b6   3 weeks ago     1.54GB
quay.io/coreos/flannel                             v0.14.0       8522d622299c   5 weeks ago     67.9MB
k8s.gcr.io/sig-storage/csi-provisioner             v2.2.1        b93fb1bfc551   6 weeks ago     56.4MB
k8s.gcr.io/sig-storage/csi-attacher                v3.2.1        6de272f18137   6 weeks ago     53.5MB
k8s.gcr.io/sig-storage/csi-resizer                 v1.2.0        0aa9629e1508   7 weeks ago     54MB
k8s.gcr.io/sig-storage/csi-node-driver-registrar   v2.2.0        8e5a15e16dca   8 weeks ago     18.7MB
k8s.gcr.io/pause                                   3.4.1         0f8457a4c2ec   5 months ago    683kB
k8s.gcr.io/coredns/coredns                         v1.8.0        296a6d5035e2   8 months ago    42.5MB
k8s.gcr.io/etcd                                    3.4.13-0      0369cf4303ff   10 months ago   253MB


[root@master tmp]# kubectl create secret generic mssql --from-literal=SA_PASSWORD="P@ssw0rd!"
secret/mssql created
[root@master tmp]# kubectl get secrets | grep -i mssql
mssql                               Opaque                                1      26s

[root@master tmp]# mkdir sql
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/pvc.yaml -O /tmp/sql/pvc.yaml
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/sql.yaml -O /tmp/sql/sql.yaml
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/CSNoIndex.sql -O sql/CSNoIndex.sql
[root@master tmp]# wget https://raw.githubusercontent.com/HendreyFu/csi/main/CSIndex.sql -O sql/CSIndex.sql
[root@master tmp]# vim sql/pvc.yaml
[root@master tmp]# kubectl create -f sql/pvc.yaml
persistentvolumeclaim/mssql-data created
persistentvolumeclaim/mssql-data2 created
persistentvolumeclaim/mssql-log2 created
[root@master tmp]# kubectl get pvc
NAME          STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Bound    csi-115a96149c   10Gi       RWO            powerstore-xfs   5s
mssql-data2   Bound    csi-3962f2348e   5Gi        RWO            powerstore-xfs   5s
mssql-log2    Bound    csi-1b60e606af   2Gi        RWO            powerstore-xfs   5s
[root@master tmp]# kubectl get pv
NAME             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                        STORAGECLASS     REASON   AGE
csi-115a96149c   10Gi       RWO            Delete           Bound    csi-powerstore/mssql-data    powerstore-xfs            7s
csi-1b60e606af   2Gi        RWO            Delete           Bound    csi-powerstore/mssql-log2    powerstore-xfs            7s
csi-3962f2348e   5Gi        RWO            Delete           Bound    csi-powerstore/mssql-data2   powerstore-xfs            7s
[root@master tmp]# kubectl describe pvc mssql-data
Name:          mssql-data
Namespace:     csi-powerstore
StorageClass:  powerstore-xfs
Status:        Bound
Volume:        csi-115a96149c
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-class: powerstore-xfs
               volume.beta.kubernetes.io/storage-provisioner: csi-powerstore.dellemc.com
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      10Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       <none>
Events:
  Type    Reason                 Age                From                                                                                                   Message
  ----    ------                 ----               ----                                                                                                   -------
  Normal  ExternalProvisioning   23s (x2 over 23s)  persistentvolume-controller                                                                            waiting for a volume to be created, either by external provisioner "csi-powerstore.dellemc.com" or manually created by system administrator
  Normal  Provisioning           22s (x2 over 23s)  csi-powerstore.dellemc.com_powerstore-controller-74c75cb64-rv79g_90c3bcdf-4b8f-407a-9f51-32dd58799852  External provisioner is provisioning volume for claim "csi-powerstore/mssql-data"
  Normal  ProvisioningSucceeded  22s (x2 over 22s)  csi-powerstore.dellemc.com_powerstore-controller-74c75cb64-rv79g_90c3bcdf-4b8f-407a-9f51-32dd58799852  Successfully provisioned volume csi-115a96149c

[root@master tmp]# pstcli -u admin -p P@ssw0rd! -d 192.168.1.40 -session
cli> volume show -sort name+ -limit 3
 #  |                  id                  |      name      |  type   |                 wwn                 |         size         | protection_policy.na~
----+--------------------------------------+----------------+---------+-------------------------------------+----------------------+-----------------------
  1 | 4bdb1237-6502-470c-9671-b84495a02426 | csi-115a96149c | Primary | naa.68ccf0980008ba33c40ecd501d0108~ | 10737418240 (10.00G) |
  2 | 053058e6-b839-4542-87b4-b7fd4240a0cc | csi-1b60e606af | Primary | naa.68ccf09800523f509ddeca42e919df~ | 2147483648 (2.00G)   |
  3 | 37676fa0-f7dd-4d2a-835b-ad935baa798d | csi-3962f2348e | Primary | naa.68ccf09800fa3ff3516f641b726594~ | 5368709120 (5.00G)   |
cli> job show -sort resource_name+ -limit 10
 #  |                  id                  | resourc~ |    resource_name     | description_l~ |   state   |   start_time   |    end_time    | progress_pe~
----+--------------------------------------+----------+----------------------+----------------+-----------+----------------+----------------+--------------
  1 | 38aab931-340a-4c0f-b5c5-f1d132c72f2e | volume   | csi-115a96149c       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  2 | 73af6083-92d1-450d-98a8-d9f3e6569a27 | volume   | csi-115a96149c       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  3 | 404d9bfe-4ecc-4f8b-824f-9ca629123ebd | volume   | csi-1b60e606af       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  4 | 4df24f6a-1246-4db8-81e4-df160b437747 | volume   | csi-1b60e606af       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  5 | a0f3e08e-d157-442d-a72f-9f02ea571fe6 | volume   | csi-3962f2348e       | Create a volu~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  6 | df706671-dd43-4162-8e96-1c835b9914be | volume   | csi-3962f2348e       | Create a volu~ | FAILED    | 06/25/2021 09~ | 06/25/2021 09~ |          100
  7 | f43d9ebc-624b-4302-b945-d95324f2dd13 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
  8 | 72341901-c28d-497b-8140-8db83f42a05a | host     | csi-node-node1.loca~ | Create host.   | COMPLETED | 06/25/2021 07~ | 06/25/2021 07~ |          100
  9 | 017510df-c156-4310-a3e4-c8aadd4abf97 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
 10 | 9da311b1-fab8-4523-9869-35dfba779b23 | host     | csi-node-node1.loca~ | Attach volume~ | COMPLETED | 06/25/2021 09~ | 06/25/2021 09~ |          100
cli>

cli> exit

[root@master tmp]# kubectl describe pv csi-115a96149c
Name:              csi-115a96149c
Labels:            <none>
Annotations:       pv.kubernetes.io/provisioned-by: csi-powerstore.dellemc.com
Finalizers:        [kubernetes.io/pv-protection]
StorageClass:      powerstore-xfs
Status:            Bound
Claim:             csi-powerstore/mssql-data
Reclaim Policy:    Delete
Access Modes:      RWO
VolumeMode:        Filesystem
Capacity:          10Gi
Node Affinity:
  Required Terms:
    Term 0:        csi-powerstore.dellemc.com/192.168.1.40-iscsi in [true]
                   csi-powerstore.dellemc.com/192.168.1.40-nfs in [true]
Message:
Source:
    Type:              CSI (a Container Storage Interface (CSI) volume source)
    Driver:            csi-powerstore.dellemc.com
    FSType:            xfs
    VolumeHandle:      4bdb1237-6502-470c-9671-b84495a02426/PSec370360bc60/scsi
    ReadOnly:          false
    VolumeAttributes:      FsType=xfs
                           Name=csi-115a96149c
                           Protocol=scsi
                           arrayID=PSec370360bc60
                           csi.storage.k8s.io/pv/name=csi-115a96149c
                           csi.storage.k8s.io/pvc/name=mssql-data
                           csi.storage.k8s.io/pvc/namespace=csi-powerstore
                           storage.kubernetes.io/csiProvisionerIdentity=1624625930028-8081-csi-powerstore.dellemc.com
Events:                <none>
[root@master tmp]#

[root@master tmp]# vim sql/sql.yaml
[root@master tmp]# kubectl create -f sql/sql.yaml
deployment.apps/mssql-deployment created
service/mssql-deployment created

[root@master tmp]# kubectl get pods
NAME                                    READY   STATUS    RESTARTS   AGE
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          33s
powerstore-controller-74c75cb64-pnjgm   4/4     Running   4          91m
powerstore-controller-74c75cb64-rv79g   4/4     Running   5          91m
powerstore-controller-74c75cb64-zjqnp   4/4     Running   4          91m
powerstore-node-794fz                   2/2     Running   2          91m
powerstore-node-bzrxg                   2/2     Running   2          91m
powerstore-node-frl67                   2/2     Running   2          91m
[root@master tmp]# kubectl get services
NAME               TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
mssql-deployment   NodePort   10.108.193.217   <none>        1433:31690/TCP   41s


[root@master tmp]# kubectl logs -f mssql-deployment-5f4cd94964-hs774
...
2021-06-25 13:27:06.66 spid11s     Clearing tempdb database.
2021-06-25 13:27:07.32 spid11s     [2]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1.
2021-06-25 13:27:07.32 spid11s     Starting up database 'tempdb'.
2021-06-25 13:27:07.60 spid11s     The tempdb database has 1 data file(s).
2021-06-25 13:27:07.61 spid36s     The Service Broker endpoint is in disabled or stopped state.
2021-06-25 13:27:07.62 spid36s     The Database Mirroring endpoint is in disabled or stopped state.
2021-06-25 13:27:07.66 spid36s     Service Broker manager has started.
2021-06-25 13:27:07.69 spid9s      Database 'msdb' running the upgrade step from version 902 to version 903.
2021-06-25 13:27:07.73 spid9s      Database 'msdb' running the upgrade step from version 903 to version 904.
2021-06-25 13:27:07.91 spid9s      Recovery is complete. This is an informational message only. No user action is required.
2021-06-25 13:27:07.94 spid39s     The default language (LCID 0) has been set for engine and full-text services.
2021-06-25 13:27:08.11 spid39s     The tempdb database has 2 data file(s).
2021-06-25 13:33:50.07 spid57      Attempting to load library 'xplog70.dll' into memory. This is an informational message only. No user action is required.
2021-06-25 13:33:50.13 spid57      Using 'xplog70.dll' version '2019.150.4138' to execute extended stored procedure 'xp_msver'. This is an informational message only; no user action is required.

[root@master tmp]# kubectl get pods -o wide | grep mssql -B2
NAME                                    READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          10m    10.244.1.6     node1.local   <none>           <none>

[root@master sql]# kubectl cp /tmp/sql/ mssql-deployment-5f4cd94964-hs774:/tmp/

[root@master tmp]# kubectl exec -it mssql-deployment-5f4cd94964-hs774 bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -Q "select @@version"
                                                                                                                                                             
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Microsoft SQL Server 2019 (RTM-CU11) (KB5003249) - 15.0.4138.2 (X64)
        May 27 2021 17:34:14
        Copyright (C) 2019 Microsoft Corporation
        Developer Edition (64-bit) on Linux (Red Hat Enterprise Linux 8.3 (Ootpa)) <X64>                                                                     

(1 rows affected)

bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd!
1> select @@VERSION as Version, SERVERPROPERTY('ServerName') as 'Container ID', SERVERPROPERTY('Edition') as Edition;
2> go
1> create database [TestDB] CONTAINMENT = NONE on primary ( NAME = N'TestDB', FILENAME = N'/var/opt/mssql/data2/TestDB.mdf', SIZE = 4GB, FILEGROWTH = 1024KB ) LOG ON ( NAME = N'TestDB_log', FILENAME = N'/var/opt/mssql/log2/TestDB_log.ldf', SIZE = 1GB, FILEGROWTH = 10% )
2> go
1> use TestDB
2> CREATE TABLE Inventory (id INT, name NVARCHAR(50), quantity INT)
3> INSERT INTO Inventory VALUES (1, 'banana', 150); INSERT INTO Inventory VALUES (2, 'orange', 154);
4> go
Changed database context to 'TestDB'.

(1 rows affected)

(1 rows affected)
1> SELECT * FROM Inventory WHERE quantity > 152;
2> go
id          name                                               quantity
----------- -------------------------------------------------- -----------
          2 orange                                                     154

(1 rows affected)
1>exit

//The aggregation query over 5 million rows with SQL optimizer option to ignore columnstore index
SELECT SUM(Price), AVG(Price) FROM Orders;
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -i /tmp/sql/CSNoIndex.sql
Changed database context to 'SampleDB'.
DBCC execution completed. If DBCC printed error messages, contact your system administrator.

----------- -----------
   50000000          10
Not using columnstore index: 960 ms

----------- -----------
   50000000          10
Not using columnstore index: 826 ms

----------- -----------
   50000000          10
Not using columnstore index: 822 ms

----------- -----------
   50000000          10
Not using columnstore index: 701 ms

----------- -----------
   50000000          10
Not using columnstore index: 716 ms

----------- -----------
   50000000          10
Not using columnstore index: 713 ms

----------- -----------
   50000000          10
Not using columnstore index: 885 ms

----------- -----------
   50000000          10
Not using columnstore index: 766 ms

----------- -----------
   50000000          10
Not using columnstore index: 789 ms

----------- -----------
   50000000          10
Not using columnstore index: 830 ms

//The aggregation query over 5 million rows
bash-4.4$ /opt/mssql-tools/bin/sqlcmd -S localhost,1433 -U sa -P P@ssw0rd! -i /tmp/sql/CSIndex.sql
Changed database context to 'SampleDB'.
DBCC execution completed. If DBCC printed error messages, contact your system administrator.

----------- -----------
   50000000          10
Using nonclustered columnstore index: 121 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 9 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 5 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 8 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 7 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 8 ms

----------- -----------
   50000000          10
Using nonclustered columnstore index: 4 ms
bash-4.4$


bash-4.4$ cd /var/opt/mssql/
bash-4.4$ ls -l
total 8
drwxr-sr-x. 2 mssql 10001 4096 Jun 25 13:27 data
drwxrwsr-x. 2 root  10001   24 Jun 25 13:40 data2
drwxr-sr-x. 2 mssql 10001 4096 Jun 25 13:40 log
drwxrwsr-x. 2 root  10001   28 Jun 25 13:40 log2
drwxr-sr-x. 2 mssql 10001   25 Jun 25 13:27 secrets
bash-4.4$ ls -hl data2/
total 4.1G
-rw-r-----. 1 mssql 10001 4.0G Jun 25 13:40 TestDB.mdf
bash-4.4$ ls -hl log2/
total 1.0G
-rw-r-----. 1 mssql 10001 1.0G Jun 25 13:42 TestDB_log.ldf
bash-4.4$ ls -hl data
total 735M
-rw-r-----. 1 mssql 10001  256 Jun 25 13:27 Entropy.bin
-rw-r-----. 1 mssql 10001 328M Jun 25 16:19 SampleDB.mdf
-rw-r-----. 1 mssql 10001 328M Jun 25 16:38 SampleDB_log.ldf
bash-4.4$ df -H
Filesystem                                                                                                     Size  Used Avail Use% Mounted on
overlay                                                                                                         67G  5.9G   61G   9% /
tmpfs                                                                                                           68M     0   68M   0% /dev
tmpfs                                                                                                          3.1G     0  3.1G   0% /sys/fs/cgroup
/dev/mapper/cl-root                                                                                             67G  5.9G   61G   9% /etc/hosts
shm                                                                                                             68M     0   68M   0% /dev/shm
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-115a96149c/globalmount/4bdb1237-6502-470c-9671-b84495a02426   11G  119M   11G   2% /var/opt/mssql
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-1b60e606af/globalmount/053058e6-b839-4542-87b4-b7fd4240a0cc  2.2G  1.2G  1.1G  52% /var/opt/mssql/log2
/var/lib/kubelet/plugins/kubernetes.io/csi/pv/csi-3962f2348e/globalmount/37676fa0-f7dd-4d2a-835b-ad935baa798d  5.4G  4.4G  1.1G  81% /var/opt/mssql/data2
tmpfs                                                                                                          3.1G   13k  3.1G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                                                                                                          3.1G     0  3.1G   0% /proc/acpi
tmpfs                                                                                                          3.1G     0  3.1G   0% /proc/scsi
tmpfs                                                                                                          3.1G     0  3.1G   0% /sys/firmware
bash-4.4$
bash-4.4$ exit
exit
[root@master tmp]#

#install Azure Data Studio
1)https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15
2)check witch node and ports run sql server
[root@master tmp]# kubectl get services -o wide
NAME               TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE   SELECTOR
mssql-deployment   NodePort   10.108.193.217   <none>        1433:31690/TCP   22m   app=mssql

[root@master tmp]# kubectl get pods -o wide | grep mssql -B2
NAME                                    READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
mssql-deployment-5f4cd94964-hs774       1/1     Running   0          28m    10.244.1.6     node1.local   <none>           <none>

3)check sql listen port
[root@master tmp]# ssh node1
Last login: Fri Jun 25 07:18:58 2021 from 192.168.1.20
[root@node1 ~]# netstat -ntpl | grep 31690
tcp        0      0 0.0.0.0:31690           0.0.0.0:*               LISTEN      2740/kube-proxy

4)install GUI Azure Data Studio on client,
Server:    192.168.1.21,31690
User Name: sa
Password:  P@ssw0rd!
5)test db scripts...

#use root config sql container
1)
[root@node1 ~]# docker ps -l
CONTAINER ID   IMAGE          COMMAND                  CREATED       STATUS       PORTS     NAMES
efcf6d8e2a05   31312494c1b6   "/opt/mssql/bin/perm…"   7 hours ago   Up 7 hours             k8s_mssql_mssql-deployment-5f4cd94964-hdbrd_csi-powerstore_526d50ff-b729-49d4-ae20-d1caa22ae68c_0
[root@node1 ~]# docker exec -u 0 -it efcf6d8e2a05 bash
[root@mssqlinst /]# id
uid=0(root) gid=0(root) groups=0(root),10001
[root@mssqlinst /]# /opt/mssql/bin/
checkinstallextensibility.sh  generate-sql-dump.sh          mssql-conf                    setnetbr
compress-dump.sh              handle-crash.sh               paldumper                     sqlservr
crash-support-functions.sh    launchpadd                    permissions_check.sh
[root@mssqlinst /]# /opt/mssql/bin/mssql-conf list
control.alternatewritethrough                           Enable optimized write through flush for O_DSYNC requests
control.hestacksize                                     Host extension stack size in KB
control.stoponguestprocessfault                         Stops the process if any guest process reports unhandled exception
control.writethrough                                    Use O_DSYNC for file flag write through requests
[root@mssqlinst /]# /opt/mssql/bin/mssql-conf setup
The license terms for this product can be found in
/usr/share/doc/mssql-server or downloaded from:
https://go.microsoft.com/fwlink/?LinkId=2104294&clcid=0x409

The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010&clcid=0x409

Configuring SQL Server...

Initial setup of Microsoft SQL Server failed. Please consult the ERRORLOG
in /var/opt/mssql/log for more information.

2)
recommand use Environment variables:
https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-configure-environment-variables?view=sql-server-ver15
https://www.sqlshack.com/configure-sql-server-2017-linux-mssql-conf-available-tools/

#delete sql pods and pvc
[root@master tmp]# kubectl delete -f sql/sql.yaml
deployment.apps "mssql-deployment" deleted
service "mssql-deployment" deleted
[root@master tmp]# kubectl delete -f sql/pvc.yaml
persistentvolumeclaim "mssql-data" deleted
persistentvolumeclaim "mssql-data2" deleted
persistentvolumeclaim "mssql-log2" deleted
[root@master tmp]# kubectl get pvc
No resources found in csi-powerstore namespace.
[root@master tmp]# kubectl get pv
No resources found

cli> job show -sort start_time- -limit 30
 #  |                  id                  | reso~ | resource_n~ |         description_l10n         | state  | start_t~ | end_time | progre~
----+--------------------------------------+-------+-------------+----------------------------------+--------+----------+----------+---------
  1 | 99b33d26-44e2-449b-924e-e351d7624ac7 |       |             | Detaching                        | PENDI~ |          |          |       0
  2 | 9e9eda82-78b4-4252-8458-15741c97aa14 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  3 | 2515482d-a5f4-4fd4-9f4f-d00d73c91be1 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  4 | dc81be97-656d-4991-bfeb-6484bc71d465 |       |             | Detaching                        | PENDI~ |          |          |       0
  5 | d3d3a464-34c0-4b56-b353-0ce16d28049d |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  6 | c92cf2bc-5648-41bf-b36d-1c8457854873 |       |             | Detaching                        | PENDI~ |          |          |       0
  7 | 2c028595-ff4a-4492-9ef1-67a8ae89aea0 |       |             | Waiting for Detach               | PENDI~ |          |          |       0
  8 | e46143cc-c234-4f53-8ed8-ec2c2a052aff |       |             | Detaching                        | PENDI~ |          |          |       0
  9 | 108027e2-2e28-4358-b2ea-bf9597e6da15 | volu~ | csi-115a96~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 10 | 84ee562d-f11a-4166-9733-506d352a84bd | volu~ | csi-1b60e6~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 11 | 5c92827c-4466-4849-9b75-a12f344e5b4b | volu~ | csi-3962f2~ | Delete a volume.                 | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 12 | 62f2d0ac-b74b-45c5-9567-0a05d903f97a |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 13 | 8995c7c0-0629-4e6c-9c50-8bc928037cfa |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 14 | 015bd3a6-13e9-427c-8834-4b6a5ad9ffff |       |             | Detaching Host 17aa8ad2-2da1-40~ | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 15 | 3811a07b-471b-4d2a-aa44-5b9f0f9acb34 | host  | csi-node-n~ | Detach volume from host.         | FAILED | 06/26/2~ | 06/26/2~ |     100
 16 | cb5b2d32-3047-459d-bacd-2ff69001c17a |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 17 | 92b07e18-a608-44c9-ab0c-30f939d7b74e |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 18 | db29653b-d98c-4de9-9a63-8176fe4d3c93 |       |             | Detaching Host 17aa8ad2-2da1-40~ | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 19 | 7a522a09-d2a3-4de6-aa16-94cbb26acf0d | host  | csi-node-n~ | Detach volume from host.         | FAILED | 06/26/2~ | 06/26/2~ |     100
 20 | c9d4c164-cacd-4e6b-ae23-a8dc425608e1 |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 21 | a4457590-faea-4c78-b29c-f0e6e2e74aa1 |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 22 | d0579ddd-9689-4aae-a430-6eacfa0d920c |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 23 | b607c34a-97d6-483c-ac1d-085ccfea700e |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 24 | 1492b383-fd10-44da-afa9-ff7c75dc9e0e |       |             | Waiting for Detach               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 25 | 309abad2-31dd-4309-90a7-fa6bc807f4c7 |       |             | Detaching                        | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 26 | 95b7915f-458d-483c-b39a-65a978227b18 |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 27 | 60e51fc7-df8e-4b3e-a3bd-1487747824ae |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 28 | 66b845a4-1a68-450c-8f6a-dc7474ca251c |       |             | Validating                       | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 29 | fdd2293a-8c50-461a-8a17-c2ec88599c84 |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
 30 | 9cf226be-dc97-42f7-ac51-60c913b7dc9b |       |             | Retrieving Objects               | COMPL~ | 06/26/2~ | 06/26/2~ |     100
cli>



##SQL BDC Cluster Deployment
SQL Server 2019 Big Data Clusters
https://www.youtube.com/watch?v=syFE77B6d14
Deploying SQL Server Big Data Clusters - Ben Weissman
https://www.youtube.com/watch?v=H_HA4zteg6k
Deploy Big Data Cluster
https://infohub.delltechnologies.com/l/microsoft-sql-server-2019-big-data-cluster-on-dell-emc-vxrail/step-2-deploy-big-data-cluster
Dell EMC PowerStore - SQL Server 2019 Big Data Clusters
https://www.youtube.com/watch?v=Cu9D8lrWCpc

Baremetal or VM hardware:
VM hardware       Value
CPU               8
Memory            64 GB
New Hard disk     100 GB
New Network       Name of port group created for workload traffic per PowerStore configuration instructions 
Configuration
Parameter         disk.EnableUUID=TRUE

[root@master sql]# cat /etc/yum.conf
[main]
gpgcheck=1
installonly_limit=3
clean_requirements_on_remove=True
best=True
skip_if_unavailable=False
sslverify=false
[root@master sql]# yum module install -y python36

[root@master tmp]# useradd stack
[root@master tmp]# echo redhat | passwd stack --stdin
Changing password for user stack.
passwd: all authentication tokens updated successfully.
[root@master tmp]# echo "stack ALL=(root) NOPASSWD:ALL" | tee -a /etc/sudoers.d/stack
stack ALL=(root) NOPASSWD:ALL
[root@master tmp]# chmod 0440 /etc/sudoers.d/stack
[root@master tmp]# su - stack
[stack@master ~]$ sudo ls
[stack@master ~]$ yum install wget
[stack@master ~]$ wget --no-check-certificate https://packages.microsoft.com/keys/microsoft.asc
[stack@master ~]$ sudo rpm --import microsoft.asc
[stack@master ~]$ sudo curl -k -o /etc/yum.repos.d/mssql-server.repo https://packages.microsoft.com/config/rhel/8/prod.repo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   192  100   192    0     0    240      0 --:--:-- --:--:-- --:--:--   240
[stack@master ~]$ sudo cat /etc/yum.repos.d/mssql-server.repo
[packages-microsoft-com-prod]
name=packages-microsoft-com-prod
baseurl=https://packages.microsoft.com/rhel/8/prod/
enabled=1
gpgcheck=1
gpgkey=https://packages.microsoft.com/keys/microsoft.asc
[stack@master ~]$
[stack@master ~]$ sudo yum -y install azdata-cli
[stack@master ~]$ azdata --version
20.3.5

Build (20210609.2)

SQL Server 2019 (15.0.4138)

Legal docs and information: https://aka.ms/eula-azdata-en

Python (Linux) 3.6.8 (default, Mar 19 2021, 05:13:41)
[GCC 8.4.1 20200928 (Red Hat 8.4.1-1)]

Python location '/usr/bin/python3'

BDC Support matrix, Release history:
https://docs.microsoft.com/en-us/sql/big-data-cluster/release-notes-big-data-cluster?view=sql-server-ver15
Release	Container OS      Kubernetes API	   Runtime	                                       Data Storage	   Log Storage
CU13	   Ubuntu 20.04 LTS	1.20	            containerd 1.4.6,CRI-O 1.20.0	                  Block only	      Block only
CU12	   Ubuntu 20.04 LTS	1.20	            containerd 1.4.3,docker 20.10.2,CRI-O 1.20.0	   Block only	      Block only

[stack@master ~]$ azdata bdc config list
The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010

The license terms for azdata can be viewed at:
https://aka.ms/eula-azdata-en

Do you accept the license terms? (y/n): y
[
  "aks-dev-test",
  "aks-dev-test-ha",
  "aro-dev-test",
  "aro-dev-test-ha",
  "kubeadm-dev-test",
  "kubeadm-prod",
  "openshift-dev-test",
  "openshift-prod"
]
[stack@master ~]$ azdata bdc config init --source kubeadm-dev-test --path custom
"Created configuration profile in custom"
[stack@master ~]$ vi custom/control.json
[stack@master ~]$ cat custom/control.json
{
    "apiVersion": "v1",
    "metadata": {
        "kind": "Cluster",
        "name": "mssql-cluster"
    },
    "spec": {
        "docker": {
            "registry": "mcr.microsoft.com",
            "repository": "mssql/bdc",
            "imageTag": "2019-CU13-ubuntu-20.04",
            "imagePullPolicy": "IfNotPresent"
        },
        "storage": {
            "data": {
                "className": "powerstore-xfs",
                "accessMode": "ReadWriteOnce",
                "size": "15Gi"
            },
            "logs": {
                "className": "powerstore-xfs",
                "accessMode": "ReadWriteOnce",
                "size": "10Gi"
            }
        },
        "endpoints": [
            {
                "name": "Controller",
                "serviceType": "NodePort",
                "port": 30080
            },
            {
                "name": "ServiceProxy",
                "serviceType": "NodePort",
                "port": 30777
            }
        ],
        "settings": {
            "controller": {
                "logs.rotation.size": "5000",
                "logs.rotation.days": "7"
            }
        }
    },
    "security": {}
}
[stack@master ~]$ grep -i memory custom/bdc.json
                    "spark-defaults-conf.spark.driver.memory": "1664m",
                    "spark-defaults-conf.spark.driver.memoryOverhead": "384",
                    "spark-defaults-conf.spark.executor.memory": "3712m",
                    "spark-defaults-conf.spark.executor.memoryOverhead": "384",
                    "yarn-site.yarn.nodemanager.resource.memory-mb": "12288",

[stack@master ~]$exit

[root@master tmp]# cp -a /home/stack/custom/ ./
[root@master tmp]# ls custom/
bdc.json  control.json
[root@master tmp]# vi custom/control.json
[
#Optional for > SQL Server 2019 CU 5.
https://docs.microsoft.com/en-us/sql/big-data-cluster/deployment-guidance?view=sql-server-ver15
export AZDATA_USERNAME=admin
export AZDATA_PASSWORD=P@ssw0rd!
export ACCEPT_EULA=yes
]
[root@master tmp]# azdata bdc create --config-profile custom --accept-eula yes
The privacy statement can be viewed at:
https://go.microsoft.com/fwlink/?LinkId=853010

The license terms for SQL Server Big Data Cluster can be viewed at:
Enterprise: https://go.microsoft.com/fwlink/?linkid=2104292
Standard: https://go.microsoft.com/fwlink/?linkid=2104294
Developer: https://go.microsoft.com/fwlink/?linkid=2104079


Cluster deployment documentation can be viewed at:
https://aka.ms/bdc-deploy

Azdata username:admin
Azdata password:
Confirm Azdata password:

NOTE: Cluster creation can take a significant amount of time depending on
configuration, network speed, and the number of nodes in the cluster.

Starting cluster deployment.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Cluster controller endpoint is available at 192.168.1.21:30080.
Cluster control plane is ready.
Master pool is ready.
Compute pool is ready.
Cluster 'mssql-cluster' is not ready after 15.0 minutes. Check controller logs for more details.
Data pool is ready.
Storage pool is ready.
Cluster 'mssql-cluster' deployed successfully.

[root@master tmp]# kubectl get pods -n mssql-cluster
[root@master tmp]# kubectl get pvc -n mssql-cluster -L app,plane,role,type
[root@master tmp]# kubectl config set-context --current --namespace mssql-cluster
[root@master tmp]# kubectl get pods
NAME              READY   STATUS    RESTARTS   AGE
appproxy-hcmw6    2/2     Running   0          28m
compute-0-0       3/3     Running   0          28m
control-cr5qx     3/3     Running   0          34m
controldb-0       2/2     Running   0          31m
controlwd-6ch6m   1/1     Running   0          31m
data-0-0          3/3     Running   0          28m
data-0-1          3/3     Running   0          28m
gateway-0         2/2     Running   0          28m
logsdb-0          1/1     Running   0          31m
logsui-bw5lj      1/1     Running   0          31m
master-0          3/3     Running   0          28m
metricsdb-0       1/1     Running   0          31m
metricsdc-2fs6x   1/1     Running   0          31m
metricsdc-l7tl4   1/1     Running   0          31m
metricsdc-txdtg   1/1     Running   0          31m
metricsui-s5clm   1/1     Running   0          31m
mgmtproxy-m9mt6   2/2     Running   0          31m
nmnode-0-0        2/2     Running   0          28m
sparkhead-0       4/4     Running   0          28m
storage-0-0       4/4     Running   0          28m
storage-0-1       4/4     Running   0          28m
[root@master tmp]# kubectl get pvc
NAME               STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS     AGE
data-compute-0-0   Bound    csivol-c75c006aaf   15Gi       RWO            powerstore-xfs   28m
data-controldb     Bound    csivol-11c4d435da   15Gi       RWO            powerstore-xfs   34m
data-controller    Bound    csivol-be231d8552   15Gi       RWO            powerstore-xfs   34m
data-data-0-0      Bound    csivol-120472a175   15Gi       RWO            powerstore-xfs   28m
data-data-0-1      Bound    csivol-9f7930430d   15Gi       RWO            powerstore-xfs   28m
data-gateway-0     Bound    csivol-6b488ba678   15Gi       RWO            powerstore-xfs   28m
data-logsdb-0      Bound    csivol-4249d1eeac   15Gi       RWO            powerstore-xfs   31m
data-master-0      Bound    csivol-0a44263783   15Gi       RWO            powerstore-xfs   28m
data-metricsdb-0   Bound    csivol-25a1ad5afd   15Gi       RWO            powerstore-xfs   31m
data-nmnode-0-0    Bound    csivol-6c56fb8dcf   15Gi       RWO            powerstore-xfs   28m
data-sparkhead-0   Bound    csivol-0f758e4ef2   15Gi       RWO            powerstore-xfs   28m
data-storage-0-0   Bound    csivol-b549834bbc   15Gi       RWO            powerstore-xfs   28m
data-storage-0-1   Bound    csivol-143675ca34   15Gi       RWO            powerstore-xfs   28m
logs-compute-0-0   Bound    csivol-f822089d6d   10Gi       RWO            powerstore-xfs   28m
logs-controldb     Bound    csivol-262f3f3d89   10Gi       RWO            powerstore-xfs   34m
logs-controller    Bound    csivol-38735eaca3   10Gi       RWO            powerstore-xfs   34m
logs-data-0-0      Bound    csivol-deb9cdf0c0   10Gi       RWO            powerstore-xfs   28m
logs-data-0-1      Bound    csivol-1d968c6a0a   10Gi       RWO            powerstore-xfs   28m
logs-gateway-0     Bound    csivol-a0ec32f783   10Gi       RWO            powerstore-xfs   28m
logs-logsdb-0      Bound    csivol-82108f0d02   10Gi       RWO            powerstore-xfs   31m
logs-master-0      Bound    csivol-be215c358e   10Gi       RWO            powerstore-xfs   28m
logs-metricsdb-0   Bound    csivol-f45dca73af   10Gi       RWO            powerstore-xfs   31m
logs-nmnode-0-0    Bound    csivol-d4907c2a5f   10Gi       RWO            powerstore-xfs   28m
logs-sparkhead-0   Bound    csivol-a547d0eafe   10Gi       RWO            powerstore-xfs   28m
logs-storage-0-0   Bound    csivol-be1c00c43b   10Gi       RWO            powerstore-xfs   28m
logs-storage-0-1   Bound    csivol-6db78042b3   10Gi       RWO            powerstore-xfs   28m
[root@master tmp]# kubectl get pv
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                            STORAGECLASS     REASON   AGE
csivol-0a44263783   15Gi       RWO            Delete           Bound    mssql-cluster/data-master-0      powerstore-xfs            28m
csivol-0f758e4ef2   15Gi       RWO            Delete           Bound    mssql-cluster/data-sparkhead-0   powerstore-xfs            28m
csivol-11c4d435da   15Gi       RWO            Delete           Bound    mssql-cluster/data-controldb     powerstore-xfs            34m
csivol-120472a175   15Gi       RWO            Delete           Bound    mssql-cluster/data-data-0-0      powerstore-xfs            28m
csivol-143675ca34   15Gi       RWO            Delete           Bound    mssql-cluster/data-storage-0-1   powerstore-xfs            28m
csivol-1d968c6a0a   10Gi       RWO            Delete           Bound    mssql-cluster/logs-data-0-1      powerstore-xfs            28m
csivol-25a1ad5afd   15Gi       RWO            Delete           Bound    mssql-cluster/data-metricsdb-0   powerstore-xfs            31m
csivol-262f3f3d89   10Gi       RWO            Delete           Bound    mssql-cluster/logs-controldb     powerstore-xfs            34m
csivol-38735eaca3   10Gi       RWO            Delete           Bound    mssql-cluster/logs-controller    powerstore-xfs            34m
csivol-4249d1eeac   15Gi       RWO            Delete           Bound    mssql-cluster/data-logsdb-0      powerstore-xfs            31m
csivol-6b488ba678   15Gi       RWO            Delete           Bound    mssql-cluster/data-gateway-0     powerstore-xfs            28m
csivol-6c56fb8dcf   15Gi       RWO            Delete           Bound    mssql-cluster/data-nmnode-0-0    powerstore-xfs            28m
csivol-6db78042b3   10Gi       RWO            Delete           Bound    mssql-cluster/logs-storage-0-1   powerstore-xfs            28m
csivol-82108f0d02   10Gi       RWO            Delete           Bound    mssql-cluster/logs-logsdb-0      powerstore-xfs            31m
csivol-9f7930430d   15Gi       RWO            Delete           Bound    mssql-cluster/data-data-0-1      powerstore-xfs            28m
csivol-a0ec32f783   10Gi       RWO            Delete           Bound    mssql-cluster/logs-gateway-0     powerstore-xfs            28m
csivol-a547d0eafe   10Gi       RWO            Delete           Bound    mssql-cluster/logs-sparkhead-0   powerstore-xfs            28m
csivol-b549834bbc   15Gi       RWO            Delete           Bound    mssql-cluster/data-storage-0-0   powerstore-xfs            28m
csivol-be1c00c43b   10Gi       RWO            Delete           Bound    mssql-cluster/logs-storage-0-0   powerstore-xfs            28m
csivol-be215c358e   10Gi       RWO            Delete           Bound    mssql-cluster/logs-master-0      powerstore-xfs            28m
csivol-be231d8552   15Gi       RWO            Delete           Bound    mssql-cluster/data-controller    powerstore-xfs            34m
csivol-c75c006aaf   15Gi       RWO            Delete           Bound    mssql-cluster/data-compute-0-0   powerstore-xfs            28m
csivol-d4907c2a5f   10Gi       RWO            Delete           Bound    mssql-cluster/logs-nmnode-0-0    powerstore-xfs            28m
csivol-deb9cdf0c0   10Gi       RWO            Delete           Bound    mssql-cluster/logs-data-0-0      powerstore-xfs            28m
csivol-f45dca73af   10Gi       RWO            Delete           Bound    mssql-cluster/logs-metricsdb-0   powerstore-xfs            31m
csivol-f822089d6d   10Gi       RWO            Delete           Bound    mssql-cluster/logs-compute-0-0   powerstore-xfs            28m
[root@master tmp]# kubectl get pv|wc
     27     219    3645
[root@master tmp]# kubectl get services
NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                                                                                                               AGE
appproxy-svc              ClusterIP   10.110.8.143     <none>        8080/TCP                                                                                                                                                                                                                              28m
appproxy-svc-external     NodePort    10.111.99.76     <none>        8080:30778/TCP                                                                                                                                                                                                                        28m
compute-0-svc             ClusterIP   10.102.250.195   <none>        1433/TCP,8300/TCP,8310/TCP,8311/TCP,8400/TCP,8410/TCP,8411/TCP,5502/TCP                                                                                                                                                               28m
controldb-svc             ClusterIP   10.101.61.66     <none>        1433/TCP,8311/TCP,8411/TCP                                                                                                                                                                                                            35m
controller-svc            ClusterIP   10.101.209.98    <none>        443/TCP,8311/TCP,8301/TCP,8411/TCP,8401/TCP                                                                                                                                                                                           35m
controller-svc-external   NodePort    10.104.84.54     <none>        8443:30080/TCP                                                                                                                                                                                                                        35m
data-0-svc                ClusterIP   10.104.34.175    <none>        1433/TCP,8300/TCP,8310/TCP,8311/TCP,8312/TCP,8313/TCP,8400/TCP,8410/TCP,8411/TCP,8412/TCP,8413/TCP                                                                                                                                    28m
gateway-svc               ClusterIP   10.105.75.136    <none>        8443/TCP,8300/TCP,8311/TCP,8400/TCP,8411/TCP                                                                                                                                                                                          28m
gateway-svc-external      NodePort    10.101.80.182    <none>        8443:30443/TCP                                                                                                                                                                                                                        28m
hdfsvault-svc             ClusterIP   10.96.179.19     <none>        443/TCP                                                                                                                                                                                                                               28m
logsdb-svc                ClusterIP   10.97.108.197    <none>        9200/TCP,8300/TCP,8400/TCP                                                                                                                                                                                                            31m
logsui-svc                ClusterIP   10.104.122.35    <none>        5601/TCP,8300/TCP,8400/TCP                                                                                                                                                                                                            31m
master-p-svc              ClusterIP   10.103.149.50    <none>        1433/TCP                                                                                                                                                                                                                              28m
master-svc                ClusterIP   10.107.196.189   <none>        8088/TCP,50075/TCP,50020/TCP,50010/TCP,8031/TCP,8032/TCP,8033/TCP,8040/TCP,8042/TCP,8080/TCP,1433/TCP,1533/TCP,9995/TCP,8998/TCP,8300/TCP,8301/TCP,8302/TCP,8310/TCP,8311/TCP,8400/TCP,8401/TCP,8402/TCP,8410/TCP,8411/TCP,8312/TCP   28m
master-svc-external       NodePort    10.107.231.229   <none>        1433:31433/TCP                                                                                                                                                                                                                        28m
metricsdb-svc             ClusterIP   10.107.171.88    <none>        8086/TCP,8300/TCP,8400/TCP                                                                                                                                                                                                            31m
metricsdc-svc             ClusterIP   10.107.240.63    <none>        8300/TCP,8400/TCP                                                                                                                                                                                                                     31m
metricsui-svc             ClusterIP   10.100.141.8     <none>        3000/TCP,8300/TCP,8400/TCP                                                                                                                                                                                                            31m
mgmtproxy-svc             ClusterIP   10.97.76.11      <none>        443/TCP,8300/TCP,8311/TCP,8400/TCP,8411/TCP                                                                                                                                                                                           31m
mgmtproxy-svc-external    NodePort    10.102.66.79     <none>        8443:30777/TCP                                                                                                                                                                                                                        31m
mssqlvault-svc            ClusterIP   10.102.214.210   <none>        443/TCP                                                                                                                                                                                                                               28m
nmnode-0-svc              ClusterIP   10.111.160.188   <none>        9000/TCP,50470/TCP,14000/TCP,8300/TCP,8311/TCP,8400/TCP,8411/TCP,2020/TCP,50200/TCP                                                                                                                                                   28m
sparkhead-svc             ClusterIP   10.99.245.95     <none>        8090/TCP,8031/TCP,8032/TCP,8033/TCP,8080/TCP,1433/TCP,9995/TCP,8998/TCP,8999/TCP,9084/TCP,18480/TCP,19888/TCP                                                                                                                         28m
storage-0-svc             ClusterIP   10.103.239.134   <none>        50470/TCP,50075/TCP,50200/TCP,50020/TCP,9000/TCP,50010/TCP,8040/TCP,8042/TCP,1433/TCP,8443/TCP,8300/TCP,8301/TCP,8310/TCP,8311/TCP,8400/TCP,8401/TCP,8410/TCP,8411/TCP                                                                28m
[root@master tmp]#

#check BDC status
azdata login -n mssql-cluster
azdata bdc endpoint list -o table
azdata bdc status show
azdata bdc control status show
azdata bdc sql status show

[root@master tmp]# azdata login -n mssql-cluster
Option '-n' has been deprecated and will be removed in a future release. Use '--namespace' instead.
Username: admin
Password:
Logged in successfully to `https://192.168.1.21:30080` in namespace `mssql-cluster`. Setting active context to `mssql-cluster`.
[root@master tmp]# azdata bdc endpoint list -o table
Description                                             Endpoint                                                 Name               Protocol
------------------------------------------------------  -------------------------------------------------------  -----------------  ----------
Gateway to access HDFS files, Spark                     https://192.168.1.21:30443                               gateway            https
Spark Jobs Management and Monitoring Dashboard          https://192.168.1.21:30443/gateway/default/sparkhistory  spark-history      https
Spark Diagnostics and Monitoring Dashboard              https://192.168.1.21:30443/gateway/default/yarn          yarn-ui            https
Application Proxy                                       https://192.168.1.21:30778                               app-proxy          https
Management Proxy                                        https://192.168.1.22:30777                               mgmtproxy          https
Log Search Dashboard                                    https://192.168.1.22:30777/kibana                        logsui             https
Metrics Dashboard                                       https://192.168.1.22:30777/grafana                       metricsui          https
Cluster Management Service                              https://192.168.1.21:30080                               controller         https
SQL Server Master Instance Front-End                    192.168.1.22,31433                                       sql-server-master  tds
HDFS File System Proxy                                  https://192.168.1.21:30443/gateway/default/webhdfs/v1    webhdfs            https
Proxy for running Spark statements, jobs, applications  https://192.168.1.21:30443/gateway/default/livy/v1       livy               https
Hadoop KMS proxy for managing Hadoop Encryption keys    https://192.168.1.21:30443/gateway/default/hadoopkms/v1  hadoopkms          https
[root@master tmp]# azdata bdc status show


 Mssql-cluster: ready                                                                                                                Health Status:  healthy
 ===========================================================================================================================================================
 Services: READY                                                                                                                     Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Servicename    State    Healthstatus    Details

 sql            READY    healthy         -
 hdfs           READY    healthy         -
 spark          READY    healthy         -
 control        READY    healthy         -
 gateway        READY    healthy         -
 app            READY    healthy         -


 Sql Services: ready                                                                                                                 Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 master          ready    healthy         StatefulSet master is healthy
 compute-0       ready    healthy         StatefulSet compute-0 is healthy
 data-0          ready    healthy         StatefulSet data-0 is healthy
 storage-0       ready    healthy         StatefulSet storage-0 is healthy


 Hdfs Services: ready                                                                                                                Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 nmnode-0        ready    healthy         StatefulSet nmnode-0 is healthy
 storage-0       ready    healthy         StatefulSet storage-0 is healthy
 sparkhead       ready    healthy         StatefulSet sparkhead is healthy


 Spark Services: ready                                                                                                               Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 sparkhead       ready    healthy         StatefulSet sparkhead is healthy
 storage-0       ready    healthy         StatefulSet storage-0 is healthy


 Control Services: ready                                                                                                             Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 controldb       ready    healthy         StatefulSet controldb is healthy
 control         ready    healthy         ReplicaSet control is healthy
 metricsdc       ready    healthy         DaemonSet metricsdc is healthy
 metricsui       ready    healthy         ReplicaSet metricsui is healthy
 metricsdb       ready    healthy         StatefulSet metricsdb is healthy
 logsui          ready    healthy         ReplicaSet logsui is healthy
 logsdb          ready    healthy         StatefulSet logsdb is healthy
 mgmtproxy       ready    healthy         ReplicaSet mgmtproxy is healthy
 controlwd       ready    healthy         ReplicaSet controlwd is healthy


 Gateway Services: ready                                                                                                             Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 gateway         ready    healthy         StatefulSet gateway is healthy


 App Services: ready                                                                                                                 Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 appproxy        ready    healthy         ReplicaSet appproxy is healthy


[root@master tmp]# azdata bdc control status show


 Control: READY                                                                                                                      Health Status:  healthy
 ===========================================================================================================================================================
 Resources: ready                                                                                                                    Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 controldb       ready    healthy         StatefulSet controldb is healthy
 control         ready    healthy         ReplicaSet control is healthy
 metricsdc       ready    healthy         DaemonSet metricsdc is healthy
 metricsui       ready    healthy         ReplicaSet metricsui is healthy
 metricsdb       ready    healthy         StatefulSet metricsdb is healthy
 logsui          ready    healthy         ReplicaSet logsui is healthy
 logsdb          ready    healthy         StatefulSet logsdb is healthy
 mgmtproxy       ready    healthy         ReplicaSet mgmtproxy is healthy
 controlwd       ready    healthy         ReplicaSet controlwd is healthy


[root@master tmp]# azdata bdc sql status show


 Sql: READY                                                                                                                          Health Status:  healthy
 ===========================================================================================================================================================
 Resources: ready                                                                                                                    Health Status:  healthy
 -----------------------------------------------------------------------------------------------------------------------------------------------------------
 Resourcename    State    Healthstatus    Details

 master          ready    healthy         StatefulSet master is healthy
 compute-0       ready    healthy         StatefulSet compute-0 is healthy
 data-0          ready    healthy         StatefulSet data-0 is healthy
 storage-0       ready    healthy         StatefulSet storage-0 is healthy


[root@master tmp]#

[root@master tmp]# ssh node1
Last login: Wed Oct  6 04:21:30 2021 from 192.168.1.20
[root@node1 ~]# docker images|grep mssql
mcr.microsoft.com/mssql/bdc/mssql-server-data             2019-CU13-ubuntu-20.04   93382876afa7   4 days ago     10.9GB
mcr.microsoft.com/mssql/bdc/mssql-hadoop                  2019-CU13-ubuntu-20.04   27539432ba45   4 days ago     14.7GB
mcr.microsoft.com/mssql/bdc/mssql-security-support        2019-CU13-ubuntu-20.04   500f7c24c0b8   4 days ago     866MB
mcr.microsoft.com/mssql/bdc/mssql-security-knox           2019-CU13-ubuntu-20.04   6844521990a3   4 days ago     1GB
mcr.microsoft.com/mssql/bdc/mssql-controller              2019-CU13-ubuntu-20.04   0dfdcbbe2ba4   4 days ago     1.11GB
mcr.microsoft.com/mssql/bdc/mssql-app-service-proxy       2019-CU13-ubuntu-20.04   686f5ca460df   4 days ago     929MB
mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit       2019-CU13-ubuntu-20.04   dbbed1633c4d   4 days ago     1.09GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf        2019-CU13-ubuntu-20.04   348da2408550   4 days ago     1.09GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd        2019-CU13-ubuntu-20.04   cce544f21310   4 days ago     1.17GB
mcr.microsoft.com/mssql/rhel/server                       2019-latest              b572b24fd03c   2 months ago   1.66GB
[root@node1 ~]# docker ps
CONTAINER ID   IMAGE                                                 COMMAND                  CREATED             STATUS             PORTS     NAMES
3928185de95e   dbbed1633c4d                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_fluentbit_storage-0-1_mssql-cluster_f307388e-3883-43dc-9e58-1d581a07c330_0
b7e53f9cb9d0   dbbed1633c4d                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_fluentbit_data-0-0_mssql-cluster_040b8958-6ca7-4868-9a5a-a8dd0e1feb10_0
008f50f9bb16   mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd    "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_collectd_storage-0-1_mssql-cluster_f307388e-3883-43dc-9e58-1d581a07c330_0
c4903334a9af   mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd    "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_collectd_data-0-0_mssql-cluster_040b8958-6ca7-4868-9a5a-a8dd0e1feb10_0
5414202f22cb   dbbed1633c4d                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_fluentbit_sparkhead-0_mssql-cluster_59923293-bdba-4350-b151-6c1a3dfad116_0
9ee0b3366f7e   27539432ba45                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_hadoop-hivemetastore_sparkhead-0_mssql-cluster_59923293-bdba-4350-b151-6c1a3dfad116_0
e8df1314bef3   27539432ba45                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_hadoop-livy-sparkhistory_sparkhead-0_mssql-cluster_59923293-bdba-4350-b151-6c1a3dfad116_0
23c271af8666   dbbed1633c4d                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_fluentbit_nmnode-0-0_mssql-cluster_d00f1d67-3c75-431c-8104-bd364300f47f_0
9ab6d7e685b8   93382876afa7                                          "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_mssql-server_storage-0-1_mssql-cluster_f307388e-3883-43dc-9e58-1d581a07c330_0
80cbc4fd4925   mcr.microsoft.com/mssql/bdc/mssql-hadoop              "/opt/agent/bin/agent"   33 minutes ago      Up 33 minutes                k8s_hadoop_storage-0-1_mssql-cluster_f307388e-3883-43dc-9e58-1d581a07c330_0
2a16a2d4d425   mcr.microsoft.com/mssql/bdc/mssql-hadoop              "/opt/agent/bin/agent"   34 minutes ago      Up 33 minutes                k8s_hadoop_nmnode-0-0_mssql-cluster_d00f1d67-3c75-431c-8104-bd364300f47f_0
7a6c51ced0e8   mcr.microsoft.com/mssql/bdc/mssql-hadoop              "/opt/agent/bin/agent"   34 minutes ago      Up 33 minutes                k8s_hadoop-yarn-jobhistory_sparkhead-0_mssql-cluster_59923293-bdba-4350-b151-6c1a3dfad116_0
e738fcdcfa49   mcr.microsoft.com/mssql/bdc/mssql-server-data         "/opt/agent/bin/agent"   49 minutes ago      Up 48 minutes                k8s_mssql-server_data-0-0_mssql-cluster_040b8958-6ca7-4868-9a5a-a8dd0e1feb10_0
5c66c718d8e0   k8s.gcr.io/pause:3.5                                  "/pause"                 53 minutes ago      Up 53 minutes                k8s_POD_storage-0-1_mssql-cluster_f307388e-3883-43dc-9e58-1d581a07c330_0
9600fd1b098d   dbbed1633c4d                                          "/opt/agent/bin/agent"   54 minutes ago      Up 54 minutes                k8s_fluentbit_gateway-0_mssql-cluster_6f8afe92-6b96-40ca-a733-91a7c49dce2b_0
5b71ecedf0e2   mcr.microsoft.com/mssql/bdc/mssql-security-knox       "/opt/agent/bin/agent"   54 minutes ago      Up 54 minutes                k8s_knox_gateway-0_mssql-cluster_6f8afe92-6b96-40ca-a733-91a7c49dce2b_0
9cb06cd2ba4a   k8s.gcr.io/pause:3.5                                  "/pause"                 54 minutes ago      Up 54 minutes                k8s_POD_nmnode-0-0_mssql-cluster_d00f1d67-3c75-431c-8104-bd364300f47f_0
4f2caaf54fd3   k8s.gcr.io/pause:3.5                                  "/pause"                 54 minutes ago      Up 54 minutes                k8s_POD_sparkhead-0_mssql-cluster_59923293-bdba-4350-b151-6c1a3dfad116_0
de0b1a36b2e9   k8s.gcr.io/pause:3.5                                  "/pause"                 54 minutes ago      Up 54 minutes                k8s_POD_data-0-0_mssql-cluster_040b8958-6ca7-4868-9a5a-a8dd0e1feb10_0
04ffc4cf0648   dbbed1633c4d                                          "/opt/agent/bin/agent"   54 minutes ago      Up 54 minutes                k8s_fluentbit_appproxy-hcmw6_mssql-cluster_f46fa03b-b890-4bd5-af50-441514b3dcc7_0
f8a082bdb8da   mcr.microsoft.com/mssql/bdc/mssql-app-service-proxy   "/opt/agent/bin/agent"   54 minutes ago      Up 54 minutes                k8s_app-service-proxy_appproxy-hcmw6_mssql-cluster_f46fa03b-b890-4bd5-af50-441514b3dcc7_0
9cfe5d70ebe5   k8s.gcr.io/pause:3.5                                  "/pause"                 54 minutes ago      Up 54 minutes                k8s_POD_gateway-0_mssql-cluster_6f8afe92-6b96-40ca-a733-91a7c49dce2b_0
ea95093f1bcb   k8s.gcr.io/pause:3.5                                  "/pause"                 54 minutes ago      Up 54 minutes                k8s_POD_appproxy-hcmw6_mssql-cluster_f46fa03b-b890-4bd5-af50-441514b3dcc7_0
3c70fd721bcc   mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf    "/opt/agent/bin/agent"   57 minutes ago      Up 57 minutes                k8s_telegraf_metricsdc-txdtg_mssql-cluster_e858378b-3d7d-4cfa-abc5-0251e993ad04_0
995b28f61bde   k8s.gcr.io/pause:3.5                                  "/pause"                 57 minutes ago      Up 57 minutes                k8s_POD_metricsdc-txdtg_mssql-cluster_e858378b-3d7d-4cfa-abc5-0251e993ad04_0
7a850ef5bd7a   mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit   "/opt/agent/bin/agent"   58 minutes ago      Up 58 minutes                k8s_fluentbit_control-cr5qx_mssql-cluster_d8b3e919-d10b-46b0-b3a8-776e5e0c7d94_0
21435287bc33   mcr.microsoft.com/mssql/bdc/mssql-security-support    "/opt/agent/bin/agent"   59 minutes ago      Up 59 minutes                k8s_security-support_control-cr5qx_mssql-cluster_d8b3e919-d10b-46b0-b3a8-776e5e0c7d94_0
365da16206c0   mcr.microsoft.com/mssql/bdc/mssql-controller          "/opt/bin/start-cont…"   59 minutes ago      Up 59 minutes                k8s_controller_control-cr5qx_mssql-cluster_d8b3e919-d10b-46b0-b3a8-776e5e0c7d94_0
f25516a1855a   k8s.gcr.io/pause:3.5                                  "/pause"                 About an hour ago   Up About an hour             k8s_POD_control-cr5qx_mssql-cluster_d8b3e919-d10b-46b0-b3a8-776e5e0c7d94_0
8e5f21b50034   448b83161ea3                                          "/csi-powerstore"        20 hours ago        Up 20 hours                  k8s_driver_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
f6386e4ac423   k8s.gcr.io/sig-storage/csi-snapshotter                "/csi-snapshotter --…"   20 hours ago        Up 20 hours                  k8s_snapshotter_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
9ff034ad2011   k8s.gcr.io/sig-storage/csi-provisioner                "/csi-provisioner --…"   20 hours ago        Up 20 hours                  k8s_provisioner_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
f66d4322b301   k8s.gcr.io/sig-storage/csi-resizer                    "/csi-resizer --csi-…"   20 hours ago        Up 20 hours                  k8s_resizer_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
cc9b36dc2b9f   k8s.gcr.io/sig-storage/csi-attacher                   "/csi-attacher --csi…"   20 hours ago        Up 20 hours                  k8s_attacher_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
c2ef980e068d   k8s.gcr.io/sig-storage/csi-node-driver-registrar      "/csi-node-driver-re…"   20 hours ago        Up 20 hours                  k8s_registrar_powerstore-node-8cmkd_csi-powerstore_768a6532-631f-445b-9d8f-78ad9d1babfe_0
d2bb18278c46   448b83161ea3                                          "/csi-powerstore"        20 hours ago        Up 20 hours                  k8s_driver_powerstore-node-8cmkd_csi-powerstore_768a6532-631f-445b-9d8f-78ad9d1babfe_0
346ca8953a50   k8s.gcr.io/pause:3.5                                  "/pause"                 20 hours ago        Up 20 hours                  k8s_POD_powerstore-controller-8ffbb88c7-6b7k4_csi-powerstore_18f87a7d-86d2-46b6-8dc5-becb75718f4d_0
afc465a9020f   k8s.gcr.io/pause:3.5                                  "/pause"                 20 hours ago        Up 20 hours                  k8s_POD_powerstore-node-8cmkd_csi-powerstore_768a6532-631f-445b-9d8f-78ad9d1babfe_0
35af4799d04a   8d147537fb7d                                          "/coredns -conf /etc…"   23 hours ago        Up 23 hours                  k8s_coredns_coredns-78fcd69978-k5f9p_kube-system_7e5b6d42-d67e-4b26-ae25-2a07bd966e00_2
bb0ce34bedc2   8d147537fb7d                                          "/coredns -conf /etc…"   23 hours ago        Up 23 hours                  k8s_coredns_coredns-78fcd69978-7ghd2_kube-system_db8dda2b-374b-4d98-81e6-549f4a5d9174_2
1425d4803ada   k8s.gcr.io/pause:3.5                                  "/pause"                 23 hours ago        Up 23 hours                  k8s_POD_coredns-78fcd69978-k5f9p_kube-system_7e5b6d42-d67e-4b26-ae25-2a07bd966e00_11
2d0649f446a4   k8s.gcr.io/pause:3.5                                  "/pause"                 23 hours ago        Up 23 hours                  k8s_POD_coredns-78fcd69978-7ghd2_kube-system_db8dda2b-374b-4d98-81e6-549f4a5d9174_12
e2c399894108   8522d622299c                                          "/opt/bin/flanneld -…"   23 hours ago        Up 23 hours                  k8s_kube-flannel_kube-flannel-ds-mrrcn_kube-system_34388ed4-d646-4d5f-87da-b982774bfbfe_2
98c1e3cf6439   873127efbc8a                                          "/usr/local/bin/kube…"   23 hours ago        Up 23 hours                  k8s_kube-proxy_kube-proxy-zjsfs_kube-system_fa6a444f-23e2-4951-bcdd-71eedbac6f4e_2
36f155c54b77   k8s.gcr.io/pause:3.5                                  "/pause"                 23 hours ago        Up 23 hours                  k8s_POD_kube-proxy-zjsfs_kube-system_fa6a444f-23e2-4951-bcdd-71eedbac6f4e_2
5882d505a007   k8s.gcr.io/pause:3.5                                  "/pause"                 23 hours ago        Up 23 hours                  k8s_POD_kube-flannel-ds-mrrcn_kube-system_34388ed4-d646-4d5f-87da-b982774bfbfe_2
[root@node1 ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:          64150       12564       16794          88       34791       50877
Swap:             0           0           0
[root@node1 ~]#
[root@node1 ~]# netstat -ntpl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:30080           0.0.0.0:*               LISTEN      2597/kube-proxy
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      1185/kubelet
tcp        0      0 0.0.0.0:31433           0.0.0.0:*               LISTEN      2597/kube-proxy
tcp        0      0 127.0.0.1:10249         0.0.0.0:*               LISTEN      2597/kube-proxy
tcp        0      0 0.0.0.0:30443           0.0.0.0:*               LISTEN      2597/kube-proxy
tcp        0      0 127.0.0.1:46805         0.0.0.0:*               LISTEN      1185/kubelet
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1115/sshd
tcp        0      0 0.0.0.0:30777           0.0.0.0:*               LISTEN      2597/kube-proxy
tcp        0      0 0.0.0.0:30778           0.0.0.0:*               LISTEN      2597/kube-proxy
tcp6       0      0 :::10250                :::*                    LISTEN      1185/kubelet
tcp6       0      0 :::10256                :::*                    LISTEN      2597/kube-proxy
tcp6       0      0 :::22                   :::*                    LISTEN      1115/sshd
[root@node1 ~]#

azdata bdc endpoint list -e sql-server-master
Azure Data Studio (launch GUI console, SERVERS: connect to bdc "xxxip,31433", use admin to login then enabel sa account;  SQL SERVER BIG DATA CLUSTERS: https://192.168.1.21:30080)
https://docs.microsoft.com/en-us/sql/big-data-cluster/connect-to-big-data-cluster?view=sql-server-ver15
By default, the user name SA is disabled during big data cluster deployment!!
need set AZDATA_USERNAME and AZDATA_PASSWORD environment when install!!
or enable sa:  //https://nielsberglund.com/2019/12/23/how-to-deploy-sql-server-2019-big-data-cluster-using-azure-data-studio/
[
 USE master;
 GO
 ALTER LOGIN sa WITH PASSWORD=N'P@ssw0rd!'
 GO
 ALTER LOGIN sa ENABLE;
 GO
]
in GUI NOTEBOOKS: open .ipynb to test scripts... (Note: github .ipynb need use raw format to download!)
(wget https://github.com/microsoft/sqlworkshops-bdc/raw/de44633dfc01db08cef36084a8a2975b6fa5befa/SQL2019BDC/notebooks/bdc_tutorial_01.ipynb -O bdc_tutorial_01.ipynb)


#upgrade BDC
azdata bdc upgrade -n mssql-cluster -t 2019-CUxx-ubuntu-xx -r mcr.microsoft.com/mssql/bdc


#delete BDC
[root@master ~]# azdata bdc delete --name mssql-cluster --force

This operation will delete everything inside of cluster "mssql-cluster"
which includes the SQL Server containers, Kubernetes secrets and services,
and HDFS containers. Data stored on persistent volumes will get deleted if
the storage class reclaim policy is set to delete/recycle.
Namespace "mssql-cluster" and other objects created outside of Big Data Cluster
will not be dropped.

Deleting cluster 'mssql-cluster'.
Cluster 'mssql-cluster' deleted successfully.

#BDC Architecture
https://www.youtube.com/watch?v=GvOo-VV7-p4
Control Plane
  -Controller(SQL Server Master,Knox Gateway,Livy,HIVE,SQL Cluster Administration Portal,Grafana Dashboard,Kibana Dashboard)
Compute Plane
  -Compute Pool(SQL Server,SQL Server...)
Data Plane
  -Data Pool(SQL Server)
  -Storage Pool(SQL Server,Spark,HDFS)
App Pool
  -App Pool(ML Server,Job(SSIS(SQL Server Integration Services)),Web Apps)
HDFS (Hadoop Distributed File System)

#Load sample data
https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster
curl -o bootstrap-sample-db.sh "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/bootstrap-sample-db.sh"
chmod +x bootstrap-sample-db.sh
curl -o bootstrap-sample-db.sql "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/bootstrap-sample-db.sql"
./bootstrap-sample-db.sh <CLUSTER_NAMESPACE> <SQL_MASTER_ENDPOINT> <KNOX_ENDPOINT>


#BDC workshop lab
https://github.com/microsoft/sqlworkshops-bdc/tree/master/SQL2019BDC/notebooks
https://microsoft.github.io/sqlworkshops/
https://github.com/microsoft/sqlworkshops-bdc
https://aka.ms/bdc-samples

[root@master tmp]# curl "https://sabwoody.blob.core.windows.net/backups/WideWorldImporters.bak" -o WWI.bak
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  568M  100  568M    0     0  11.2M      0  0:00:50  0:00:50 --:--:-- 12.8M
[root@master tmp]# curl "https://sabwoody.blob.core.windows.net/backups/AdventureWorks.bak" -o AdventureWorks.bak
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  207M  100  207M    0     0  10.7M      0  0:00:19  0:00:19 --:--:-- 11.1M
[root@master tmp]# curl "https://sabwoody.blob.core.windows.net/backups/AdventureWorksDW.bak" -o AdventureWorksDW.bak
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 97.1M  100 97.1M    0     0  10.4M      0  0:00:09  0:00:09 --:--:-- 10.7M
[root@master tmp]# curl "https://sabwoody.blob.core.windows.net/backups/WideWorldImportersDW.bak" -o WWIDW.bak
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  268M  100  268M    0     0  10.6M      0  0:00:25  0:00:25 --:--:-- 11.1M
[root@master tmp]# ls -hl *.bak
-rw-r--r--. 1 root root 208M Oct  7 10:45 AdventureWorks.bak
-rw-r--r--. 1 root root  98M Oct  7 10:45 AdventureWorksDW.bak
-rw-r--r--. 1 root root  48M May 22  2017 WideWorldImportersDW-Full.bak
-rw-r--r--. 1 root root 569M Oct  7 10:43 WWI.bak
-rw-r--r--. 1 root root 269M Oct  7 10:46 WWIDW.bak
[root@master tmp]# kubectl cp WWI.bak master-0:/var/opt/mssql/data -c mssql-server -n mssql-cluster
[root@master tmp]# kubectl cp WWIDW.bak master-0:/var/opt/mssql/data -c mssql-server -n mssql-cluster
[root@master tmp]# kubectl cp AdventureWorks.bak master-0:/var/opt/mssql/data -c mssql-server -n mssql-cluster
[root@master tmp]# kubectl cp AdventureWorksDW.bak master-0:/var/opt/mssql/data -c mssql-server -n mssql-cluster
[root@master tmp]#

[root@master tmp]# kubectl exec -it master-0 -n mssql-cluster bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
Defaulted container "mssql-server" out of: mssql-server, collectd, fluentbit
To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

agent@master-0:/$ ls -hl /var/opt/mssql/data/
total 1.9G
-rw-r--r--. 1 agent agent 208M Oct  7 14:54 AdventureWorks.bak
-rw-r--r--. 1 agent agent  98M Oct  7 14:55 AdventureWorksDW.bak
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:12 DWConfiguration.mdf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:12 DWConfiguration_log.ldf
-rw-rw----. 1 mssql mssql 500M Oct  6 08:12 DWDiagnostics.mdf
-rw-rw----. 1 mssql mssql  72M Oct  6 08:12 DWDiagnostics_log.ldf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 DWQueue.mdf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:12 DWQueue_log.ldf
-rw-rw----. 1 mssql mssql  256 Oct  6 08:04 Entropy.bin
-rw-r--r--. 1 agent agent 569M Oct  7 14:50 WWI.bak
-rw-r--r--. 1 agent agent 269M Oct  7 14:54 WWIDW.bak
-rw-rw----. 1 mssql mssql 4.5M Oct  7 05:18 master.mdf
-rw-rw----. 1 mssql mssql 2.0M Oct  7 14:21 mastlog.ldf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 09:40 model.mdf
-rw-rw----. 1 mssql mssql  14M Oct  6 08:05 model_msdbdata.mdf
-rw-rw----. 1 mssql mssql 512K Oct  6 08:05 model_msdblog.ldf
-rw-rw----. 1 mssql mssql 2.3M Oct  6 08:05 model_replicatedmaster.ldf
-rw-rw----. 1 mssql mssql 4.5M Oct  6 08:05 model_replicatedmaster.mdf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 09:40 modellog.ldf
-rw-rw----. 1 mssql mssql  14M Oct  6 08:05 msdbdata.mdf
-rw-rw----. 1 mssql mssql 512K Oct  6 08:05 msdblog.ldf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb.mdf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb2.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb3.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb4.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb5.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb6.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb7.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  6 08:05 tempdb8.ndf
-rw-rw----. 1 mssql mssql 8.0M Oct  7 14:09 templog.ldf
agent@master-0:/$

#use curl tools and BDC user admin/P@ssw0rd! to create directory and upload sample data, user is BDC create input name and password!!
https://docs.microsoft.com/en-us/sql/big-data-cluster/data-ingestion-curl?view=sql-server-ver16
[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/product_review_data?op=MKDIRS"
HTTP/1.1 200 OK
Date: Thu, 07 Oct 2021 15:04:09 GMT
Set-Cookie: KNOXSESSIONID=node01o9fbsz1gsbwnx7qsotfo3aqh4.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:04:09 GMT
Date: Thu, 07 Oct 2021 15:04:09 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:04:09 GMT
Date: Thu, 07 Oct 2021 15:04:09 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Content-Type: application/json;charset=utf-8
Transfer-Encoding: chunked

{"boolean":true}

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_customers?op=MKDIRS"
HTTP/1.1 200 OK
Date: Thu, 07 Oct 2021 15:08:16 GMT
Set-Cookie: KNOXSESSIONID=node0sqjqndc25sep1utan49vpgcix5.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:08:17 GMT
Date: Thu, 07 Oct 2021 15:08:17 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:08:17 GMT
Date: Thu, 07 Oct 2021 15:08:17 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Content-Type: application/json;charset=utf-8
Transfer-Encoding: chunked

{"boolean":true}

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_products?op=MKDIRS"
HTTP/1.1 200 OK
Date: Thu, 07 Oct 2021 15:09:10 GMT
Set-Cookie: KNOXSESSIONID=node0l0ydqmt4savi1uq7empniovgc6.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:09:10 GMT
Date: Thu, 07 Oct 2021 15:09:10 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:09:10 GMT
Date: Thu, 07 Oct 2021 15:09:10 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Content-Type: application/json;charset=utf-8
Transfer-Encoding: chunked

{"boolean":true}[root@master tmp]#
[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/web_logs?op=MKDIRS"
HTTP/1.1 200 OK
Date: Thu, 07 Oct 2021 15:09:52 GMT
Set-Cookie: KNOXSESSIONID=node01orbtr68f6us51eidpm4bpx0uj7.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:09:52 GMT
Date: Thu, 07 Oct 2021 15:09:52 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:09:52 GMT
Date: Thu, 07 Oct 2021 15:09:52 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Content-Type: application/json;charset=utf-8
Transfer-Encoding: chunked

{"boolean":true}[root@master tmp]#
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/product_reviews.csv" -o product_reviews.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   215  100   215    0     0    271      0 --:--:-- --:--:-- --:--:--   271
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/products.csv" -o products.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   215  100   215    0     0   1053      0 --:--:-- --:--:-- --:--:--  1053rl -
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/customers.csv" -o customers.csv
u  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 43717  100 43717    0     0   234k      0 --:--:-- --:--:-- --:--:--  234krl -
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/stockitemholdings.csv" -o products.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   215  100   215    0     0   1335      0 --:--:-- --:--:-- --:--:--  1335
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/web_clickstreams.csv" -o web_clickstreams.csv
c  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
 35  170M   35 60.0M    0     0   9.8M      0  0:00:17  0:00:06  0:00:11 10.6Msvet-formatted.c
100  170M  100  170M    0     0  10.0M      0  0:00:16  0:00:16 --:--:-- 10.3Mormatted.csvng-f
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/fleet-formatted.csv" -o fleet-formatted.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  8074  100  8074    0     0  17326      0 --:--:-- --:--:-- --:--:-- 17289
[root@master tmp]# curl -G "https://sabwoody.blob.core.windows.net/backups/training-formatted.csv" -o training-formatted.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 6341k  100 6341k    0     0  7247k      0 --:--:-- --:--:-- --:--:-- 7247k
[root@master tmp]# ls -halt *.csv
-rw-r--r--. 1 root root 6.2M Oct  7 11:12 training-formatted.csv
-rw-r--r--. 1 root root 7.9K Oct  7 11:11 fleet-formatted.csv
-rw-r--r--. 1 root root 171M Oct  7 11:11 web_clickstreams.csv
-rw-r--r--. 1 root root  215 Oct  7 11:11 products.csv
-rw-r--r--. 1 root root  43K Oct  7 11:11 customers.csv
-rw-r--r--. 1 root root  215 Oct  7 11:10 product_reviews.csv

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/product_review_data/product_reviews.csv?op=create&overwrite=true" -H "Content-Type: application/octet-stream" -T "product_reviews.csv"
HTTP/1.1 307 Temporary Redirect
Date: Thu, 07 Oct 2021 15:17:27 GMT
Set-Cookie: KNOXSESSIONID=node012xa50nne37ekdgiwz00rbpxf8.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:17:27 GMT
Date: Thu, 07 Oct 2021 15:17:27 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:17:27 GMT
Date: Thu, 07 Oct 2021 15:17:27 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Location: https://192.168.1.21:30443/gateway/default/webhdfs/data/v1/webhdfs/v1/product_review_data/product_reviews.csv?_=AAAACAAAABAAAADQt3IMBq3UdvmyHwdvF0IDwKBXg1sjyhhX-6WDHt14yzMbCwsW8SoPlmF0xVau4BacJjw32JoyG5e9k7EhpOLIJs3Rjh2HJMjy1J7fhZHY60vboPLlX8U-6sEsegtGZ1-yPdMCKYe84JEaghBv89-JYnlcv0fNSouZDhbHISvV25pP6L-DTNqP70Q14Yn1sY-Nm6xgZq7umZBwFSZGJ4bZoOPBbaTRAKsOiV5ra4kEyFaJHM25OnIjW1R8BJrtEbm7Xn0FyicMVv_3h18l8aFd90LauY5fLgkNO3oxvZqasFF0ZT_AdiqYRQ
Content-Type: application/octet-stream
Content-Length: 0
Connection: close

HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Date: Thu, 07 Oct 2021 15:17:27 GMT
Set-Cookie: KNOXSESSIONID=node01nyhhax6drlq21eokpyszg80fp9.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:17:27 GMT
Location: https://192.168.1.21:30443/gateway/default/webhdfs/v1/product_review_data/product_reviews.csv
Access-Control-Allow-Origin: *
Connection: close

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_customers/customers.csv?op=create&overwrite=true" -H "Content-Type: application/octet-stream" -T "customers.csv"
HTTP/1.1 307 Temporary Redirect
Date: Thu, 07 Oct 2021 15:19:05 GMT
Set-Cookie: KNOXSESSIONID=node0329jv2vrg4jvujqvred89p2e10.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:19:05 GMT
Date: Thu, 07 Oct 2021 15:19:05 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:19:05 GMT
Date: Thu, 07 Oct 2021 15:19:05 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Location: https://192.168.1.21:30443/gateway/default/webhdfs/data/v1/webhdfs/v1/partner_customers/customers.csv?_=AAAACAAAABAAAADQNXHPF65EN1-742ureA9U97iwhWUwLbdD0QTKCNYod-9l3HirlaJ5ZzMfqymzafgHqBu-udYQYf2U36qG0npH1y3brKwYiduGzyfPg7Z2vB8bg8NEC5UcJA73aIE5W9HfDsIFUnC9Rlas_nJ6gezu08almkVshcV6Yh69nQsPA4dlBC-wlfENZ7qwEHpV6rTDXf3IYDlw2yMMiStjGQnZSBL4WSe1Ku3l-s5b6FSANzIMJt2qJJevwHb-eV_t8Xa5jWWv7mad8F8KOrjopaBqLdNf4ldoPGVuaN_yPsCFH_7USM9kxihGlg
Content-Type: application/octet-stream
Content-Length: 0
Connection: close

HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Date: Thu, 07 Oct 2021 15:19:05 GMT
Set-Cookie: KNOXSESSIONID=node06nfqpnmsfjsvvyi8grli4jrl11.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:19:05 GMT
Location: https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_customers/customers.csv
Access-Control-Allow-Origin: *
Connection: close

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_products/products.csv?op=create&overwrite=true" -H "Content-Type: application/octet-stream" -T "products.csv"
HTTP/1.1 307 Temporary Redirect
Date: Thu, 07 Oct 2021 15:20:09 GMT
Set-Cookie: KNOXSESSIONID=node010gcdw9debzksdye2olb8jpmv12.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:20:09 GMT
Date: Thu, 07 Oct 2021 15:20:09 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:20:09 GMT
Date: Thu, 07 Oct 2021 15:20:09 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Location: https://192.168.1.21:30443/gateway/default/webhdfs/data/v1/webhdfs/v1/partner_products/products.csv?_=AAAACAAAABAAAADQQ9O9OOFUa0iqf32VM4rTaH0YCaTV80Guj_Uzup2z4o0rE7_XWi2eTykmWBPR27WB5RyuxWt8bK2XPzjCGGj5-468a1vlY-I21S0l2cbDxHtBceghJjsUMbLsWN-NV8BDpVY1EnQOyKFRId9QVtthM24NAfpaD7w1q-RiE8Cc4Xe6Db2Vwb4vVVIjETLNadz8gXgi-sn-FS7AMxuJkJGrDLwlsJAW-IdATperBqpvkfz4vS9fBbJZq2rtCKC9-tDOitojneHM4nKWGxZMLJPeWfizIDqXdcygBTtdQMJO7rSabyfc4gkmSw
Content-Type: application/octet-stream
Content-Length: 0
Connection: close

HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Date: Thu, 07 Oct 2021 15:20:09 GMT
Set-Cookie: KNOXSESSIONID=node014kqanhsjlj9q19kig3hdsbhum13.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:20:09 GMT
Location: https://192.168.1.21:30443/gateway/default/webhdfs/v1/partner_products/products.csv
Access-Control-Allow-Origin: *
Connection: close

[root@master tmp]# curl -i -L -k -u admin:P@ssw0rd! -X PUT "https://192.168.1.21:30443/gateway/default/webhdfs/v1/web_logs/web_clickstreams.csv?op=create&overwrite=true" -H "Content-Type: application/octet-stream" -T "web_clickstreams.csv"
HTTP/1.1 307 Temporary Redirect
Date: Thu, 07 Oct 2021 15:21:06 GMT
Set-Cookie: KNOXSESSIONID=node01pbyx8fjq7q73jwwx27s32dfc14.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:21:06 GMT
Date: Thu, 07 Oct 2021 15:21:06 GMT
Cache-Control: no-cache
Expires: Thu, 07 Oct 2021 15:21:06 GMT
Date: Thu, 07 Oct 2021 15:21:06 GMT
Pragma: no-cache
X-FRAME-OPTIONS: SAMEORIGIN
Location: https://192.168.1.21:30443/gateway/default/webhdfs/data/v1/webhdfs/v1/web_logs/web_clickstreams.csv?_=AAAACAAAABAAAADQOHHWritW0CUVmd6r0MjxyV1tYVLJgL_pAeOZe6fM-LBlT1DAiVZMsgsj7zFtN_SJh2jcgYvCuv9N3zh5QEkyU9TcHiBgk_XOh5HNnKKqU2JtmHglcLujYpKI4if0BGajHBRw5P-8eeC2r_otfaBoWGmjE0pFjHGgKCr-7TvZ2ag1LUYCNLUFKvZjK8zSR3XTSIr1iYZlnI9IIaHPaT8a2zxHjbCLW96H4_QyMGvWjHqIEnklNwUoLSt8dur9lq2yHYkLtRMofnfWvZwfD8EpCh9tFODAi9FkA1yyUvomn92Mdtg5jmzmRQ
Content-Type: application/octet-stream
Content-Length: 0
Connection: close

HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Date: Thu, 07 Oct 2021 15:21:06 GMT
Set-Cookie: KNOXSESSIONID=node0qclib0monnwyq8dr8wrmij7415.node0; Path=/gateway/default; Secure; HttpOnly
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: rememberMe=deleteMe; Path=/gateway/default; Max-Age=0; Expires=Wed, 06-Oct-2021 15:21:06 GMT
Location: https://192.168.1.21:30443/gateway/default/webhdfs/v1/web_logs/web_clickstreams.csv
Access-Control-Allow-Origin: *
Connection: close

[root@master tmp]#
use Azure Data Studio GUI checck:
Servers --> 192.168.1.22,31433 --> HDFS:
  partner_customers	--> customers.csv
  partner_products	--> products.csv
  product_review_data   --> product_reviews.csv
  web_logs		--> web_clickstreams.csv

4 directory and sample data success upload!!!


#BDC offline deployments
https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster/deployment/offline
#deploy private registry
[root@master tmp]# docker pull registry:2
2: Pulling from library/registry
213ec9aee27d: Pull complete
5299e6f78605: Pull complete
4c2fb79b7ce6: Pull complete
74a97d2d84d9: Pull complete
44c4c74a95e4: Pull complete
Digest: sha256:83bb78d7b28f1ac99c68133af32c93e9a1c149bcd3cb6e683a3ee56e312f1c96
Status: Downloaded newer image for registry:2
docker.io/library/registry:2
[root@master tmp]# docker images | grep registry
registry                                         2          3a0f7b0a13ef   3 weeks ago     24.1MB
[root@master tmp]#
[root@master tmp]# vi /etc/docker/daemon.json
[root@master tmp]# cat /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "insecure-registries": ["master.local:5000"]
}
[root@master tmp]#
[root@master tmp]# systemctl restart docker
[root@master tmp]# systemctl status docker
? docker.service - Docker Application Container Engine
   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2022-09-01 12:59:55 EDT; 9s ago
     Docs: https://docs.docker.com
 Main PID: 1194628 (dockerd)
    Tasks: 35
   Memory: 65.6M
   CGroup: /system.slice/docker.service
           +-1194628 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
           +-1194884 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 5000 -container-ip 172.17.0.2 -container-port 5000
           +-1194891 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 5000 -container-ip 172.17.0.2 -container-port 5000

Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.242561324-04:00" level=info msg="Removing stale sandbox e89e0c38288cedb72e01df>
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.244657204-04:00" level=warning msg="Error (Unable to complete atomic operation>
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.321125859-04:00" level=info msg="Default bridge (docker0) is assigned with an >
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.774862155-04:00" level=info msg="Loading containers: done."
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.804992101-04:00" level=info msg="Docker daemon" commit=a89b842 graphdriver(s)=>
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.805087711-04:00" level=info msg="Daemon has completed initialization"
Sep 01 12:59:55 master.local systemd[1]: Started Docker Application Container Engine.
Sep 01 12:59:55 master.local dockerd[1194628]: time="2022-09-01T12:59:55.836423781-04:00" level=info msg="API listen on /var/run/docker.sock"
Sep 01 12:59:58 master.local dockerd[1194628]: time="2022-09-01T12:59:58.215119782-04:00" level=info msg="ignoring event" container=45b3735ec578699bb15>
Sep 01 12:59:58 master.local dockerd[1194628]: time="2022-09-01T12:59:58.874529991-04:00" level=info msg="ignoring event" container=fd7ac58948ea0c7ea87>
[root@master tmp]#
[root@master tmp]# docker run --privileged -d --name registry -p 5000:5000 -v /var/lib/registry:/var/lib/registry --restart=always registry:2
821cd035872a91c3f80362b14a30f28d93b57685d822e53def3dfcf337006e47
[root@master tmp]# netstat -ntpl |grep 5000
tcp        0      0 0.0.0.0:5000            0.0.0.0:*               LISTEN      1190945/docker-prox
tcp6       0      0 :::5000                 :::*                    LISTEN      1190951/docker-prox
[root@master tmp]# docker ps |grep registry
821cd035872a   registry:2             "/entrypoint.sh /etc…"   24 seconds ago   Up 23 seconds   0.0.0.0:5000->5000/tcp, :::5000->5000/tcp   registry
[root@master tmp]#
[root@master tmp]# docker tag registry:2 master.local:5000/registry:2
[root@master tmp]# docker push master.local:5000/registry:2
The push refers to repository [master.local:5000/registry]
73130e341eaf: Pushed
692a418a42be: Pushed
d3db20e71506: Pushed
145b66c455f7: Pushed
994393dc58e7: Pushed
2: digest: sha256:29f25d3b41a11500cc8fc4e19206d483833a68543c30aefc8c145c8b1f0b1450 size: 1363
[root@master tmp]# docker images | grep registry
registry                                         2          3a0f7b0a13ef   3 weeks ago     24.1MB
master.local:5000/registry                       2          3a0f7b0a13ef   3 weeks ago     24.1MB
[root@master tmp]# ls -halt /var/lib/registry/docker/registry/v2/
total 0
drwxr-xr-x. 4 root root 39 Sep  1 13:01 .
drwxr-xr-x. 3 root root 20 Sep  1 13:01 blobs
drwxr-xr-x. 3 root root 16 Sep  1 13:01 ..
drwxr-xr-x. 3 root root 22 Sep  1 13:01 repositories
[root@master tmp]# du -hs /var/lib/registry/docker/
8.9M    /var/lib/registry/docker/

#test push image from node1
[root@master ~]# ssh node1
Last login: Thu Sep  1 13:21:48 2022 from 192.168.1.20
[root@node1 ~]# vi /etc/docker/daemon.json
[root@node1 ~]# cat /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "insecure-registries": ["master.local:5000"]
}
[root@node1 ~]# systemctl restart docker
[root@node1 ~]# systemctl status docker
? docker.service - Docker Application Container Engine
   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2022-09-01 22:51:16 EDT; 10s ago
     Docs: https://docs.docker.com
 Main PID: 2642605 (dockerd)
    Tasks: 39
   Memory: 104.9M
   CGroup: /system.slice/docker.service
           +-2642605 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.353960977-04:00" level=info msg="Removing stale sandbox 1c663822d1383>
Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.370673882-04:00" level=warning msg="Error (Unable to complete atomic >
Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.451459281-04:00" level=info msg="Default bridge (docker0) is assigned>
Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.573853043-04:00" level=info msg="Loading containers: done."
Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.603457839-04:00" level=info msg="Docker daemon" commit=a89b842 graphd>
Sep 01 22:51:16 node1.local dockerd[2642605]: time="2022-09-01T22:51:16.603600864-04:00" level=info msg="Daemon has completed initialization"
Sep 01 22:51:16 node1.local systemd[1]: Started Docker Application Container Engine.

[root@node1 ~]# docker login -u root -p emc2Local! master.local:5000
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
[root@node1 ~]# docker images |grep 2019
mcr.microsoft.com/mssql/bdc/mssql-server-data         2019-CU17-ubuntu-20.04   332ea5fd66df   4 weeks ago     14.3GB
mcr.microsoft.com/mssql/bdc/mssql-hadoop              2019-CU17-ubuntu-20.04   80caa83a131a   4 weeks ago     17.4GB
mcr.microsoft.com/mssql/bdc/mssql-control-watchdog    2019-CU17-ubuntu-20.04   13f96a54904f   4 weeks ago     770MB
mcr.microsoft.com/mssql/bdc/mssql-monitor-kibana      2019-CU17-ubuntu-20.04   aad8b4e20b14   4 weeks ago     1.34GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit   2019-CU17-ubuntu-20.04   6ab44b92be43   4 weeks ago     1.1GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-grafana     2019-CU17-ubuntu-20.04   f39f41d0af3c   4 weeks ago     1.02GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf    2019-CU17-ubuntu-20.04   0798c672a513   4 weeks ago     1.1GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd    2019-CU17-ubuntu-20.04   e8abe19bf26e   4 weeks ago     1.18GB
[root@node1 ~]# docker tag mcr.microsoft.com/mssql/bdc/mssql-control-watchdog:2019-CU17-ubuntu-20.04 master.local:5000/mssql/bdc/mssql-control-watchdog:2019-CU17-ubuntu-20.04
[root@node1 ~]# docker push master.local:5000/mssql/bdc/mssql-control-watchdog:2019-CU17-ubuntu-20.04
The push refers to repository [master.local:5000/mssql/bdc/mssql-control-watchdog]
b7eb4ed9ce84: Pushed
faffd7b2fa83: Pushed
dd576e670421: Pushed
28fd033c7d0c: Pushed
2019-CU17-ubuntu-20.04: digest: sha256:240c6446846739b1f44ee75b82b2b5d60b200bce13bfe6f2f32736675751c917 size: 1159
[root@node1 ~]# docker images |grep 2019
mcr.microsoft.com/mssql/bdc/mssql-server-data         2019-CU17-ubuntu-20.04   332ea5fd66df   4 weeks ago     14.3GB
mcr.microsoft.com/mssql/bdc/mssql-hadoop              2019-CU17-ubuntu-20.04   80caa83a131a   4 weeks ago     17.4GB
master.local:5000/mssql/bdc/mssql-control-watchdog    2019-CU17-ubuntu-20.04   13f96a54904f   4 weeks ago     770MB
mcr.microsoft.com/mssql/bdc/mssql-control-watchdog    2019-CU17-ubuntu-20.04   13f96a54904f   4 weeks ago     770MB
mcr.microsoft.com/mssql/bdc/mssql-monitor-kibana      2019-CU17-ubuntu-20.04   aad8b4e20b14   4 weeks ago     1.34GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit   2019-CU17-ubuntu-20.04   6ab44b92be43   4 weeks ago     1.1GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-grafana     2019-CU17-ubuntu-20.04   f39f41d0af3c   4 weeks ago     1.02GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf    2019-CU17-ubuntu-20.04   0798c672a513   4 weeks ago     1.1GB
mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd    2019-CU17-ubuntu-20.04   e8abe19bf26e   4 weeks ago     1.18GB
[root@node1 ~]# logout
Connection to node1 closed.
[root@master ~]# ls -halt /var/lib/registry/docker/registry/v2/repositories/mssql/bdc/
total 0
drwxr-xr-x. 5 root root 55 Sep  1 22:55 mssql-control-watchdog
[root@master ~]# du -hs /var/lib/registry/docker/registry/v2/repositories/mssql/bdc/
36K     /var/lib/registry/docker/registry/v2/repositories/mssql/bdc/
[root@master ~]# du -hs /var/lib/registry/docker/registry/v2/
279M    /var/lib/registry/docker/registry/v2/

#test push image from local host
[root@master tmp]# docker pull mcr.microsoft.com/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04
2019-CU17-ubuntu-20.04: Pulling from mssql/bdc/mssql-dns
87fd477f588c: Pull complete
cedd18b89ca6: Pull complete
edd95dcf0b15: Pull complete
713c4ad6746b: Pull complete
Digest: sha256:e238053d895c7dd93f51973757956c5bafc4cd76556f71c152969c59b5c5aa58
Status: Downloaded newer image for mcr.microsoft.com/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04
mcr.microsoft.com/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04
[root@master tmp]# docker images|grep mssql
mcr.microsoft.com/mssql/bdc/mssql-dns            2019-CU17-ubuntu-20.04   5aaeb94c4c45   4 weeks ago     916MB
[root@master tmp]# docker tag mcr.microsoft.com/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04 master.local:5000/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04
[root@master tmp]# docker push master.local:5000/mssql/bdc/mssql-dns:2019-CU17-ubuntu-20.04
The push refers to repository [master.local:5000/mssql/bdc/mssql-dns]
a47005962864: Pushed
76b24eab9289: Pushed
671bdf2b5f88: Pushed
28fd033c7d0c: Pushed
2019-CU17-ubuntu-20.04: digest: sha256:e238053d895c7dd93f51973757956c5bafc4cd76556f71c152969c59b5c5aa58 size: 1161
[root@master tmp]#
[root@master tmp]# docker images | grep mssql
master.local:5000/mssql/bdc/mssql-dns            2019-CU17-ubuntu-20.04   5aaeb94c4c45   4 weeks ago     916MB
mcr.microsoft.com/mssql/bdc/mssql-dns            2019-CU17-ubuntu-20.04   5aaeb94c4c45   4 weeks ago     916MB
[root@master tmp]#

https://docs.microsoft.com/en-us/sql/big-data-cluster/deploy-offline?view=sql-server-ver15
[root@master tmp]# curl -o push-bdc-images-to-custom-private-repo.py "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/deployment/offline/push-bdc-images-to-custom-private-repo.py"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  3814  100  3814    0     0  24448      0 --:--:-- --:--:-- --:--:-- 24448

[root@master tmp]# python3 --version
Python 3.6.8
[root@master tmp]# python3 push-bdc-images-to-custom-private-repo.py          //push-bdc-images-to-custom-private-repo.py have issue can't download and push images!!!
Provide Docker registry source - press ENTER for using `mcr.microsoft.com`:mcr.microsoft.com
Provide Docker repository source - press ENTER for using `mssql/bdc`:mssql/bdc
Provide Docker tag for the images at the source: 2019-CU17-ubuntu-20.04
Provide Docker registry target:master.local:5000
Provide Docker repository target:registry
Provide Docker username for the target registry:root
Provide Docker password for the target registry:
Provide Docker tag for the images at the target: 2019-CU17-ubuntu-20.04
Pulling images from source repository: mcr.microsoft.com/mssql/bdc
"docker pull" requires exactly 1 argument.
See 'docker pull --help'.

Usage:  docker pull [OPTIONS] NAME[:TAG|@DIGEST]

Pull an image or a repository from a registry
Execute docker login to target registry:master.local:5000
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

Tagging local images...
"docker tag" requires exactly 2 arguments.
See 'docker tag --help'.

Usage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]

Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
Push images to target Docker repository: master.local:5000/registry
"docker push" requires exactly 1 argument.
See 'docker push --help'.

Usage:  docker push [OPTIONS] NAME[:TAG]

Push an image or a repository to a registry
Images are now pushed to the target repository.
REPOSITORY                                       TAG        IMAGE ID       CREATED         SIZE
k8s.gcr.io/kube-apiserver                        v1.24.4    6cab9d1bed1b   2 weeks ago     130MB
k8s.gcr.io/kube-apiserver                        v1.23.10   9ca5fafbe8dc   2 weeks ago     135MB
k8s.gcr.io/kube-controller-manager               v1.23.10   91a4a0d5de4e   2 weeks ago     125MB
k8s.gcr.io/kube-scheduler                        v1.23.10   d5c0efb802d9   2 weeks ago     53.5MB
k8s.gcr.io/kube-proxy                            v1.23.10   71b9bf9750e1   2 weeks ago     112MB
registry                                         2          3a0f7b0a13ef   3 weeks ago     24.1MB
master.local:5000/registry                       2          3a0f7b0a13ef   3 weeks ago     24.1MB
rancher/mirrored-flannelcni-flannel              v0.19.1    252b2c3ee6c8   3 weeks ago     62.3MB
dellemc/csi-powerstore                           v2.3.0     c620bd57fa1e   8 weeks ago     294MB
rancher/mirrored-flannelcni-flannel-cni-plugin   v1.1.0     fcecffc7ad4a   3 months ago    8.09MB
k8s.gcr.io/etcd                                  3.5.1-0    25f8c7f3da61   10 months ago   293MB
k8s.gcr.io/coredns/coredns                       v1.8.6     a4ca41631cc7   10 months ago   46.8MB
k8s.gcr.io/pause                                 3.6        6270bb605e12   12 months ago   683kB
[root@master tmp]#

#change code for debug push-bdc-images-to-custom-private-repo.py
for image in images:
     cmd += "docker pull " + SOURCE_DOCKER_REGISTRY + "/" + SOURCE_DOCKER_REPOSITORY + "/" + image + ":" + SOURCE_DOCKER_TAG +  " & "
     print(SOURCE_DOCKER_REGISTRY)
     print(cmd)
cmd = cmd[:len(cmd)-3]
execute_cmd(cmd)

mcr.microsoft.com
docker pull mcr.microsoft.com/mssql/bdc/mssql-app-service-proxy:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-control-watchdog:latest & docker       pull mcr.microsoft.com/mssql/bdc/mssql-controller:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-dns:latest & docker pull mcr.microsoft.com/mssq      l/bdc/mssql-hadoop,mssql-mleap-serving-runtime:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-mlserver-py-runtime:latest & docker pull mcr.micro      soft.com/mssql/bdc/mssql-mlserver-r-runtime:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd:latest & docker pull mcr.microsoft.c      om/mssql/bdc/mssql-monitor-elasticsearch:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit:latest & docker pull mcr.microsoft.com      /mssql/bdc/mssql-monitor-grafana:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-influxdb:latest & docker pull mcr.microsoft.com/mssql/bd      c/mssql-monitor-kibana:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-se      curity-knox:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-security-support:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-server-contro      ller:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-server-data:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-ha-operator:latest & dock      er pull mcr.microsoft.com/mssql/bdc/mssql-ha-supervisor:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-service-proxy:latest &
mcr.microsoft.com
docker pull mcr.microsoft.com/mssql/bdc/mssql-app-service-proxy:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-control-watchdog:latest & docker       pull mcr.microsoft.com/mssql/bdc/mssql-controller:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-dns:latest & docker pull mcr.microsoft.com/mssq      l/bdc/mssql-hadoop,mssql-mleap-serving-runtime:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-mlserver-py-runtime:latest & docker pull mcr.micro      soft.com/mssql/bdc/mssql-mlserver-r-runtime:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-collectd:latest & docker pull mcr.microsoft.c      om/mssql/bdc/mssql-monitor-elasticsearch:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-fluentbit:latest & docker pull mcr.microsoft.com      /mssql/bdc/mssql-monitor-grafana:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-influxdb:latest & docker pull mcr.microsoft.com/mssql/bd      c/mssql-monitor-kibana:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-monitor-telegraf:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-se      curity-knox:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-security-support:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-server-contro      ller:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-server-data:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-ha-operator:latest & dock      er pull mcr.microsoft.com/mssql/bdc/mssql-ha-supervisor:latest & docker pull mcr.microsoft.com/mssql/bdc/mssql-service-proxy:latest & docker pull mcr.mi      crosoft.com/mssql/bdc/mssql-ssis-app-runtime:latest &
"docker pull" requires exactly 1 argument.
See 'docker pull --help'.

Usage:  docker pull [OPTIONS] NAME[:TAG|@DIGEST]

Pull an image or a repository from a registry
Execute docker login to target registry:master:5000
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
Error response from daemon: Get "https://master:5000/v2/": http: server gave HTTP response to HTTPS client

Tagging local images...
"docker tag" requires exactly 2 arguments.
See 'docker tag --help'.

Usage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]

Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
Push images to target Docker repository: master:5000/mssql/bdc
"docker push" requires exactly 1 argument.
See 'docker push --help'.

Usage:  docker push [OPTIONS] NAME[:TAG]

Push an image or a repository to a registry
Images are now pushed to the target repository.
...


#BDC upgrade
azdata bdc upgrade -n mssql-cluster -t 2019-CU5-ubuntu-16.04 -r mcr.microsoft.com/mssql/bdc


issue:
1)
[root@master ~]# kubectl get pods -w -n csi-powerstore
NAME                                     READY   STATUS             RESTARTS   AGE
powerstore-controller-7bc455d5c7-bn2q9   5/5     Running            184        16h
powerstore-controller-7bc455d5c7-d4fjd   4/5     CrashLoopBackOff   184        16h
powerstore-controller-7bc455d5c7-vfvgt   4/5     CrashLoopBackOff   184        16h
powerstore-node-6hljh                    2/2     Running            0          16h
powerstore-node-jbbds                    2/2     Running            0          16h
powerstore-node-xg7wp                    2/2     Running            0          16h
powerstore-controller-7bc455d5c7-bn2q9   4/5     Error              184        16h
powerstore-controller-7bc455d5c7-bn2q9   4/5     CrashLoopBackOff   184        16h


[root@master dell-csi-helm-installer]# kubectl logs -f powerstore-controller-7bc455d5c7-bn2q9 -c snapshotter

I0322 10:11:27.729241       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
E0322 10:12:06.262052       1 leaderelection.go:325] error retrieving resource lock csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/csi-powerstore/leases/external-snapshotter-leader-csi-powerstore-dellemc-com": dial tcp 10.96.0.1:443: i/o timeout
I0322 10:12:06.262096       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
E0322 10:12:45.820648       1 leaderelection.go:325] error retrieving resource lock csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/csi-powerstore/leases/external-snapshotter-leader-csi-powerstore-dellemc-com": dial tcp 10.96.0.1:443: i/o timeout
I0322 10:12:45.820688       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
^C
-->fix
#only use 2 node test, master and node1!!!
check /etc/hosts right lines!!!
192.168.1.20 master master
192.168.1.21 node1  node1
[root@master ~]# kubectl get pods
NAME                                     READY   STATUS    RESTARTS   AGE
powerstore-controller-7bc455d5c7-5zm85   5/5     Running   112        9h
powerstore-controller-7bc455d5c7-kqlrv   5/5     Running   10         9h
powerstore-node-rskw4                    2/2     Running   4          9h
powerstore-node-z7l8b                    2/2     Running   4          9h

[root@master ~]# kubectl logs powerstore-controller-7bc455d5c7-kqlrv snapshotter
I0613 02:56:56.060628       1 leaderelection.go:273] successfully renewed lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com
I0613 02:57:01.070784       1 leaderelection.go:273] successfully renewed lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com

[root@master ~]# kubectl logs powerstore-controller-7bc455d5c7-5zm85 snapshotter -f
I0613 02:58:49.876381       1 leaderelection.go:346] lock is held by powerstore-controller-7bc455d5c7-kqlrv and has not yet expired
I0613 02:58:49.876398       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-snapshotter-leader-csi-powerstore-dellemc-com

2)csi 1.4.0 driver install issue
[root@master dell-csi-helm-installer]# ./csi-install.sh --namespace csi-powerstore --values ./my-powerstore-settings.yaml
...
...
|- Verifying helm version                                           Success

------------------------------------------------------
> Verification Complete - Success
------------------------------------------------------
|
|- Installing Driver                                                Error: template: csi-powerstore/templates/controller.yaml:67:19: executing "csi-powerstore/templates/controller.yaml" at <.Values.replication.enabled>: nil pointer evaluating interface {}.enabled

------------------------------------------------------
Error: Helm operation failed, output can be found in /tmp/csi-install.127624.out. The failure should be examined, before proceeding. Additionally, running csi-uninstall.sh may be needed to clean up partial deployments.
Installation cannot continue
-->fix
#add "replication" to false!!!
[root@master dell-csi-helm-installer]# vim my-powerstore-settings.yaml
...
replication:
  enabled: false

3)
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-8xhgz driver | grep -i "error\|failed"
{"level":"error","msg":"iscsi initiators found on node","time":"2021-06-22T16:28:08.568003871Z"}
{"level":"error","msg":"failed to read initiator ports names: FC is not supported for this host","time":"2021-06-22T16:28:08.568096312Z"}
{"level":"error","msg":"FC was not found or filtered with FCPortsFilterFile","time":"2021-06-22T16:28:08.568120251Z"}
{"level":"error","msg":"Get \"https://192.168.1.30/api/rest/host?limit=1000\u0026offset=0\u0026order=name\u0026select=id%2Cname%2Cdescription%2Chost_group_id%2Cimport_host_system_id%2Cos_type%2Ctype%2Chost_initiators\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:08.619686872Z"}
{"level":"error","msg":"can't setup host on https://192.168.1.30/api/rest: Get \"https://192.168.1.30/api/rest/host?limit=1000\u0026offset=0\u0026order=name\u0026select=id%2Cname%2Cdescription%2Chost_group_id%2Cimport_host_system_id%2Cos_type%2Ctype%2Chost_initiators\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:08.619779977Z"}
{"level":"error","msg":"Get \"https://192.168.1.30/api/rest/ip_pool_address?order=id\u0026purposes=cs.%7BStorage_Iscsi_Target%7D\u0026select=address%2Cappliance_id%2Cid%2Cip_port_id%2Cip_port%28target_iqn%2C+id%29%2Cnetwork_id%2Cnode_id%2Cpurposes\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:09.493292411Z"}
{"level":"error","msg":"couldn't get targets from array: Get \"https://192.168.1.30/api/rest/ip_pool_address?order=id\u0026purposes=cs.%7BStorage_Iscsi_Target%7D\u0026select=address%2Cappliance_id%2Cid%2Cip_port_id%2Cip_port%28target_iqn%2C+id%29%2Cnetwork_id%2Cnode_id%2Cpurposes\": tls: failed to parse certificate from server: asn1: structure error: integer not minimally-encoded","time":"2021-06-22T16:28:09.493310476Z"}
[root@master dell-csi-helm-installer]#
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-685ff6cb4b-g95w6 attacher | grep -i "error\|failed"
I0622 16:28:08.972809       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.973742       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.975031       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.977185       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.978389       1 connection.go:186] GRPC error: <nil>
I0622 16:28:09.014772       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0622 16:28:17.654198       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-685ff6cb4b-g95w6 provisioner | grep -i "error\|failed"
I0622 16:28:08.348313       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.349898       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.351509       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.352395       1 connection.go:186] GRPC error: <nil>
I0622 16:28:08.369140       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
I0622 16:28:19.020188       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com

[root@master tmp]# kubectl get pvc
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Pending                                      powerstore-xfs   9s
mssql-data2   Pending                                      powerstore-xfs   9s
mssql-log2    Pending                                      powerstore-xfs   9s
[root@master tmp]# kubectl describe pvc mssql-data
...
Events:
  Type     Reason                Age                From                                                                                                    Message
  ----     ------                ----               ----                                                                                                    -------
  Normal   Provisioning          14s (x5 over 27s)  csi-powerstore.dellemc.com_powerstore-controller-685ff6cb4b-rkk2q_72dc4dfb-a968-444c-9a81-de775162c97a  External provisioner is provisioning volume for claim "default/mssql-data"
  Warning  ProvisioningFailed    14s (x5 over 27s)  csi-powerstore.dellemc.com_powerstore-controller-685ff6cb4b-rkk2q_72dc4dfb-a968-444c-9a81-de775162c97a  failed to provision volume with StorageClass "powerstore-xfs": rpc error: code = Internal desc = Array IP's been provided, however it is not supported in current version. Configure you storage classes according to the documentation
  Normal   ExternalProvisioning  13s (x4 over 29s)  persistentvolume-controller                                                                             waiting for a volume to be created, either by external provisioner "csi-powerstore.dellemc.com" or manually created by system administrator

-->fix
use 192.168.1.40 firmware with sp4 normal!!!

[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 
driver     registrar
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 driver | grep -i "error\|failed"
{"level":"error","msg":"iscsi initiators found on node","time":"2021-06-25T11:55:29.025240969Z"}
{"level":"error","msg":"failed to read initiator ports names: FC is not supported for this host","time":"2021-06-25T11:55:29.025326146Z"}
{"level":"error","msg":"FC was not found or filtered with FCPortsFilterFile","time":"2021-06-25T11:55:29.02536739Z"}
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-node-frl67 registrar | grep -i "error\|failed"
I0625 11:56:23.245146       1 connection.go:186] GRPC error: <nil>
I0625 11:56:23.720754       1 main.go:90] Received NotifyRegistrationStatus call: &RegistrationStatus{PluginRegistered:true,Error:,}
[root@master dell-csi-helm-installer]#

[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm
attacher     driver       provisioner  resizer
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm attacher | grep -i "error\|failed"
I0625 11:57:38.984501       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.985615       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.987002       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.988187       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.989306       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.033355       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0625 11:57:47.666299       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
I0625 11:57:58.319250       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-attacher-leader-csi-powerstore-dellemc-com
root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm driver | grep -i "error\|failed"
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm provisioner |grep -i "error\|failed"
I0625 11:57:38.903729       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.905305       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.906920       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.908222       1 connection.go:186] GRPC error: <nil>
I0625 11:57:38.945069       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
I0625 11:57:49.593829       1 leaderelection.go:248] failed to acquire lease csi-powerstore/csi-powerstore-dellemc-com
[root@master dell-csi-helm-installer]# kubectl logs -n csi-powerstore powerstore-controller-74c75cb64-pnjgm resizer |grep -i "error\|failed"
I0625 11:57:39.393998       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.395062       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.396430       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.398074       1 connection.go:186] GRPC error: <nil>
I0625 11:57:39.417296       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-resizer-csi-powerstore-dellemc-com
I0625 11:57:48.054355       1 leaderelection.go:248] failed to acquire lease csi-powerstore/external-resizer-csi-powerstore-dellemc-com

[root@master ~]# kubectl get pvc
NAME          STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS     AGE
mssql-data    Bound    csi-115a96149c   10Gi       RWO            powerstore-xfs   100m
mssql-data2   Bound    csi-3962f2348e   5Gi        RWO            powerstore-xfs   100m
mssql-log2    Bound    csi-1b60e606af   2Gi        RWO            powerstore-xfs   100m
[root@master ~]# kubectl describe pvc mssql-data
Name:          mssql-data
Namespace:     csi-powerstore
StorageClass:  powerstore-xfs
Status:        Bound
Volume:        csi-115a96149c
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-class: powerstore-xfs
               volume.beta.kubernetes.io/storage-provisioner: csi-powerstore.dellemc.com
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      10Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       mssql-deployment-5f4cd94964-hs774
Events:        <none>

4)curl issue
cluster1 with firmware 1.0.0.0.4.038 have issue.
cluster2 with firmware 1.0.4.0.5.003 normal !!!
rhel8.2 and centos 8.4 same issue, will rhel7 curl is normal !!!

[root@master ~]#  curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.30/api/rest/cluster?select=*
*   Trying 192.168.1.30...
* TCP_NODELAY set
* Connected to 192.168.1.30 (192.168.1.30) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS alert, bad certificate (554):
* error:0D0E20DD:asn1 encoding routines:c2i_ibuf:illegal padding
* Closing connection 0
curl: (35) error:0D0E20DD:asn1 encoding routines:c2i_ibuf:illegal padding
[root@master ~]#

[root@master ~]#  curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=*
*   Trying 192.168.1.40...
* TCP_NODELAY set
* Connected to 192.168.1.40 (192.168.1.40) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server did not agree to a protocol
* Server certificate:
*  subject: C=US + O=Dell + L=Hopkinton + OU=PowerStore + ST=Massachusetts + CN=ManagementHTTP.PSec370360bc60
*  start date: Jun 21 03:11:23 2021 GMT
*  expire date: Jun 20 03:11:23 2026 GMT
*  issuer: C=US; ST=MA; O=Dell EMC; CN=Dell EMC PowerStore CA YZ4USM9E
*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Host: 192.168.1.40
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.61.1
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: IhJC/04NmCqSmLQxvgyVSsnebB8A/0qHDa+K3LkhXJY=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=dae0401ca49609c01f6102c5f9fa5191; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.40 left intact
[{"id":"0","global_id":"PSec370360bc60","name":"POD3-Cluster2","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.40","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.40","compatibility_level":1,"state_l10n":"Configured"}]
[root@master ~]#


[root@linux17 ~]# curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.30/api/rest/cluster?select=*
* About to connect() to 192.168.1.30 port 443 (#0)
*   Trying 192.168.1.30...
* Connected to 192.168.1.30 (192.168.1.30) port 443 (#0)
* Initializing NSS with certpath: sql:/etc/pki/nssdb
* skipping SSL peer certificate verification
* NSS: client certificate not found (nickname not specified)
* SSL connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
* Server certificate:
*       subject: C=US+O=Dell+L=Hopkinton+OU=PowerStore+ST=Massachusetts+CN=ManagementHTTP.PS04e694d0c442
*       start date: Jun 21 03:09:45 2021 GMT
*       expire date: Jun 20 03:09:45 2026 GMT
*       common name: ManagementHTTP.PS04e694d0c442
*       issuer: CN=Dell EMC PowerStore CA ZTUGYPNK,O=Dell EMC,ST=MA,C=US
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.29.0
> Host: 192.168.1.30
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: IrfmhMXOORUkBZ0RGzAPV1AK+O07s5uRbULnslrRr8s=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=b5557d07ba1347883106689382b97a74; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.30 left intact
[{"id":"0","global_id":"PS04e694d0c442","name":"POD3-Cluster1","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.30","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.30","compatibility_level":1,"state_l10n":"Configured"}]
[root@linux17 ~]#

-->fix
192.168.1.30 powerstore firmware 1.0.0.0.4.038 have reset api issue!!! (rhel7 use curl check normal, but centos 8.4 or rhel 8.2 have this issue!)
192.168.1.40 powerstore firmware sp4 1.0.4.0.5.003 can use normal!!!

[root@master ~]# curl -vvv -k --user admin:P@ssw0rd! https://192.168.1.40/api/rest/cluster?select=*
*   Trying 192.168.1.40...
* TCP_NODELAY set
* Connected to 192.168.1.40 (192.168.1.40) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server did not agree to a protocol
* Server certificate:
*  subject: C=US + O=Dell + L=Hopkinton + OU=PowerStore + ST=Massachusetts + CN=ManagementHTTP.PSec370360bc60
*  start date: Jun 21 03:11:23 2021 GMT
*  expire date: Jun 20 03:11:23 2026 GMT
*  issuer: C=US; ST=MA; O=Dell EMC; CN=Dell EMC PowerStore CA YZ4USM9E
*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.
* Server auth using Basic with user 'admin'
> GET /api/rest/cluster?select=* HTTP/1.1
> Host: 192.168.1.40
> Authorization: Basic YWRtaW46UEBzc3cwcmQh
> User-Agent: curl/7.61.1
> Accept: */*
>
< HTTP/1.1 200 OK
< DELL-EMC-TOKEN: cLdyIkHyN9a/gVqfpZPeHzNLTcuEMj1C55WLJqAEy9Q=
< Content-Type: application/json
< transfer-encoding: chunked
< content-language: en-US
< set-cookie: auth_cookie=9ccf86b61424b93b3f57e891f6a3a95d; Path=/; Secure; HTTPOnly
<
* Connection #0 to host 192.168.1.40 left intact
[{"id":"0","global_id":"PSec370360bc60","name":"POD3-Cluster2","physical_mtu":1500,"master_appliance_id":"A1","state":"Configured","appliance_count":1,"management_address":"192.168.1.40","is_encryption_enabled":true,"storage_discovery_address":"192.168.2.40","compatibility_level":1,"state_l10n":"Configured"}]

5)azdata install issue
[root@master sql]# yum list azdata-cli
packages-microsoft-com-prod                                                                                                  0.0  B/s |   0  B     00:00
Errors during downloading metadata for repository 'packages-microsoft-com-prod':
  - Curl error (60): Peer certificate cannot be authenticated with given CA certificates for https://packages.microsoft.com/rhel/8/prod/repodata/repomd.xml [SSL certificate problem: self signed certificate in certificate chain]
Error: Failed to download metadata for repo 'packages-microsoft-com-prod': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried

-->fix
add "sslverify=false" to /etc/yum.conf
[root@master sql]# cat /etc/yum.conf
[main]
gpgcheck=1
installonly_limit=3
clean_requirements_on_remove=True
best=True
skip_if_unavailable=False
sslverify=false

[root@master sql]# yum list azdata-cli
packages-microsoft-com-prod                                                                                                  6.2 MB/s | 7.5 MB     00:01
Last metadata expiration check: 0:00:19 ago on Fri 25 Jun 2021 11:52:48 PM EDT.
Available Packages
azdata-cli.x86_64                                                  20.3.5-1.el7                                                   packages-microsoft-com-prod

6)BDC deploy issue
metricsdc-xxx pods continus crash-->error-->running

mssql-cluster    metricsdc-gx5w6                              0/1     CrashLoopBackOff    3 (17s ago)     7m10s
mssql-cluster    metricsdc-qjwp7                              0/1     Error               3 (113s ago)    7m10s
mssql-cluster    metricsdc-qjwp7                              0/1     CrashLoopBackOff    3 (15s ago)     7m24s
mssql-cluster    metricsdc-gx5w6                              1/1     Running             4 (50s ago)     7m43s
mssql-cluster    metricsdc-qjwp7                              1/1     Running             4 (45s ago)     7m54s
mssql-cluster    metricsdc-v9tnk                              0/1     Error               3 (115s ago)    8m13s
mssql-cluster    metricsdc-v9tnk                              0/1     CrashLoopBackOff    3 (12s ago)     8m25s
mssql-cluster    metricsdc-v9tnk                              1/1     Running             4 (51s ago)     9m4s

[root@master ~]# kubectl logs -f metricsdc-v9tnk
2021/10/05 16:12:09.563521 [telegraf:stderr] 2021/10/05 16:10:45 [LAUNCH] Starting to run the process "telegraf"
2021/10/05 16:12:09.563536 [telegraf:stderr] cat: /var/run/secrets/kubernetes.io/serviceaccount/token: Permission denied
2021/10/05 16:12:09.563550 [telegraf:stderr] 2021/10/05 16:10:45 [LAUNCH] The process "telegraf" exists and returns error: The process exited with code '1' and error: exit status 1
2021/10/05 16:12:09.563561 [telegraf:stderr] 2021/10/05 16:10:45 [LAUNCH] Starting to force stop process "telegraf"
2021/10/05 16:12:09.563580 [telegraf:stderr] 2021/10/05 16:10:45 The process launcher "telegraf" exited: Failed to force stop the process "telegraf": no such process
2021/10/05 16:12:09.563618 [telegraf:stderr] 2021/10/05 16:10:46 [LAUNCH] Starting to run the process "telegraf"
2021/10/05 16:12:09.563637 [telegraf:stderr] cat: /var/run/secrets/kubernetes.io/serviceaccount/token: Permission denied
2021/10/05 16:12:09.563647 [telegraf:stderr] 2021/10/05 16:10:46 [LAUNCH] The process "telegraf" exists and returns error: The process exited with code '1' and error: exit status 1
2021/10/05 16:12:09.563657 [telegraf:stderr] 2021/10/05 16:10:46 [LAUNCH] Starting to force stop process "telegraf"
2021/10/05 16:12:09.563674 [telegraf:stderr] 2021/10/05 16:10:46 The process launcher "telegraf" exited: Failed to force stop the process "telegraf": no such process

ssh node1 tail -f /var/log/message
Oct  5 12:16:20 node1 kubelet[1185]: I1005 12:16:20.652454    1185 kubelet_pods.go:897] "Unable to retrieve pull secret, the image pull may not succeed." pod="mssql-cluster/control-vcz6w" secret="" err="secret \"mssql-private-registry\" not found"

Password doesn't meet the password complexity requirement. For more information: https://docs.microsoft.com/sql/relational-databases/security/password-policy

-->Fix
image use CU13 fix issue!!!, CU12 image have this issue!


7)kubernetes 1.24 install issue
[root@master1 ~]# kubeadm init   --kubernetes-version=v1.24.2   --pod-network-cidr=10.244.0.0/16  --image-repository=registry.aliyuncs.com/google_containers/ --apiserver-advertise-address=192.168.1.20
[init] Using Kubernetes version: v1.24.2
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
[ERROR CRI]: container runtime is not running: output: E0605 10:35:34.973561   12491 remote_runtime.go:925] "Status from runtime service failed" err="rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService"
time="2022-06-05T10:35:34+09:00" level=fatal msg="getting status of runtime: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService"
, error: exit status 1
To see the stack trace of this error execute with --v=5 or higher

-->Fix 
https://stackoverflow.com/questions/72504257/i-encountered-when-executing-kubeadm-init-error-issue
https://github.com/containerd/containerd/issues/4581

rm /etc/containerd/config.toml      //all node(master and workers) need delete this config!!
systemctl restart containerd

re-run: kubeadm init xxx


